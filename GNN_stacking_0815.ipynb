{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "from torch_geometric.data import Data,DataLoader\n",
    "from functions_refactor import *\n",
    "from pytorch_util import *\n",
    "#from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixed parameters\n",
    "block = MEGNet_block\n",
    "head_mol,head_atom,head_edge = head_mol,head_atom,head_edge\n",
    "clip = 0.5\n",
    "batch_size = 64\n",
    "threshold = 1e3\n",
    "reuse = False\n",
    "lr = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# changing parameters\n",
    "head = SimplyInteraction\n",
    "data = '../Data/{}_data_stacking_0815.pickle'\n",
    "dim = 22\n",
    "logLoss = False\n",
    "layer = 6\n",
    "factor = 3\n",
    "epochs = 19\n",
    "edge_in4 = 22\n",
    "aggr = 'max'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl,val_dl = get_data(data,batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss: +1.327, val_loss: +0.097, \n",
      "train_vector: -0.79|-0.87|-2.05|-2.25|-2.32|-1.95|-2.19|-2.54, \n",
      "val_vector  : -1.55|-1.91|-2.43|-3.01|-2.94|-2.27|-2.91|-3.12\n",
      "\n",
      "epoch:1, train_loss: +0.099, val_loss: +0.091, \n",
      "train_vector: -1.48|-1.79|-2.47|-3.10|-2.97|-2.31|-2.97|-3.15, \n",
      "val_vector  : -1.57|-2.00|-2.49|-3.26|-3.00|-2.31|-3.05|-3.11\n",
      "\n",
      "epoch:2, train_loss: +0.095, val_loss: +0.096, \n",
      "train_vector: -1.49|-1.82|-2.52|-3.18|-3.00|-2.36|-3.07|-3.19, \n",
      "val_vector  : -1.56|-1.71|-2.53|-3.04|-3.04|-2.36|-3.04|-3.19\n",
      "\n",
      "epoch:3, train_loss: +0.094, val_loss: +0.094, \n",
      "train_vector: -1.49|-1.81|-2.54|-3.22|-3.01|-2.38|-3.11|-3.21, \n",
      "val_vector  : -1.42|-1.99|-2.55|-3.01|-3.04|-2.39|-3.16|-3.21\n",
      "\n",
      "epoch:4, train_loss: +0.091, val_loss: +0.092, \n",
      "train_vector: -1.51|-1.88|-2.56|-3.26|-3.02|-2.39|-3.14|-3.22, \n",
      "val_vector  : -1.58|-1.87|-2.49|-3.08|-3.03|-2.38|-3.13|-3.10\n",
      "\n",
      "epoch:5, train_loss: +0.093, val_loss: +0.099, \n",
      "train_vector: -1.48|-1.82|-2.56|-3.28|-3.03|-2.40|-3.15|-3.22, \n",
      "val_vector  : -1.59|-1.87|-2.48|-2.39|-2.98|-2.37|-3.04|-3.15\n",
      "\n",
      "epoch:6, train_loss: +0.092, val_loss: +0.089, \n",
      "train_vector: -1.50|-1.85|-2.57|-3.29|-3.03|-2.40|-3.16|-3.23, \n",
      "val_vector  : -1.54|-2.00|-2.55|-3.08|-3.07|-2.40|-3.11|-3.24\n",
      "\n",
      "epoch:7, train_loss: +0.090, val_loss: +0.106, \n",
      "train_vector: -1.52|-1.89|-2.57|-3.30|-3.05|-2.40|-3.16|-3.23, \n",
      "val_vector  : -1.55|-1.35|-2.56|-2.97|-2.98|-2.39|-3.21|-3.20\n",
      "\n",
      "epoch:8, train_loss: +0.090, val_loss: +0.093, \n",
      "train_vector: -1.52|-1.88|-2.58|-3.31|-3.04|-2.41|-3.17|-3.23, \n",
      "val_vector  : -1.37|-2.04|-2.58|-3.06|-3.05|-2.40|-3.19|-3.23\n",
      "\n",
      "epoch:9, train_loss: +0.089, val_loss: +0.109, \n",
      "train_vector: -1.51|-1.94|-2.58|-3.30|-3.04|-2.41|-3.17|-3.23, \n",
      "val_vector  : -1.22|-1.57|-2.56|-3.33|-3.01|-2.39|-3.09|-3.10\n",
      "\n",
      "epoch:10, train_loss: +0.090, val_loss: +0.089, \n",
      "train_vector: -1.50|-1.90|-2.58|-3.31|-3.05|-2.41|-3.17|-3.24, \n",
      "val_vector  : -1.47|-2.04|-2.57|-3.33|-3.07|-2.41|-3.18|-3.24\n",
      "\n",
      "epoch:11, train_loss: +0.089, val_loss: +0.085, \n",
      "train_vector: -1.50|-1.93|-2.58|-3.31|-3.05|-2.41|-3.18|-3.24, \n",
      "val_vector  : -1.60|-2.07|-2.58|-3.34|-3.05|-2.40|-3.21|-3.24\n",
      "\n",
      "epoch:12, train_loss: +0.090, val_loss: +0.094, \n",
      "train_vector: -1.49|-1.93|-2.58|-3.33|-3.05|-2.41|-3.18|-3.24, \n",
      "val_vector  : -1.44|-2.01|-2.53|-3.01|-3.06|-2.36|-3.00|-3.15\n",
      "\n",
      "epoch:13, train_loss: +0.090, val_loss: +0.096, \n",
      "train_vector: -1.49|-1.92|-2.59|-3.33|-3.06|-2.41|-3.18|-3.24, \n",
      "val_vector  : -1.34|-2.05|-2.54|-2.96|-3.02|-2.39|-3.12|-3.17\n",
      "\n",
      "epoch:14, train_loss: +0.089, val_loss: +0.099, \n",
      "train_vector: -1.50|-1.93|-2.58|-3.34|-3.06|-2.41|-3.18|-3.24, \n",
      "val_vector  : -1.62|-1.48|-2.57|-3.24|-3.06|-2.40|-3.04|-3.17\n",
      "\n",
      "epoch:15, train_loss: +0.089, val_loss: +0.091, \n",
      "train_vector: -1.50|-1.95|-2.59|-3.33|-3.06|-2.41|-3.19|-3.24, \n",
      "val_vector  : -1.47|-1.95|-2.57|-3.23|-3.06|-2.41|-3.20|-3.23\n",
      "\n",
      "epoch:16, train_loss: +0.089, val_loss: +0.086, \n",
      "train_vector: -1.45|-1.98|-2.59|-3.35|-3.07|-2.41|-3.19|-3.25, \n",
      "val_vector  : -1.55|-2.12|-2.54|-3.26|-3.08|-2.41|-3.18|-3.22\n",
      "\n",
      "epoch:17, train_loss: +0.088, val_loss: +0.087, \n",
      "train_vector: -1.51|-1.96|-2.59|-3.35|-3.07|-2.41|-3.19|-3.24, \n",
      "val_vector  : -1.62|-2.05|-2.57|-3.08|-3.01|-2.41|-3.16|-3.17\n",
      "\n",
      "epoch:18, train_loss: +0.085, val_loss: +0.084, \n",
      "train_vector: -1.56|-2.03|-2.59|-3.38|-3.08|-2.42|-3.20|-3.25, \n",
      "val_vector  : -1.57|-2.11|-2.58|-3.37|-3.08|-2.41|-3.21|-3.26\n",
      "\n",
      "epoch:19, train_loss: +0.085, val_loss: +0.088, \n",
      "train_vector: -1.56|-2.05|-2.59|-3.38|-3.08|-2.42|-3.20|-3.25, \n",
      "val_vector  : -1.47|-2.06|-2.57|-3.39|-3.08|-2.41|-3.15|-3.22\n",
      "\n",
      "-----stop due to poor performance-----\n"
     ]
    }
   ],
   "source": [
    "    model = GNN_multiHead_interleave_stacking(reuse,block,head,dim,layer,factor,edge_in4).to('cuda:0')\n",
    "    paras = trainable_parameter(model)\n",
    "    opt = Adam(paras,lr=lr)\n",
    "    scheduler = ReduceLROnPlateau(opt, 'min',factor=0.5,patience=5,min_lr=1e-05)\n",
    "    \n",
    "    model,train_loss_perType,val_loss_perType,bestWeight = train_type_earlyStop(opt,model,epochs,train_dl,val_dl,paras,clip,\\\n",
    "                                                                    scheduler=scheduler,logLoss=logLoss,threshold=threshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss: +3.744, val_loss: +0.105, \n",
      "train_vector: +0.33|-0.10|-0.71|-1.61|-1.42|-1.04|-0.70|-1.72, \n",
      "val_vector  : -1.46|-1.83|-2.30|-3.05|-2.85|-2.20|-2.82|-2.99\n",
      "\n",
      "epoch:1, train_loss: +0.100, val_loss: +0.099, \n",
      "train_vector: -1.47|-1.89|-2.37|-3.08|-2.95|-2.24|-2.91|-3.05, \n",
      "val_vector  : -1.40|-1.86|-2.46|-3.28|-2.99|-2.31|-3.01|-3.15\n",
      "\n",
      "epoch:2, train_loss: +0.095, val_loss: +0.095, \n",
      "train_vector: -1.48|-1.90|-2.46|-3.23|-3.00|-2.32|-3.00|-3.13, \n",
      "val_vector  : -1.52|-1.91|-2.48|-3.06|-3.01|-2.37|-3.00|-3.15\n",
      "\n",
      "epoch:3, train_loss: +0.092, val_loss: +0.091, \n",
      "train_vector: -1.50|-1.93|-2.50|-3.28|-3.02|-2.36|-3.05|-3.17, \n",
      "val_vector  : -1.51|-2.09|-2.45|-3.11|-2.95|-2.40|-3.07|-3.22\n",
      "\n",
      "epoch:4, train_loss: +0.090, val_loss: +0.096, \n",
      "train_vector: -1.51|-1.96|-2.52|-3.28|-3.03|-2.38|-3.09|-3.18, \n",
      "val_vector  : -1.35|-1.94|-2.55|-3.22|-3.00|-2.40|-3.16|-3.21\n",
      "\n",
      "epoch:5, train_loss: +0.091, val_loss: +0.089, \n",
      "train_vector: -1.48|-1.96|-2.54|-3.30|-3.04|-2.39|-3.11|-3.20, \n",
      "val_vector  : -1.51|-2.07|-2.55|-3.32|-2.94|-2.42|-3.09|-3.19\n",
      "\n",
      "epoch:6, train_loss: +0.090, val_loss: +0.089, \n",
      "train_vector: -1.48|-1.97|-2.55|-3.32|-3.05|-2.40|-3.13|-3.20, \n",
      "val_vector  : -1.53|-1.97|-2.56|-3.40|-2.99|-2.41|-3.14|-3.24\n",
      "\n",
      "epoch:7, train_loss: +0.089, val_loss: +0.097, \n",
      "train_vector: -1.51|-1.98|-2.56|-3.33|-3.06|-2.40|-3.14|-3.21, \n",
      "val_vector  : -1.38|-1.96|-2.46|-3.38|-2.83|-2.41|-2.91|-3.21\n",
      "\n",
      "epoch:8, train_loss: +0.089, val_loss: +0.093, \n",
      "train_vector: -1.50|-1.99|-2.56|-3.33|-3.07|-2.41|-3.14|-3.22, \n",
      "val_vector  : -1.30|-2.12|-2.57|-3.38|-3.05|-2.42|-3.20|-3.26\n",
      "\n",
      "epoch:9, train_loss: +0.088, val_loss: +0.085, \n",
      "train_vector: -1.49|-2.01|-2.57|-3.34|-3.06|-2.41|-3.16|-3.22, \n",
      "val_vector  : -1.60|-2.12|-2.57|-3.34|-3.06|-2.41|-3.14|-3.07\n",
      "\n",
      "epoch:10, train_loss: +0.088, val_loss: +0.089, \n",
      "train_vector: -1.52|-1.99|-2.57|-3.34|-3.07|-2.41|-3.15|-3.23, \n",
      "val_vector  : -1.47|-2.12|-2.55|-3.25|-2.97|-2.42|-3.09|-3.22\n",
      "\n",
      "epoch:11, train_loss: +0.088, val_loss: +0.108, \n",
      "train_vector: -1.51|-2.01|-2.57|-3.35|-3.07|-2.41|-3.16|-3.22, \n",
      "val_vector  : -1.15|-1.74|-2.42|-3.35|-2.90|-2.41|-3.04|-3.25\n",
      "\n",
      "epoch:12, train_loss: +0.087, val_loss: +0.087, \n",
      "train_vector: -1.52|-2.01|-2.58|-3.35|-3.07|-2.41|-3.17|-3.23, \n",
      "val_vector  : -1.48|-2.06|-2.60|-3.41|-3.02|-2.43|-3.22|-3.26\n",
      "\n",
      "epoch:13, train_loss: +0.086, val_loss: +0.089, \n",
      "train_vector: -1.54|-2.02|-2.58|-3.35|-3.08|-2.41|-3.17|-3.23, \n",
      "val_vector  : -1.59|-1.95|-2.59|-3.25|-3.04|-2.42|-3.20|-2.98\n",
      "\n",
      "epoch:14, train_loss: +0.087, val_loss: +0.092, \n",
      "train_vector: -1.51|-2.01|-2.58|-3.36|-3.07|-2.41|-3.17|-3.23, \n",
      "val_vector  : -1.43|-1.97|-2.57|-3.10|-3.09|-2.43|-3.21|-3.19\n",
      "\n",
      "epoch:15, train_loss: +0.088, val_loss: +0.086, \n",
      "train_vector: -1.50|-2.00|-2.58|-3.35|-3.08|-2.41|-3.17|-3.24, \n",
      "val_vector  : -1.51|-2.11|-2.60|-3.39|-3.08|-2.43|-3.08|-3.26\n",
      "\n",
      "epoch:16, train_loss: +0.085, val_loss: +0.085, \n",
      "train_vector: -1.56|-2.05|-2.59|-3.39|-3.09|-2.42|-3.19|-3.25, \n",
      "val_vector  : -1.54|-2.13|-2.57|-3.45|-3.06|-2.43|-3.18|-3.27\n",
      "\n",
      "epoch:17, train_loss: +0.084, val_loss: +0.094, \n",
      "train_vector: -1.57|-2.05|-2.59|-3.39|-3.09|-2.42|-3.19|-3.25, \n",
      "val_vector  : -1.61|-2.06|-2.29|-2.79|-2.97|-2.37|-2.98|-3.18\n",
      "\n",
      "epoch:18, train_loss: +0.084, val_loss: +0.093, \n",
      "train_vector: -1.56|-2.06|-2.59|-3.39|-3.09|-2.42|-3.18|-3.24, \n",
      "val_vector  : -1.32|-2.08|-2.55|-3.43|-3.06|-2.43|-3.16|-3.21\n",
      "\n",
      "Training completed in 670.399570941925s\n"
     ]
    }
   ],
   "source": [
    "# layer = 4\n",
    "    model = GNN_multiHead_interleave_stacking(reuse,block,head,dim,layer,factor,edge_in4).to('cuda:0')\n",
    "    paras = trainable_parameter(model)\n",
    "    opt = RAdam(paras,lr=lr)\n",
    "    scheduler = ReduceLROnPlateau(opt, 'min',factor=0.5,patience=5,min_lr=1e-05)\n",
    "    \n",
    "    model,train_loss_perType,val_loss_perType,bestWeight = train_type_earlyStop(opt,model,epochs,train_dl,val_dl,paras,clip,\\\n",
    "                                                                    scheduler=scheduler,logLoss=logLoss,threshold=threshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss: +2.494, val_loss: -2.325, \n",
      "train_vector: -0.34|-0.17|-0.91|-1.43|-1.45|-1.44|-1.15|-1.35, \n",
      "val_vector  : -1.36|-1.46|-2.33|-3.08|-2.69|-2.05|-2.84|-2.78\n",
      "\n",
      "epoch:1, train_loss: +0.108, val_loss: -2.510, \n",
      "train_vector: -1.41|-1.77|-2.41|-3.09|-2.77|-2.15|-2.95|-2.85, \n",
      "val_vector  : -1.53|-1.83|-2.45|-3.18|-2.84|-2.22|-3.01|-3.02\n",
      "\n",
      "epoch:2, train_loss: +0.100, val_loss: -2.561, \n",
      "train_vector: -1.43|-1.83|-2.48|-3.18|-2.89|-2.27|-3.04|-3.00, \n",
      "val_vector  : -1.54|-1.87|-2.48|-3.20|-2.94|-2.30|-3.07|-3.10\n",
      "\n",
      "epoch:3, train_loss: +0.097, val_loss: -2.560, \n",
      "train_vector: -1.43|-1.88|-2.52|-3.22|-2.94|-2.32|-3.09|-3.08, \n",
      "val_vector  : -1.28|-2.01|-2.51|-3.14|-3.00|-2.33|-3.10|-3.12\n",
      "\n",
      "epoch:4, train_loss: +0.094, val_loss: -2.616, \n",
      "train_vector: -1.48|-1.89|-2.54|-3.24|-2.97|-2.35|-3.12|-3.12, \n",
      "val_vector  : -1.49|-2.05|-2.52|-3.29|-2.93|-2.35|-3.14|-3.15\n",
      "\n",
      "epoch:5, train_loss: +0.094, val_loss: -2.573, \n",
      "train_vector: -1.47|-1.86|-2.55|-3.26|-2.99|-2.37|-3.13|-3.14, \n",
      "val_vector  : -1.33|-1.94|-2.54|-3.11|-3.00|-2.37|-3.13|-3.17\n",
      "\n",
      "epoch:6, train_loss: +0.094, val_loss: -2.609, \n",
      "train_vector: -1.44|-1.87|-2.56|-3.28|-3.01|-2.38|-3.14|-3.16, \n",
      "val_vector  : -1.58|-1.70|-2.54|-3.31|-3.03|-2.38|-3.15|-3.18\n",
      "\n",
      "epoch:7, train_loss: +0.093, val_loss: -2.634, \n",
      "train_vector: -1.45|-1.89|-2.56|-3.29|-3.02|-2.39|-3.15|-3.18, \n",
      "val_vector  : -1.51|-2.02|-2.56|-3.33|-3.01|-2.38|-3.16|-3.11\n",
      "\n",
      "epoch:8, train_loss: +0.092, val_loss: -2.569, \n",
      "train_vector: -1.45|-1.92|-2.57|-3.30|-3.02|-2.39|-3.15|-3.19, \n",
      "val_vector  : -1.29|-1.93|-2.55|-3.05|-2.96|-2.38|-3.17|-3.21\n",
      "\n",
      "epoch:9, train_loss: +0.093, val_loss: -2.532, \n",
      "train_vector: -1.42|-1.90|-2.57|-3.30|-3.03|-2.40|-3.17|-3.20, \n",
      "val_vector  : -1.51|-1.59|-2.57|-2.82|-3.01|-2.39|-3.18|-3.19\n",
      "\n",
      "epoch:10, train_loss: +0.092, val_loss: -2.579, \n",
      "train_vector: -1.45|-1.92|-2.58|-3.32|-3.04|-2.40|-3.17|-3.20, \n",
      "val_vector  : -1.19|-2.01|-2.56|-3.20|-3.01|-2.39|-3.15|-3.12\n",
      "\n",
      "epoch:11, train_loss: +0.091, val_loss: -2.662, \n",
      "train_vector: -1.47|-1.92|-2.58|-3.32|-3.04|-2.40|-3.17|-3.21, \n",
      "val_vector  : -1.55|-2.00|-2.56|-3.35|-3.05|-2.39|-3.18|-3.22\n",
      "\n",
      "epoch:12, train_loss: +0.093, val_loss: -2.637, \n",
      "train_vector: -1.39|-1.94|-2.58|-3.33|-3.03|-2.40|-3.18|-3.21, \n",
      "val_vector  : -1.54|-2.01|-2.57|-3.26|-2.94|-2.39|-3.17|-3.21\n",
      "\n",
      "epoch:13, train_loss: +0.089, val_loss: -2.645, \n",
      "train_vector: -1.49|-1.97|-2.58|-3.33|-3.05|-2.40|-3.18|-3.22, \n",
      "val_vector  : -1.61|-1.79|-2.57|-3.35|-3.03|-2.40|-3.18|-3.22\n",
      "\n",
      "epoch:14, train_loss: +0.089, val_loss: -2.656, \n",
      "train_vector: -1.49|-1.94|-2.58|-3.34|-3.05|-2.41|-3.18|-3.22, \n",
      "val_vector  : -1.42|-2.09|-2.58|-3.39|-3.08|-2.40|-3.10|-3.21\n",
      "\n",
      "epoch:15, train_loss: +0.088, val_loss: -2.655, \n",
      "train_vector: -1.51|-1.97|-2.58|-3.36|-3.05|-2.41|-3.18|-3.22, \n",
      "val_vector  : -1.44|-2.04|-2.58|-3.34|-3.02|-2.40|-3.17|-3.24\n",
      "\n",
      "epoch:16, train_loss: +0.091, val_loss: -2.626, \n",
      "train_vector: -1.44|-1.94|-2.58|-3.35|-3.04|-2.41|-3.19|-3.22, \n",
      "val_vector  : -1.59|-2.09|-2.56|-3.10|-2.96|-2.40|-3.15|-3.16\n",
      "\n",
      "epoch:17, train_loss: +0.091, val_loss: -2.629, \n",
      "train_vector: -1.47|-1.89|-2.58|-3.35|-3.05|-2.41|-3.19|-3.23, \n",
      "val_vector  : -1.55|-1.82|-2.57|-3.39|-2.96|-2.40|-3.17|-3.18\n",
      "\n",
      "epoch:18, train_loss: +0.086, val_loss: -2.665, \n",
      "train_vector: -1.57|-1.97|-2.59|-3.38|-3.07|-2.41|-3.20|-3.23, \n",
      "val_vector  : -1.59|-2.08|-2.57|-3.20|-3.07|-2.41|-3.19|-3.22\n",
      "\n",
      "Training completed in 1090.4970433712006s\n"
     ]
    }
   ],
   "source": [
    "# layer = 6\n",
    "model = GNN_multiHead_interleave_stacking(reuse,block,head,dim,layer,factor,edge_in4).to('cuda:0')\n",
    "paras = trainable_parameter(model)\n",
    "opt = RAdam(paras,lr=lr,weight_decay=1e-2)\n",
    "scheduler = ReduceLROnPlateau(opt, 'min',factor=0.5,patience=5,min_lr=1e-05)\n",
    "\n",
    "model,train_loss_perType,val_loss_perType,bestWeight = train_type_earlyStop(opt,model,epochs,train_dl,val_dl,paras,clip,\\\n",
    "                                                                scheduler=scheduler,logLoss=logLoss,threshold=threshold,typeTrain=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Model/GNN_stacking_0815.pickle', 'wb') as handle:\n",
    "    pickle.dump(bestWeight, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Model/GNN_stacking_0815.pickle', 'rb') as handle:\n",
    "    bestWeight = pickle.load(handle)\n",
    "\n",
    "model = GNN_multiHead_interleave_stacking(reuse,block,head,dim,layer,factor,edge_in4).to('cuda:0')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict test\n",
    "for type_i in range(8):\n",
    "    # load val data and type_id\n",
    "    with open(data.format('test').split('pickle')[0][:-1]+'_type_'+str(type_i)+'.pickle', 'rb') as handle:\n",
    "        test_data = pickle.load(handle)\n",
    "    test_list = [Data(**d) for d in test_data]\n",
    "    test_dl = DataLoader(test_list,batch_size,shuffle=False)\n",
    "\n",
    "    with open(data.format('test').split('pickle')[0][:-1]+'_id_type_'+str(type_i)+'.pickle', 'rb') as handle:\n",
    "        test_id = pickle.load(handle)\n",
    "\n",
    "    # load model\n",
    "    model.load_state_dict(bestWeight[type_i])\n",
    "\n",
    "    # predict\n",
    "    model.eval()\n",
    "    yhat_list = []\n",
    "    with torch.no_grad():\n",
    "        for data_torch in test_dl:\n",
    "            data_torch = data_torch.to('cuda:0')\n",
    "            yhat_list.append(model(data_torch,False,typeTrain=True))\n",
    "    yhat = torch.cat(yhat_list).cpu().detach().numpy()        \n",
    "\n",
    "    # join\n",
    "    assert yhat.shape[0]==test_id.shape[0],'yhat and test_id should have same shape'\n",
    "    submit_ = dict(zip(test_id,yhat))\n",
    "    test_df['type'+str(type_i)] = test_df.id.map(submit_)\n",
    "    #test_df['fold'+str(i)+'_type'+str(type_i)] = test_df.id.map(submit_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['scalar_coupling_constant'] = np.nanmean(test_df.iloc[:,5:],1)\n",
    "#test = test[['id','yhat']]\n",
    "test_df[['id','scalar_coupling_constant']].to_csv('../Submission/GNN_stacking_0815',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
