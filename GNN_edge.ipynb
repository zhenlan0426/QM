{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "from torch_geometric.data import Data,DataLoader\n",
    "from functions_refactor import *\n",
    "from pytorch_util import *\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model parameters\n",
    "reuse = False\n",
    "block = MEGNet_block\n",
    "head = feedforwardCombineHead_Update\n",
    "data = '../Data/{}_data_ACSF_expand.pickle'\n",
    "batch_size = 32\n",
    "dim = 128\n",
    "epochs = 20\n",
    "clip = 0.4\n",
    "layer1 = 3\n",
    "layer2 = 3\n",
    "factor = 2\n",
    "lr = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss: +0.250, val_loss: -0.430, \n",
      "train_vector: +3.07|+0.93|+0.11|-0.49|-0.49|+0.19|-0.53|-0.79, \n",
      "val_vector  : +0.61|-0.00|-0.29|-0.61|-1.02|-0.12|-0.91|-1.11\n",
      "\n",
      "epoch:1, train_loss: -0.531, val_loss: -0.723, \n",
      "train_vector: +0.67|+0.19|-0.39|-1.13|-1.09|-0.20|-1.07|-1.22, \n",
      "val_vector  : +0.36|-0.06|-0.55|-1.49|-1.25|-0.28|-1.22|-1.30\n",
      "\n",
      "epoch:2, train_loss: -0.717, val_loss: -0.800, \n",
      "train_vector: +0.44|-0.01|-0.55|-1.33|-1.30|-0.35|-1.23|-1.42, \n",
      "val_vector  : +0.23|+0.07|-0.71|-1.23|-1.41|-0.47|-1.38|-1.50\n",
      "\n",
      "epoch:3, train_loss: -0.824, val_loss: -0.914, \n",
      "train_vector: +0.32|-0.13|-0.64|-1.43|-1.41|-0.43|-1.33|-1.53, \n",
      "val_vector  : +0.33|-0.11|-0.78|-1.68|-1.42|-0.53|-1.48|-1.66\n",
      "\n",
      "epoch:4, train_loss: -0.903, val_loss: -0.956, \n",
      "train_vector: +0.25|-0.22|-0.72|-1.50|-1.50|-0.50|-1.40|-1.62, \n",
      "val_vector  : +0.54|-0.49|-0.80|-1.60|-1.57|-0.57|-1.49|-1.67\n",
      "\n",
      "epoch:5, train_loss: -0.962, val_loss: -1.054, \n",
      "train_vector: +0.19|-0.25|-0.77|-1.58|-1.57|-0.56|-1.47|-1.69, \n",
      "val_vector  : +0.21|-0.52|-0.88|-1.69|-1.64|-0.64|-1.56|-1.73\n",
      "\n",
      "epoch:6, train_loss: -1.022, val_loss: -1.133, \n",
      "train_vector: +0.13|-0.34|-0.83|-1.61|-1.63|-0.60|-1.53|-1.76, \n",
      "val_vector  : -0.02|-0.62|-0.90|-1.77|-1.62|-0.69|-1.67|-1.76\n",
      "\n",
      "epoch:7, train_loss: -1.066, val_loss: -1.137, \n",
      "train_vector: +0.10|-0.41|-0.86|-1.66|-1.68|-0.64|-1.57|-1.81, \n",
      "val_vector  : -0.09|-0.55|-0.98|-1.56|-1.73|-0.67|-1.67|-1.84\n",
      "\n",
      "epoch:8, train_loss: -1.109, val_loss: -1.167, \n",
      "train_vector: +0.05|-0.43|-0.91|-1.71|-1.73|-0.68|-1.61|-1.86, \n",
      "val_vector  : -0.20|-0.57|-1.01|-1.53|-1.64|-0.78|-1.71|-1.91\n",
      "\n",
      "epoch:9, train_loss: -1.146, val_loss: -1.121, \n",
      "train_vector: +0.03|-0.48|-0.94|-1.75|-1.77|-0.71|-1.65|-1.90, \n",
      "val_vector  : +0.05|-0.60|-1.02|-1.67|-1.84|-0.68|-1.39|-1.83\n",
      "\n",
      "epoch:10, train_loss: -1.170, val_loss: -1.203, \n",
      "train_vector: +0.01|-0.50|-0.97|-1.76|-1.79|-0.73|-1.67|-1.94, \n",
      "val_vector  : +0.13|-0.65|-1.06|-1.90|-1.73|-0.81|-1.66|-1.95\n",
      "\n",
      "epoch:11, train_loss: -1.204, val_loss: -1.217, \n",
      "train_vector: -0.02|-0.53|-1.00|-1.81|-1.83|-0.76|-1.70|-1.98, \n",
      "val_vector  : +0.32|-0.53|-1.08|-1.98|-1.89|-0.83|-1.80|-1.94\n",
      "\n",
      "epoch:12, train_loss: -1.232, val_loss: -1.268, \n",
      "train_vector: -0.05|-0.56|-1.03|-1.84|-1.86|-0.79|-1.73|-2.01, \n",
      "val_vector  : -0.24|-0.63|-1.10|-1.83|-1.82|-0.77|-1.76|-2.00\n",
      "\n",
      "epoch:13, train_loss: -1.250, val_loss: -1.309, \n",
      "train_vector: -0.05|-0.59|-1.05|-1.84|-1.88|-0.81|-1.75|-2.04, \n",
      "val_vector  : -0.27|-0.41|-1.11|-2.02|-1.92|-0.87|-1.84|-2.03\n",
      "\n",
      "epoch:14, train_loss: -1.286, val_loss: -1.236, \n",
      "train_vector: -0.09|-0.63|-1.08|-1.89|-1.91|-0.83|-1.78|-2.07, \n",
      "val_vector  : +0.06|-0.70|-0.98|-1.87|-1.89|-0.80|-1.67|-2.03\n",
      "\n",
      "epoch:15, train_loss: -1.299, val_loss: -1.283, \n",
      "train_vector: -0.10|-0.62|-1.09|-1.91|-1.93|-0.85|-1.80|-2.09, \n",
      "val_vector  : -0.26|-0.58|-1.18|-1.50|-1.94|-0.90|-1.85|-2.05\n",
      "\n",
      "epoch:16, train_loss: -1.321, val_loss: -1.337, \n",
      "train_vector: -0.13|-0.67|-1.11|-1.89|-1.96|-0.87|-1.82|-2.12, \n",
      "val_vector  : +0.14|-0.85|-1.16|-2.08|-1.95|-0.93|-1.77|-2.10\n",
      "\n",
      "epoch:17, train_loss: -1.342, val_loss: -1.265, \n",
      "train_vector: -0.14|-0.68|-1.13|-1.94|-1.97|-0.88|-1.84|-2.15, \n",
      "val_vector  : -0.31|+0.17|-1.17|-1.91|-1.97|-0.94|-1.90|-2.10\n",
      "\n",
      "epoch:18, train_loss: -1.359, val_loss: -1.349, \n",
      "train_vector: -0.15|-0.69|-1.15|-1.96|-2.00|-0.90|-1.85|-2.17, \n",
      "val_vector  : -0.23|-0.79|-1.23|-1.57|-2.01|-0.95|-1.90|-2.11\n",
      "\n",
      "epoch:19, train_loss: -1.383, val_loss: -1.345, \n",
      "train_vector: -0.17|-0.73|-1.17|-1.99|-2.02|-0.92|-1.87|-2.20, \n",
      "val_vector  : -0.30|-0.63|-1.24|-1.43|-2.09|-0.98|-1.98|-2.11\n",
      "\n",
      "Training completed in 1838.510727405548s\n"
     ]
    }
   ],
   "source": [
    "train_dl,val_dl = get_data(data,batch_size)\n",
    "\n",
    "model = GNN_edgeUpdate(reuse,block,head,dim,layer1,layer2,factor,**data_dict[data]).to('cuda:0')\n",
    "\n",
    "paras = trainable_parameter(model)\n",
    "opt = Adam(paras,lr=lr)\n",
    "\n",
    "model,train_loss_perType,val_loss_perType = train(opt,model,epochs,train_dl,val_dl,paras,clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(train_loss_perType,val_loss_perType,reuse,block,\\\n",
    "             head,data,batch_size,dim,clip,layer1,layer2,factor,epochs)\n",
    "save_model(model,opt,reuse,block,head,data,batch_size,dim,clip,layer1,layer2,factor,epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss: +0.342, val_loss: -0.065, \n",
      "train_vector: +4.23|+0.92|+0.10|-0.45|-0.58|+0.11|-0.64|-0.96, \n",
      "val_vector  : +3.92|+0.12|-0.29|-0.89|-0.97|-0.18|-0.99|-1.24\n",
      "\n",
      "epoch:1, train_loss: -0.261, val_loss: -0.644, \n",
      "train_vector: +2.65|+0.30|-0.34|-1.01|-1.09|-0.23|-1.06|-1.32, \n",
      "val_vector  : +0.58|-0.09|-0.52|-1.00|-1.14|-0.36|-1.21|-1.41\n",
      "\n",
      "epoch:2, train_loss: -0.631, val_loss: -0.785, \n",
      "train_vector: +0.88|+0.14|-0.51|-1.24|-1.28|-0.36|-1.20|-1.48, \n",
      "val_vector  : +0.61|-0.26|-0.65|-1.47|-1.35|-0.43|-1.18|-1.55\n",
      "\n",
      "epoch:3, train_loss: -0.747, val_loss: -0.930, \n",
      "train_vector: +0.80|-0.04|-0.62|-1.36|-1.40|-0.45|-1.31|-1.59, \n",
      "val_vector  : +0.23|-0.13|-0.75|-1.61|-1.47|-0.54|-1.47|-1.69\n",
      "\n",
      "epoch:4, train_loss: -0.832, val_loss: -0.942, \n",
      "train_vector: +0.75|-0.17|-0.69|-1.47|-1.50|-0.52|-1.39|-1.67, \n",
      "val_vector  : +0.29|-0.09|-0.75|-1.62|-1.55|-0.59|-1.48|-1.74\n",
      "\n",
      "epoch:5, train_loss: -0.887, val_loss: -1.066, \n",
      "train_vector: +0.73|-0.20|-0.76|-1.54|-1.56|-0.57|-1.45|-1.75, \n",
      "val_vector  : +0.31|-0.57|-0.85|-1.74|-1.66|-0.65|-1.55|-1.81\n",
      "\n",
      "epoch:6, train_loss: -0.936, val_loss: -1.085, \n",
      "train_vector: +0.71|-0.27|-0.81|-1.60|-1.61|-0.62|-1.49|-1.81, \n",
      "val_vector  : +0.15|-0.36|-0.90|-1.70|-1.71|-0.70|-1.60|-1.86\n",
      "\n",
      "epoch:7, train_loss: -0.981, val_loss: -1.165, \n",
      "train_vector: +0.68|-0.31|-0.85|-1.67|-1.66|-0.66|-1.52|-1.85, \n",
      "val_vector  : +0.15|-0.68|-0.94|-1.85|-1.72|-0.73|-1.68|-1.88\n",
      "\n",
      "epoch:8, train_loss: -1.011, val_loss: -1.116, \n",
      "train_vector: +0.67|-0.34|-0.89|-1.69|-1.70|-0.69|-1.56|-1.90, \n",
      "val_vector  : +0.30|-0.32|-0.91|-1.92|-1.70|-0.77|-1.67|-1.94\n",
      "\n",
      "epoch:9, train_loss: -1.050, val_loss: -1.102, \n",
      "train_vector: +0.65|-0.41|-0.93|-1.72|-1.74|-0.72|-1.60|-1.94, \n",
      "val_vector  : +0.28|-0.27|-0.99|-1.70|-1.71|-0.79|-1.70|-1.94\n",
      "\n",
      "epoch:10, train_loss: -1.084, val_loss: -1.184, \n",
      "train_vector: +0.60|-0.43|-0.96|-1.77|-1.78|-0.75|-1.62|-1.97, \n",
      "val_vector  : +0.06|-0.30|-1.06|-1.73|-1.86|-0.82|-1.76|-2.01\n",
      "\n",
      "epoch:11, train_loss: -1.117, val_loss: -1.102, \n",
      "train_vector: +0.56|-0.47|-0.99|-1.81|-1.81|-0.77|-1.64|-2.00, \n",
      "val_vector  : +0.05|+0.25|-1.03|-1.91|-1.70|-0.83|-1.61|-2.02\n",
      "\n",
      "epoch:12, train_loss: -1.149, val_loss: -1.220, \n",
      "train_vector: +0.51|-0.50|-1.01|-1.83|-1.84|-0.79|-1.68|-2.04, \n",
      "val_vector  : +0.03|-0.70|-1.09|-1.57|-1.78|-0.84|-1.78|-2.04\n",
      "\n",
      "epoch:13, train_loss: -1.181, val_loss: -1.227, \n",
      "train_vector: +0.43|-0.54|-1.04|-1.85|-1.87|-0.81|-1.70|-2.07, \n",
      "val_vector  : +0.39|-0.52|-1.06|-2.09|-1.86|-0.87|-1.75|-2.04\n",
      "\n",
      "epoch:14, train_loss: -1.201, val_loss: -1.311, \n",
      "train_vector: +0.38|-0.52|-1.06|-1.86|-1.89|-0.84|-1.73|-2.09, \n",
      "val_vector  : +0.08|-0.69|-1.15|-2.01|-1.97|-0.90|-1.74|-2.10\n",
      "\n",
      "epoch:15, train_loss: -1.235, val_loss: -1.343, \n",
      "train_vector: +0.31|-0.58|-1.08|-1.89|-1.91|-0.85|-1.75|-2.12, \n",
      "val_vector  : +0.00|-0.75|-1.17|-2.02|-1.94|-0.90|-1.86|-2.12\n",
      "\n",
      "epoch:16, train_loss: -1.267, val_loss: -1.321, \n",
      "train_vector: +0.24|-0.62|-1.10|-1.92|-1.94|-0.87|-1.77|-2.14, \n",
      "val_vector  : +0.03|-0.63|-1.15|-2.05|-1.93|-0.92|-1.82|-2.10\n",
      "\n",
      "epoch:17, train_loss: -1.284, val_loss: -1.322, \n",
      "train_vector: +0.21|-0.62|-1.12|-1.95|-1.96|-0.89|-1.78|-2.16, \n",
      "val_vector  : +0.25|-0.88|-1.18|-1.94|-1.98|-0.93|-1.78|-2.13\n",
      "\n",
      "epoch:18, train_loss: -1.302, val_loss: -1.443, \n",
      "train_vector: +0.17|-0.63|-1.13|-1.95|-1.98|-0.90|-1.80|-2.19, \n",
      "val_vector  : -0.13|-0.94|-1.21|-2.18|-1.98|-0.97|-1.93|-2.19\n",
      "\n",
      "epoch:19, train_loss: -1.323, val_loss: -1.468, \n",
      "train_vector: +0.14|-0.65|-1.15|-1.95|-2.01|-0.92|-1.82|-2.21, \n",
      "val_vector  : -0.25|-1.03|-1.20|-2.16|-2.03|-0.97|-1.94|-2.16\n",
      "\n",
      "Training completed in 1666.8049392700195s\n"
     ]
    }
   ],
   "source": [
    "# this is using old definition of GNN_edgeUpdate shown below\n",
    "train_dl,val_dl = get_data(data,batch_size)\n",
    "\n",
    "model = GNN_edgeUpdate(reuse,block,dim,layer1,layer2,factor,**data_dict[data]).to('cuda:0')\n",
    "\n",
    "paras = trainable_parameter(model)\n",
    "opt = Adam(paras,lr=lr)\n",
    "\n",
    "model,train_loss_perType,val_loss_perType = train(opt,model,epochs,train_dl,val_dl,paras,clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(train_loss_perType,val_loss_perType,reuse,block,\\\n",
    "             head,data,batch_size,dim,clip,layer1,layer2,factor,epochs)\n",
    "save_model(model,opt,reuse,block,head,data,batch_size,dim,clip,layer1,layer2,factor,epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continue training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl,val_dl = get_data(data,batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN_edgeUpdate(torch.nn.Module):\n",
    "\n",
    "    def __init__(self,reuse,block,dim,layer1,layer2,factor,\\\n",
    "                 node_in,edge_in,edge_in4,edge_in3=8):\n",
    "        # block,head are nn.Module\n",
    "        # node_in,edge_in are dim for bonding and edge_in4,edge_in3 for coupling\n",
    "        super(GNN_edgeUpdate, self).__init__()\n",
    "        self.lin_node = Sequential(BatchNorm1d(node_in),Linear(node_in, dim*factor),LeakyReLU(), \\\n",
    "                                   BatchNorm1d(dim*factor),Linear(dim*factor, dim),LeakyReLU())\n",
    "\n",
    "        self.edge1 = Sequential(BatchNorm1d(edge_in),Linear(edge_in, dim*factor),LeakyReLU(), \\\n",
    "                                   BatchNorm1d(dim*factor),Linear(dim*factor, dim),LeakyReLU())\n",
    "\n",
    "        self.edge2 = Sequential(BatchNorm1d(edge_in4+edge_in3),Linear(edge_in4+edge_in3, dim*factor),LeakyReLU(), \\\n",
    "                                   BatchNorm1d(dim*factor),Linear(dim*factor, dim),LeakyReLU())        \n",
    "        if reuse:\n",
    "            self.conv1 = block(dim=dim,edge_dim=edge_in)\n",
    "            self.conv2 = block(dim=dim,edge_dim=edge_in3+edge_in4)\n",
    "        else:\n",
    "            self.conv1 = nn.ModuleList([block(dim=dim) for _ in range(layer1)])\n",
    "            self.conv2 = nn.ModuleList([block(dim=dim) for _ in range(layer2)])            \n",
    "        \n",
    "        self.head = Sequential(Linear(dim, dim*factor),ReLU(), \\\n",
    "                               Linear(dim*factor, 1))\n",
    "        \n",
    "    def forward(self, data,IsTrain=False,typeTrain=False):\n",
    "        out = self.lin_node(data.x)\n",
    "        # edge_*3 only does not repeat for undirected graph. Hence need to add (j,i) to (i,j) in edges\n",
    "        edge_index3 = torch.cat([data.edge_index3,data.edge_index3[[1,0]]],1)\n",
    "        n = data.edge_attr3.shape[0]\n",
    "        temp_ = self.edge2(torch.cat([data.edge_attr3,data.edge_attr4],1))\n",
    "        edge_attr3 = torch.cat([temp_,temp_],0)\n",
    "        \n",
    "        edge_attr = self.edge1(data.edge_attr)\n",
    "        for conv in self.conv1:\n",
    "            out,edge_attr = conv(out,data.edge_index,edge_attr)\n",
    "        \n",
    "        for conv in self.conv2:\n",
    "            out,edge_attr3 = conv(out,edge_index3,edge_attr3)    \n",
    "        \n",
    "        edge_attr3 = edge_attr3[:n]\n",
    "        if typeTrain:\n",
    "            if IsTrain:\n",
    "                y = data.y[data.type_attr]\n",
    "            edge_attr3 = edge_attr3[data.type_attr]\n",
    "            edge_attr3_old = data.edge_attr3[data.type_attr]\n",
    "        else:\n",
    "            if IsTrain:\n",
    "                y = data.y\n",
    "            edge_attr3_old = data.edge_attr3\n",
    "            \n",
    "        yhat = self.head(edge_attr3).squeeze(1)\n",
    "        \n",
    "        if IsTrain:\n",
    "            k = torch.sum(edge_attr3_old,0)\n",
    "            nonzeroIndex = torch.nonzero(k).squeeze(1)\n",
    "            abs_ = torch.abs(y-yhat).unsqueeze(1)\n",
    "            loss_perType = torch.zeros(8,device='cuda:0')\n",
    "            loss_perType[nonzeroIndex] = torch.log(torch.sum(abs_ * edge_attr3_old[:,nonzeroIndex],0)/k[nonzeroIndex])\n",
    "            loss = torch.sum(loss_perType)/nonzeroIndex.shape[0]\n",
    "            return loss,loss_perType\n",
    "        else:\n",
    "            return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GNN_edgeUpdate(reuse,block,dim,layer1,layer2,factor,**data_dict[data]).to('cuda:0')\n",
    "\n",
    "paras = trainable_parameter(model)\n",
    "opt = Adam(paras,lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"False_<class 'functions_refactor.MEGNet_block'>_None__data_ACSF_expand.pickle_32_128_0.4_3_3_2_20_base.tar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('../Model/'+file_name)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "opt.load_state_dict(checkpoint['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss: -1.343, val_loss: -1.381, \n",
      "train_vector: +0.11|-0.69|-1.17|-1.98|-2.02|-0.94|-1.84|-2.22, \n",
      "val_vector  : +0.07|-0.75|-1.23|-2.06|-1.96|-0.99|-1.94|-2.20\n",
      "\n",
      "epoch:1, train_loss: -1.356, val_loss: -1.422, \n",
      "train_vector: +0.10|-0.68|-1.18|-1.99|-2.03|-0.95|-1.86|-2.25, \n",
      "val_vector  : -0.11|-0.88|-1.24|-2.09|-2.03|-0.96|-1.89|-2.18\n",
      "\n",
      "epoch:2, train_loss: -1.382, val_loss: -1.394, \n",
      "train_vector: +0.05|-0.74|-1.20|-2.01|-2.05|-0.96|-1.87|-2.26, \n",
      "val_vector  : -0.08|-0.97|-1.27|-1.57|-2.05|-1.01|-1.99|-2.21\n",
      "\n",
      "epoch:3, train_loss: -1.399, val_loss: -1.469, \n",
      "train_vector: +0.03|-0.76|-1.21|-2.03|-2.07|-0.97|-1.89|-2.28, \n",
      "val_vector  : -0.13|-0.96|-1.28|-2.12|-2.05|-1.03|-2.00|-2.19\n",
      "\n",
      "epoch:4, train_loss: -1.415, val_loss: -1.440, \n",
      "train_vector: -0.00|-0.75|-1.23|-2.04|-2.10|-0.99|-1.91|-2.30, \n",
      "val_vector  : -0.33|-0.50|-1.26|-2.15|-2.00|-1.03|-2.01|-2.24\n",
      "\n",
      "epoch:5, train_loss: -1.425, val_loss: -1.465, \n",
      "train_vector: -0.00|-0.76|-1.24|-2.07|-2.11|-0.99|-1.92|-2.31, \n",
      "val_vector  : +0.21|-1.05|-1.30|-2.12|-2.12|-1.04|-2.02|-2.28\n",
      "\n",
      "epoch:6, train_loss: -1.447, val_loss: -1.417, \n",
      "train_vector: -0.04|-0.80|-1.25|-2.09|-2.12|-1.01|-1.93|-2.33, \n",
      "val_vector  : -0.18|-0.62|-1.26|-2.01|-1.96|-1.05|-1.97|-2.28\n",
      "\n",
      "epoch:7, train_loss: -1.463, val_loss: -1.480, \n",
      "train_vector: -0.06|-0.82|-1.26|-2.11|-2.14|-1.02|-1.95|-2.35, \n",
      "val_vector  : -0.19|-0.91|-1.30|-2.08|-2.12|-1.08|-1.87|-2.30\n",
      "\n",
      "epoch:8, train_loss: -1.427, val_loss: -1.476, \n",
      "train_vector: -0.04|-0.63|-1.25|-2.09|-2.13|-1.01|-1.94|-2.33, \n",
      "val_vector  : -0.29|-0.60|-1.33|-2.09|-2.14|-1.07|-2.00|-2.28\n",
      "\n",
      "epoch:9, train_loss: -1.483, val_loss: -1.545, \n",
      "train_vector: -0.09|-0.83|-1.29|-2.12|-2.17|-1.04|-1.97|-2.37, \n",
      "val_vector  : -0.16|-1.02|-1.33|-2.29|-2.16|-1.07|-2.02|-2.31\n",
      "\n",
      "Training completed in 828.8543310165405s\n"
     ]
    }
   ],
   "source": [
    "model,train_loss_perType,val_loss_perType = train(opt,model,10,train_dl,val_dl,paras,clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss: -1.494, val_loss: -1.456, \n",
      "train_vector: -0.10|-0.84|-1.30|-2.12|-2.17|-1.05|-1.98|-2.39, \n",
      "val_vector  : +0.24|-0.93|-1.35|-2.01|-2.17|-1.08|-2.02|-2.33\n",
      "\n",
      "epoch:1, train_loss: -1.507, val_loss: -1.568, \n",
      "train_vector: -0.12|-0.86|-1.31|-2.13|-2.19|-1.06|-1.99|-2.40, \n",
      "val_vector  : -0.22|-1.14|-1.35|-2.20|-2.14|-1.10|-2.08|-2.31\n",
      "\n",
      "epoch:2, train_loss: -1.519, val_loss: -1.583, \n",
      "train_vector: -0.14|-0.87|-1.31|-2.16|-2.20|-1.06|-2.00|-2.41, \n",
      "val_vector  : -0.15|-1.19|-1.37|-2.29|-2.12|-1.10|-2.11|-2.35\n",
      "\n",
      "epoch:3, train_loss: -1.532, val_loss: -1.603, \n",
      "train_vector: -0.14|-0.90|-1.33|-2.16|-2.22|-1.07|-2.02|-2.42, \n",
      "val_vector  : -0.44|-0.93|-1.39|-2.33|-2.18|-1.12|-2.08|-2.35\n",
      "\n",
      "epoch:4, train_loss: -1.539, val_loss: -1.499, \n",
      "train_vector: -0.16|-0.88|-1.34|-2.17|-2.22|-1.08|-2.03|-2.44, \n",
      "val_vector  : -0.04|-0.47|-1.39|-2.35|-2.19|-1.11|-2.10|-2.34\n",
      "\n",
      "epoch:5, train_loss: -1.548, val_loss: -1.523, \n",
      "train_vector: -0.16|-0.88|-1.34|-2.19|-2.24|-1.09|-2.03|-2.45, \n",
      "val_vector  : -0.04|-0.70|-1.39|-2.32|-2.15|-1.12|-2.09|-2.37\n",
      "\n",
      "epoch:6, train_loss: -1.553, val_loss: -1.567, \n",
      "train_vector: -0.17|-0.89|-1.35|-2.18|-2.24|-1.10|-2.04|-2.46, \n",
      "val_vector  : -0.43|-0.85|-1.37|-2.22|-2.10|-1.12|-2.13|-2.32\n",
      "\n",
      "epoch:7, train_loss: -1.570, val_loss: -1.615, \n",
      "train_vector: -0.19|-0.93|-1.36|-2.19|-2.26|-1.11|-2.05|-2.47, \n",
      "val_vector  : -0.13|-1.24|-1.41|-2.22|-2.25|-1.14|-2.16|-2.37\n",
      "\n",
      "epoch:8, train_loss: -1.576, val_loss: -1.604, \n",
      "train_vector: -0.19|-0.92|-1.37|-2.21|-2.26|-1.11|-2.06|-2.48, \n",
      "val_vector  : -0.36|-0.82|-1.42|-2.41|-2.19|-1.15|-2.11|-2.37\n",
      "\n",
      "epoch:9, train_loss: -1.586, val_loss: -1.621, \n",
      "train_vector: -0.20|-0.94|-1.38|-2.21|-2.28|-1.12|-2.07|-2.49, \n",
      "val_vector  : -0.12|-1.17|-1.43|-2.31|-2.26|-1.16|-2.14|-2.38\n",
      "\n",
      "Training completed in 828.2205407619476s\n"
     ]
    }
   ],
   "source": [
    "model,train_loss_perType,val_loss_perType = train(opt,model,10,train_dl,val_dl,paras,clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss: -1.593, val_loss: -1.631, \n",
      "train_vector: -0.21|-0.96|-1.38|-2.23|-2.27|-1.12|-2.07|-2.50, \n",
      "val_vector  : -0.32|-1.06|-1.40|-2.37|-2.25|-1.16|-2.11|-2.38\n",
      "\n",
      "epoch:1, train_loss: -1.597, val_loss: -1.569, \n",
      "train_vector: -0.22|-0.94|-1.39|-2.21|-2.29|-1.13|-2.08|-2.51, \n",
      "val_vector  : -0.21|-0.65|-1.43|-2.38|-2.17|-1.17|-2.17|-2.38\n",
      "\n",
      "epoch:2, train_loss: -1.608, val_loss: -1.581, \n",
      "train_vector: -0.24|-0.98|-1.39|-2.24|-2.29|-1.14|-2.09|-2.51, \n",
      "val_vector  : +0.19|-1.08|-1.42|-2.34|-2.24|-1.17|-2.19|-2.39\n",
      "\n",
      "epoch:3, train_loss: -1.615, val_loss: -1.624, \n",
      "train_vector: -0.24|-0.98|-1.40|-2.23|-2.31|-1.14|-2.09|-2.52, \n",
      "val_vector  : -0.39|-1.15|-1.43|-2.37|-2.17|-1.17|-1.92|-2.40\n",
      "\n",
      "epoch:4, train_loss: -1.620, val_loss: -1.612, \n",
      "train_vector: -0.24|-0.96|-1.41|-2.24|-2.31|-1.15|-2.11|-2.54, \n",
      "val_vector  : -0.45|-0.78|-1.43|-2.26|-2.24|-1.17|-2.16|-2.41\n",
      "\n",
      "epoch:5, train_loss: -1.627, val_loss: -1.453, \n",
      "train_vector: -0.24|-0.98|-1.42|-2.25|-2.32|-1.16|-2.11|-2.54, \n",
      "val_vector  : +0.81|-0.72|-1.43|-2.42|-2.23|-1.18|-2.05|-2.41\n",
      "\n",
      "epoch:6, train_loss: -1.641, val_loss: -1.655, \n",
      "train_vector: -0.27|-1.01|-1.42|-2.25|-2.34|-1.16|-2.12|-2.56, \n",
      "val_vector  : -0.09|-1.22|-1.43|-2.46|-2.28|-1.19|-2.14|-2.43\n",
      "\n",
      "epoch:7, train_loss: -1.642, val_loss: -1.649, \n",
      "train_vector: -0.25|-1.00|-1.43|-2.26|-2.34|-1.17|-2.12|-2.56, \n",
      "val_vector  : -0.18|-1.21|-1.44|-2.25|-2.32|-1.19|-2.16|-2.44\n",
      "\n",
      "epoch:8, train_loss: -1.652, val_loss: -1.522, \n",
      "train_vector: -0.27|-1.02|-1.44|-2.27|-2.35|-1.18|-2.13|-2.57, \n",
      "val_vector  : +0.07|-0.61|-1.47|-2.37|-2.21|-1.20|-2.02|-2.37\n",
      "\n",
      "epoch:9, train_loss: -1.655, val_loss: -1.572, \n",
      "train_vector: -0.26|-1.00|-1.44|-2.28|-2.36|-1.18|-2.14|-2.58, \n",
      "val_vector  : -0.34|-0.30|-1.48|-2.42|-2.29|-1.20|-2.12|-2.43\n",
      "\n",
      "Training completed in 829.4752721786499s\n"
     ]
    }
   ],
   "source": [
    "model,train_loss_perType,val_loss_perType = train(opt,model,10,train_dl,val_dl,paras,clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(train_loss_perType,val_loss_perType,reuse,block,\\\n",
    "             'None',data,batch_size,dim,clip,layer1,layer2,factor,epochs)\n",
    "save_model(model,opt,reuse,block,'None',data,batch_size,dim,clip,layer1,layer2,factor,epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train on each type based on pre-trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_type =1e-4/4\n",
    "epochs_type = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GNN_edgeUpdate(reuse,block,dim,layer1,layer2,factor,**data_dict[data]).to('cuda:0')\n",
    "\n",
    "paras = trainable_parameter(model)\n",
    "opt = Adam(paras,lr=lr_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"False_<class 'functions_refactor.MEGNet_block'>_None__data_ACSF_expand.pickle_32_128_0.4_3_3_2_20_base.tar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training type: 0\n",
      "epoch:0, train_loss: -0.053, val_loss: +0.336, \n",
      "train_vector: -0.05|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.34|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:1, train_loss: -0.195, val_loss: -0.401, \n",
      "train_vector: -0.19|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00, \n",
      "val_vector  : -0.40|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:2, train_loss: -0.275, val_loss: -0.384, \n",
      "train_vector: -0.27|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00, \n",
      "val_vector  : -0.38|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:3, train_loss: -0.341, val_loss: -0.283, \n",
      "train_vector: -0.34|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00, \n",
      "val_vector  : -0.28|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:4, train_loss: -0.381, val_loss: -0.204, \n",
      "train_vector: -0.38|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00, \n",
      "val_vector  : -0.20|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-deb6fcee9be6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nTraining type: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loss_perType\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_loss_perType\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_dl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparas\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     save_results(train_loss_perType,val_loss_perType,reuse,block,\\\n",
      "\u001b[0;32m~/Desktop/kaggle/QM/Code/functions_refactor.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(opt, model, epochs, train_dl, val_dl, paras, clip, typeTrain, train_loss_list, val_loss_list)\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_perType\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtypeTrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 679\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    680\u001b[0m             \u001b[0mclip_grad_value_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparas\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m             \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(8):\n",
    "    data_type = '../Data/{}_data_ACSF_expand_type_'+str(i)+'.pickle'\n",
    "    train_dl,val_dl = get_data(data_type,batch_size)\n",
    "\n",
    "    checkpoint = torch.load('../Model/'+file_name)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    opt.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "    for para in opt.param_groups:\n",
    "        para['lr'] = lr_type\n",
    "    \n",
    "    print('\\nTraining type: {}'.format(i))\n",
    "    model,train_loss_perType,val_loss_perType = train(opt,model,epochs_type,train_dl,val_dl,paras,clip,True)\n",
    "\n",
    "    save_results(train_loss_perType,val_loss_perType,reuse,block,\\\n",
    "                 head,data,batch_size,dim,clip,layer1,layer2,factor,epochs,'type_'+str(i))\n",
    "\n",
    "    save_model(model,opt,reuse,block,head,data,batch_size,dim,clip,layer1,layer2,factor,epochs,'type_'+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train on each type from start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "head = MEGNet_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_type =1e-4\n",
    "epochs_type = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training type: 0\n",
      "epoch:0, train_loss: +1.045, val_loss: +0.319, \n",
      "train_vector: +1.05|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.32|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:1, train_loss: +0.589, val_loss: +0.739, \n",
      "train_vector: +0.59|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.74|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-be5a8c87c49d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nTraining type: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loss_perType\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_loss_perType\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_dl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparas\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     save_results(train_loss_perType,val_loss_perType,reuse,block,\\\n",
      "\u001b[0;32m~/Desktop/kaggle/QM/Code/functions_refactor.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(opt, model, epochs, train_dl, val_dl, paras, clip, typeTrain, train_loss_list, val_loss_list)\u001b[0m\n\u001b[1;32m    660\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_perType\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtypeTrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m             \u001b[0mclip_grad_value_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparas\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m             \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(8):\n",
    "    # load type data\n",
    "    data_type = '../Data/{}_data_ACSF_expand_type_'+str(i)+'.pickle'\n",
    "    train_dl,val_dl = get_data(data_type,batch_size)\n",
    "    \n",
    "    # init model\n",
    "    model = GNN_edgeUpdate(reuse,block,dim,layer1,layer2,factor,**data_dict[data]).to('cuda:0')\n",
    "    paras = trainable_parameter(model)\n",
    "    opt = Adam(paras,lr=lr_type)\n",
    "    \n",
    "    print('\\nTraining type: {}'.format(i))\n",
    "    model,train_loss_perType,val_loss_perType = train(opt,model,epochs_type,train_dl,val_dl,paras,clip,True)\n",
    "\n",
    "    save_results(train_loss_perType,val_loss_perType,reuse,block,\\\n",
    "                 head,data,batch_size,dim,clip,layer1,layer2,factor,epochs,'type_'+str(i)+'_start')\n",
    "\n",
    "    save_model(model,opt,reuse,block,head,data,batch_size,dim,clip,layer1,layer2,factor,epochs,'type_'+str(i)+'_start')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training type: 0\n",
      "epoch:0, train_loss: +1.114, val_loss: +0.828, \n",
      "train_vector: +1.11|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.83|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:1, train_loss: +0.500, val_loss: +0.160, \n",
      "train_vector: +0.50|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.16|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:2, train_loss: +0.321, val_loss: +0.162, \n",
      "train_vector: +0.32|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.16|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:3, train_loss: +0.230, val_loss: +0.028, \n",
      "train_vector: +0.23|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.03|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:4, train_loss: +0.142, val_loss: +0.135, \n",
      "train_vector: +0.14|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.13|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:5, train_loss: +0.070, val_loss: -0.087, \n",
      "train_vector: +0.07|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00, \n",
      "val_vector  : -0.09|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:6, train_loss: +0.025, val_loss: +0.217, \n",
      "train_vector: +0.02|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.22|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:7, train_loss: -0.001, val_loss: -0.227, \n",
      "train_vector: -0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00, \n",
      "val_vector  : -0.23|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:8, train_loss: -0.066, val_loss: -0.238, \n",
      "train_vector: -0.07|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00, \n",
      "val_vector  : -0.24|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "    model = GNN_edgeUpdate(reuse,block,dim,layer1,layer2,factor,**data_dict[data]).to('cuda:0')\n",
    "    paras = trainable_parameter(model)\n",
    "    opt = Adam(paras,lr=lr_type)\n",
    "    \n",
    "    print('\\nTraining type: {}'.format(i))\n",
    "    model,train_loss_perType,val_loss_perType = train(opt,model,epochs_type,train_dl,val_dl,paras,clip,True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### two stage bigger head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_type =1e-4/2\n",
    "epochs_type = 10\n",
    "file_name = \"False_<class 'functions_refactor.schnet_block'>_<class 'functions_refactor.cat3Head'>__data_ACSF_expand.pickle_32_128_2_2_2_2_20_base.tar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training type: 0\n",
      "\n",
      "Training head\n",
      "epoch:0, train_loss: +0.589, val_loss: +0.061, \n",
      "train_vector: +0.59|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.06|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:1, train_loss: +0.008, val_loss: +0.214, \n",
      "train_vector: +0.01|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.21|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:2, train_loss: -0.005, val_loss: +0.116, \n",
      "train_vector: -0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.12|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:3, train_loss: -0.008, val_loss: +0.121, \n",
      "train_vector: -0.01|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.12|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:4, train_loss: -0.010, val_loss: +0.239, \n",
      "train_vector: -0.01|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.24|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00\n",
      "\n",
      "Training completed in 85.70982599258423s\n",
      "\n",
      "Training all\n",
      "epoch:5, train_loss: +0.050, val_loss: +0.155, \n",
      "train_vector: +0.05|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.15|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:6, train_loss: -0.012, val_loss: -0.143, \n",
      "train_vector: -0.01|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00, \n",
      "val_vector  : -0.14|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:7, train_loss: -0.050, val_loss: +0.034, \n",
      "train_vector: -0.05|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.03|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:8, train_loss: -0.095, val_loss: -0.247, \n",
      "train_vector: -0.09|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00, \n",
      "val_vector  : -0.25|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:9, train_loss: -0.113, val_loss: -0.093, \n",
      "train_vector: -0.11|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00, \n",
      "val_vector  : -0.09|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:10, train_loss: -0.148, val_loss: -0.185, \n",
      "train_vector: -0.15|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00, \n",
      "val_vector  : -0.19|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:11, train_loss: -0.163, val_loss: -0.129, \n",
      "train_vector: -0.16|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00, \n",
      "val_vector  : -0.13|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:12, train_loss: -0.185, val_loss: +0.175, \n",
      "train_vector: -0.19|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.18|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:13, train_loss: -0.210, val_loss: -0.260, \n",
      "train_vector: -0.21|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00, \n",
      "val_vector  : -0.26|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:14, train_loss: -0.226, val_loss: -0.156, \n",
      "train_vector: -0.23|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00, \n",
      "val_vector  : -0.16|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00\n",
      "\n",
      "Training completed in 377.3226683139801s\n",
      "\n",
      "Training type: 1\n",
      "\n",
      "Training head\n",
      "epoch:0, train_loss: +0.832, val_loss: -0.475, \n",
      "train_vector: +0.00|+0.83|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.00|-0.47|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:1, train_loss: -0.307, val_loss: -0.487, \n",
      "train_vector: +0.00|-0.31|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.00|-0.49|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:2, train_loss: -0.381, val_loss: -0.612, \n",
      "train_vector: +0.00|-0.38|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.00|-0.61|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:3, train_loss: -0.439, val_loss: -0.491, \n",
      "train_vector: +0.00|-0.44|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.00|-0.49|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:4, train_loss: -0.482, val_loss: -0.450, \n",
      "train_vector: +0.00|-0.48|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.00|-0.45|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00\n",
      "\n",
      "Training completed in 29.753875255584717s\n",
      "\n",
      "Training all\n",
      "epoch:5, train_loss: -0.593, val_loss: -0.850, \n",
      "train_vector: +0.00|-0.59|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.00|-0.85|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:6, train_loss: -0.745, val_loss: -0.686, \n",
      "train_vector: +0.00|-0.74|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.00|-0.69|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:7, train_loss: -0.769, val_loss: -0.298, \n",
      "train_vector: +0.00|-0.77|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.00|-0.30|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:8, train_loss: -0.836, val_loss: -0.582, \n",
      "train_vector: +0.00|-0.84|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.00|-0.58|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:9, train_loss: -0.817, val_loss: -1.131, \n",
      "train_vector: +0.00|-0.82|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.00|-1.13|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:10, train_loss: -0.890, val_loss: -1.165, \n",
      "train_vector: +0.00|-0.89|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.00|-1.16|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:11, train_loss: -0.864, val_loss: -0.995, \n",
      "train_vector: +0.00|-0.86|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.00|-0.99|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:12, train_loss: -0.887, val_loss: -0.762, \n",
      "train_vector: +0.00|-0.89|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.00|-0.76|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:13, train_loss: -0.921, val_loss: -1.242, \n",
      "train_vector: +0.00|-0.92|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.00|-1.24|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:14, train_loss: -0.957, val_loss: -1.120, \n",
      "train_vector: +0.00|-0.96|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.00|-1.12|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00\n",
      "\n",
      "Training completed in 130.74536728858948s\n",
      "\n",
      "Training type: 2\n",
      "\n",
      "Training head\n",
      "epoch:0, train_loss: -0.454, val_loss: -0.591, \n",
      "train_vector: +0.00|+0.00|-0.45|+0.00|+0.00|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.00|+0.00|-0.59|+0.00|+0.00|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:1, train_loss: -0.625, val_loss: -0.609, \n",
      "train_vector: +0.00|+0.00|-0.62|+0.00|+0.00|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.00|+0.00|-0.61|+0.00|+0.00|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:2, train_loss: -0.640, val_loss: -0.642, \n",
      "train_vector: +0.00|+0.00|-0.64|+0.00|+0.00|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.00|+0.00|-0.64|+0.00|+0.00|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:3, train_loss: -0.651, val_loss: -0.643, \n",
      "train_vector: +0.00|+0.00|-0.65|+0.00|+0.00|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.00|+0.00|-0.64|+0.00|+0.00|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:4, train_loss: -0.659, val_loss: -0.676, \n",
      "train_vector: +0.00|+0.00|-0.66|+0.00|+0.00|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.00|+0.00|-0.68|+0.00|+0.00|+0.00|+0.00|+0.00\n",
      "\n",
      "Training completed in 90.99793410301208s\n",
      "\n",
      "Training all\n",
      "epoch:5, train_loss: -0.702, val_loss: -0.810, \n",
      "train_vector: +0.00|+0.00|-0.70|+0.00|+0.00|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.00|+0.00|-0.81|+0.00|+0.00|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:6, train_loss: -0.799, val_loss: -0.884, \n",
      "train_vector: +0.00|+0.00|-0.80|+0.00|+0.00|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.00|+0.00|-0.88|+0.00|+0.00|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:7, train_loss: -0.867, val_loss: -0.869, \n",
      "train_vector: +0.00|+0.00|-0.87|+0.00|+0.00|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.00|+0.00|-0.87|+0.00|+0.00|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:8, train_loss: -0.921, val_loss: -0.980, \n",
      "train_vector: +0.00|+0.00|-0.92|+0.00|+0.00|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.00|+0.00|-0.98|+0.00|+0.00|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:9, train_loss: -0.970, val_loss: -1.036, \n",
      "train_vector: +0.00|+0.00|-0.97|+0.00|+0.00|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.00|+0.00|-1.04|+0.00|+0.00|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:10, train_loss: -1.008, val_loss: -1.064, \n",
      "train_vector: +0.00|+0.00|-1.01|+0.00|+0.00|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.00|+0.00|-1.06|+0.00|+0.00|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:11, train_loss: -1.045, val_loss: -1.077, \n",
      "train_vector: +0.00|+0.00|-1.05|+0.00|+0.00|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.00|+0.00|-1.08|+0.00|+0.00|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:12, train_loss: -1.078, val_loss: -1.132, \n",
      "train_vector: +0.00|+0.00|-1.08|+0.00|+0.00|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.00|+0.00|-1.13|+0.00|+0.00|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:13, train_loss: -1.106, val_loss: -1.132, \n",
      "train_vector: +0.00|+0.00|-1.11|+0.00|+0.00|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.00|+0.00|-1.13|+0.00|+0.00|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:14, train_loss: -1.138, val_loss: -1.168, \n",
      "train_vector: +0.00|+0.00|-1.14|+0.00|+0.00|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.00|+0.00|-1.17|+0.00|+0.00|+0.00|+0.00|+0.00\n",
      "\n",
      "Training completed in 394.71592378616333s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training type: 3\n",
      "\n",
      "Training head\n",
      "epoch:0, train_loss: -1.242, val_loss: -1.765, \n",
      "train_vector: +0.00|+0.00|+0.00|-1.24|+0.00|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.00|+0.00|+0.00|-1.76|+0.00|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:1, train_loss: -1.703, val_loss: -1.774, \n",
      "train_vector: +0.00|+0.00|+0.00|-1.70|+0.00|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.00|+0.00|+0.00|-1.77|+0.00|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:2, train_loss: -1.733, val_loss: -1.693, \n",
      "train_vector: +0.00|+0.00|+0.00|-1.73|+0.00|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.00|+0.00|+0.00|-1.69|+0.00|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:3, train_loss: -1.748, val_loss: -1.865, \n",
      "train_vector: +0.00|+0.00|+0.00|-1.75|+0.00|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.00|+0.00|+0.00|-1.86|+0.00|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:4, train_loss: -1.766, val_loss: -1.651, \n",
      "train_vector: +0.00|+0.00|+0.00|-1.77|+0.00|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.00|+0.00|+0.00|-1.65|+0.00|+0.00|+0.00|+0.00\n",
      "\n",
      "Training completed in 87.28697752952576s\n",
      "\n",
      "Training all\n",
      "epoch:5, train_loss: -1.664, val_loss: -1.873, \n",
      "train_vector: +0.00|+0.00|+0.00|-1.66|+0.00|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.00|+0.00|+0.00|-1.87|+0.00|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:6, train_loss: -1.735, val_loss: -1.177, \n",
      "train_vector: +0.00|+0.00|+0.00|-1.73|+0.00|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.00|+0.00|+0.00|-1.18|+0.00|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:7, train_loss: -1.769, val_loss: -1.918, \n",
      "train_vector: +0.00|+0.00|+0.00|-1.77|+0.00|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.00|+0.00|+0.00|-1.92|+0.00|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:8, train_loss: -1.785, val_loss: -1.711, \n",
      "train_vector: +0.00|+0.00|+0.00|-1.78|+0.00|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.00|+0.00|+0.00|-1.71|+0.00|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:9, train_loss: -1.835, val_loss: -1.970, \n",
      "train_vector: +0.00|+0.00|+0.00|-1.84|+0.00|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.00|+0.00|+0.00|-1.97|+0.00|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:10, train_loss: -1.869, val_loss: -1.968, \n",
      "train_vector: +0.00|+0.00|+0.00|-1.87|+0.00|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.00|+0.00|+0.00|-1.97|+0.00|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:11, train_loss: -1.887, val_loss: -1.926, \n",
      "train_vector: +0.00|+0.00|+0.00|-1.89|+0.00|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.00|+0.00|+0.00|-1.93|+0.00|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:12, train_loss: -1.898, val_loss: -1.785, \n",
      "train_vector: +0.00|+0.00|+0.00|-1.90|+0.00|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.00|+0.00|+0.00|-1.79|+0.00|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:13, train_loss: -1.928, val_loss: -1.965, \n",
      "train_vector: +0.00|+0.00|+0.00|-1.93|+0.00|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.00|+0.00|+0.00|-1.97|+0.00|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:14, train_loss: -1.947, val_loss: -1.816, \n",
      "train_vector: +0.00|+0.00|+0.00|-1.95|+0.00|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.00|+0.00|+0.00|-1.82|+0.00|+0.00|+0.00|+0.00\n",
      "\n",
      "Training completed in 379.6869592666626s\n",
      "\n",
      "Training type: 4\n",
      "\n",
      "Training head\n",
      "epoch:0, train_loss: -1.046, val_loss: -1.436, \n",
      "train_vector: +0.00|+0.00|+0.00|+0.00|-1.05|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.00|+0.00|+0.00|+0.00|-1.44|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:1, train_loss: -1.472, val_loss: -1.587, \n",
      "train_vector: +0.00|+0.00|+0.00|+0.00|-1.47|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.00|+0.00|+0.00|+0.00|-1.59|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:2, train_loss: -1.518, val_loss: -1.575, \n",
      "train_vector: +0.00|+0.00|+0.00|+0.00|-1.52|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.00|+0.00|+0.00|+0.00|-1.57|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:3, train_loss: -1.551, val_loss: -1.541, \n",
      "train_vector: +0.00|+0.00|+0.00|+0.00|-1.55|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.00|+0.00|+0.00|+0.00|-1.54|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:4, train_loss: -1.564, val_loss: -1.633, \n",
      "train_vector: +0.00|+0.00|+0.00|+0.00|-1.56|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.00|+0.00|+0.00|+0.00|-1.63|+0.00|+0.00|+0.00\n",
      "\n",
      "Training completed in 44.453752756118774s\n",
      "\n",
      "Training all\n",
      "epoch:5, train_loss: -1.581, val_loss: -1.561, \n",
      "train_vector: +0.00|+0.00|+0.00|+0.00|-1.58|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.00|+0.00|+0.00|+0.00|-1.56|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:6, train_loss: -1.683, val_loss: -1.759, \n",
      "train_vector: +0.00|+0.00|+0.00|+0.00|-1.68|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.00|+0.00|+0.00|+0.00|-1.76|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:7, train_loss: -1.740, val_loss: -1.836, \n",
      "train_vector: +0.00|+0.00|+0.00|+0.00|-1.74|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.00|+0.00|+0.00|+0.00|-1.84|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:8, train_loss: -1.770, val_loss: -1.857, \n",
      "train_vector: +0.00|+0.00|+0.00|+0.00|-1.77|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.00|+0.00|+0.00|+0.00|-1.86|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:9, train_loss: -1.817, val_loss: -1.901, \n",
      "train_vector: +0.00|+0.00|+0.00|+0.00|-1.82|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.00|+0.00|+0.00|+0.00|-1.90|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:10, train_loss: -1.848, val_loss: -1.742, \n",
      "train_vector: +0.00|+0.00|+0.00|+0.00|-1.85|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.00|+0.00|+0.00|+0.00|-1.74|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:11, train_loss: -1.874, val_loss: -1.880, \n",
      "train_vector: +0.00|+0.00|+0.00|+0.00|-1.87|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.00|+0.00|+0.00|+0.00|-1.88|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:12, train_loss: -1.893, val_loss: -1.884, \n",
      "train_vector: +0.00|+0.00|+0.00|+0.00|-1.89|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.00|+0.00|+0.00|+0.00|-1.88|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:13, train_loss: -1.915, val_loss: -1.967, \n",
      "train_vector: +0.00|+0.00|+0.00|+0.00|-1.91|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.00|+0.00|+0.00|+0.00|-1.97|+0.00|+0.00|+0.00\n",
      "\n",
      "epoch:14, train_loss: -1.940, val_loss: -2.003, \n",
      "train_vector: +0.00|+0.00|+0.00|+0.00|-1.94|+0.00|+0.00|+0.00, \n",
      "val_vector  : +0.00|+0.00|+0.00|+0.00|-2.00|+0.00|+0.00|+0.00\n",
      "\n",
      "Training completed in 192.33296394348145s\n",
      "\n",
      "Training type: 5\n",
      "\n",
      "Training head\n",
      "epoch:0, train_loss: +0.316, val_loss: +0.194, \n",
      "train_vector: +0.00|+0.00|+0.00|+0.00|+0.00|+0.32|+0.00|+0.00, \n",
      "val_vector  : +0.00|+0.00|+0.00|+0.00|+0.00|+0.19|+0.00|+0.00\n",
      "\n",
      "epoch:1, train_loss: +0.194, val_loss: +0.184, \n",
      "train_vector: +0.00|+0.00|+0.00|+0.00|+0.00|+0.19|+0.00|+0.00, \n",
      "val_vector  : +0.00|+0.00|+0.00|+0.00|+0.00|+0.18|+0.00|+0.00\n",
      "\n",
      "epoch:2, train_loss: +0.171, val_loss: +0.176, \n",
      "train_vector: +0.00|+0.00|+0.00|+0.00|+0.00|+0.17|+0.00|+0.00, \n",
      "val_vector  : +0.00|+0.00|+0.00|+0.00|+0.00|+0.18|+0.00|+0.00\n",
      "\n",
      "epoch:3, train_loss: +0.149, val_loss: +0.131, \n",
      "train_vector: +0.00|+0.00|+0.00|+0.00|+0.00|+0.15|+0.00|+0.00, \n",
      "val_vector  : +0.00|+0.00|+0.00|+0.00|+0.00|+0.13|+0.00|+0.00\n",
      "\n",
      "epoch:4, train_loss: +0.128, val_loss: +0.128, \n",
      "train_vector: +0.00|+0.00|+0.00|+0.00|+0.00|+0.13|+0.00|+0.00, \n",
      "val_vector  : +0.00|+0.00|+0.00|+0.00|+0.00|+0.13|+0.00|+0.00\n",
      "\n",
      "Training completed in 94.3971426486969s\n",
      "\n",
      "Training all\n",
      "epoch:5, train_loss: -0.027, val_loss: -0.147, \n",
      "train_vector: +0.00|+0.00|+0.00|+0.00|+0.00|-0.03|+0.00|+0.00, \n",
      "val_vector  : +0.00|+0.00|+0.00|+0.00|+0.00|-0.15|+0.00|+0.00\n",
      "\n",
      "epoch:6, train_loss: -0.203, val_loss: -0.285, \n",
      "train_vector: +0.00|+0.00|+0.00|+0.00|+0.00|-0.20|+0.00|+0.00, \n",
      "val_vector  : +0.00|+0.00|+0.00|+0.00|+0.00|-0.28|+0.00|+0.00\n",
      "\n",
      "epoch:7, train_loss: -0.308, val_loss: -0.318, \n",
      "train_vector: +0.00|+0.00|+0.00|+0.00|+0.00|-0.31|+0.00|+0.00, \n",
      "val_vector  : +0.00|+0.00|+0.00|+0.00|+0.00|-0.32|+0.00|+0.00\n",
      "\n",
      "epoch:8, train_loss: -0.386, val_loss: -0.389, \n",
      "train_vector: +0.00|+0.00|+0.00|+0.00|+0.00|-0.39|+0.00|+0.00, \n",
      "val_vector  : +0.00|+0.00|+0.00|+0.00|+0.00|-0.39|+0.00|+0.00\n",
      "\n",
      "epoch:9, train_loss: -0.450, val_loss: -0.489, \n",
      "train_vector: +0.00|+0.00|+0.00|+0.00|+0.00|-0.45|+0.00|+0.00, \n",
      "val_vector  : +0.00|+0.00|+0.00|+0.00|+0.00|-0.49|+0.00|+0.00\n",
      "\n",
      "epoch:10, train_loss: -0.506, val_loss: -0.507, \n",
      "train_vector: +0.00|+0.00|+0.00|+0.00|+0.00|-0.51|+0.00|+0.00, \n",
      "val_vector  : +0.00|+0.00|+0.00|+0.00|+0.00|-0.51|+0.00|+0.00\n",
      "\n",
      "epoch:11, train_loss: -0.556, val_loss: -0.584, \n",
      "train_vector: +0.00|+0.00|+0.00|+0.00|+0.00|-0.56|+0.00|+0.00, \n",
      "val_vector  : +0.00|+0.00|+0.00|+0.00|+0.00|-0.58|+0.00|+0.00\n",
      "\n",
      "epoch:12, train_loss: -0.600, val_loss: -0.598, \n",
      "train_vector: +0.00|+0.00|+0.00|+0.00|+0.00|-0.60|+0.00|+0.00, \n",
      "val_vector  : +0.00|+0.00|+0.00|+0.00|+0.00|-0.60|+0.00|+0.00\n",
      "\n",
      "epoch:13, train_loss: -0.642, val_loss: -0.605, \n",
      "train_vector: +0.00|+0.00|+0.00|+0.00|+0.00|-0.64|+0.00|+0.00, \n",
      "val_vector  : +0.00|+0.00|+0.00|+0.00|+0.00|-0.60|+0.00|+0.00\n",
      "\n",
      "epoch:14, train_loss: -0.678, val_loss: -0.705, \n",
      "train_vector: +0.00|+0.00|+0.00|+0.00|+0.00|-0.68|+0.00|+0.00, \n",
      "val_vector  : +0.00|+0.00|+0.00|+0.00|+0.00|-0.70|+0.00|+0.00\n",
      "\n",
      "Training completed in 405.3645977973938s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training type: 6\n",
      "\n",
      "Training head\n",
      "epoch:0, train_loss: -0.193, val_loss: -0.417, \n",
      "train_vector: +0.00|+0.00|+0.00|+0.00|+0.00|+0.00|-0.19|+0.00, \n",
      "val_vector  : +0.00|+0.00|+0.00|+0.00|+0.00|+0.00|-0.42|+0.00\n",
      "\n",
      "epoch:1, train_loss: -0.423, val_loss: -0.460, \n",
      "train_vector: +0.00|+0.00|+0.00|+0.00|+0.00|+0.00|-0.42|+0.00, \n",
      "val_vector  : +0.00|+0.00|+0.00|+0.00|+0.00|+0.00|-0.46|+0.00\n",
      "\n",
      "epoch:2, train_loss: -0.449, val_loss: -0.413, \n",
      "train_vector: +0.00|+0.00|+0.00|+0.00|+0.00|+0.00|-0.45|+0.00, \n",
      "val_vector  : +0.00|+0.00|+0.00|+0.00|+0.00|+0.00|-0.41|+0.00\n",
      "\n",
      "epoch:3, train_loss: -0.474, val_loss: -0.513, \n",
      "train_vector: +0.00|+0.00|+0.00|+0.00|+0.00|+0.00|-0.47|+0.00, \n",
      "val_vector  : +0.00|+0.00|+0.00|+0.00|+0.00|+0.00|-0.51|+0.00\n",
      "\n",
      "epoch:4, train_loss: -0.493, val_loss: -0.516, \n",
      "train_vector: +0.00|+0.00|+0.00|+0.00|+0.00|+0.00|-0.49|+0.00, \n",
      "val_vector  : +0.00|+0.00|+0.00|+0.00|+0.00|+0.00|-0.52|+0.00\n",
      "\n",
      "Training completed in 84.60186243057251s\n",
      "\n",
      "Training all\n",
      "epoch:5, train_loss: -0.620, val_loss: -0.683, \n",
      "train_vector: +0.00|+0.00|+0.00|+0.00|+0.00|+0.00|-0.62|+0.00, \n",
      "val_vector  : +0.00|+0.00|+0.00|+0.00|+0.00|+0.00|-0.68|+0.00\n",
      "\n",
      "epoch:6, train_loss: -0.775, val_loss: -0.741, \n",
      "train_vector: +0.00|+0.00|+0.00|+0.00|+0.00|+0.00|-0.78|+0.00, \n",
      "val_vector  : +0.00|+0.00|+0.00|+0.00|+0.00|+0.00|-0.74|+0.00\n",
      "\n",
      "epoch:7, train_loss: -0.870, val_loss: -0.925, \n",
      "train_vector: +0.00|+0.00|+0.00|+0.00|+0.00|+0.00|-0.87|+0.00, \n",
      "val_vector  : +0.00|+0.00|+0.00|+0.00|+0.00|+0.00|-0.93|+0.00\n",
      "\n",
      "epoch:8, train_loss: -0.929, val_loss: -1.004, \n",
      "train_vector: +0.00|+0.00|+0.00|+0.00|+0.00|+0.00|-0.93|+0.00, \n",
      "val_vector  : +0.00|+0.00|+0.00|+0.00|+0.00|+0.00|-1.00|+0.00\n",
      "\n",
      "epoch:9, train_loss: -0.986, val_loss: -1.001, \n",
      "train_vector: +0.00|+0.00|+0.00|+0.00|+0.00|+0.00|-0.99|+0.00, \n",
      "val_vector  : +0.00|+0.00|+0.00|+0.00|+0.00|+0.00|-1.00|+0.00\n",
      "\n",
      "epoch:10, train_loss: -1.027, val_loss: -1.021, \n",
      "train_vector: +0.00|+0.00|+0.00|+0.00|+0.00|+0.00|-1.03|+0.00, \n",
      "val_vector  : +0.00|+0.00|+0.00|+0.00|+0.00|+0.00|-1.02|+0.00\n",
      "\n",
      "epoch:11, train_loss: -1.072, val_loss: -1.078, \n",
      "train_vector: +0.00|+0.00|+0.00|+0.00|+0.00|+0.00|-1.07|+0.00, \n",
      "val_vector  : +0.00|+0.00|+0.00|+0.00|+0.00|+0.00|-1.08|+0.00\n",
      "\n",
      "epoch:12, train_loss: -1.110, val_loss: -1.127, \n",
      "train_vector: +0.00|+0.00|+0.00|+0.00|+0.00|+0.00|-1.11|+0.00, \n",
      "val_vector  : +0.00|+0.00|+0.00|+0.00|+0.00|+0.00|-1.13|+0.00\n",
      "\n",
      "epoch:13, train_loss: -1.143, val_loss: -1.151, \n",
      "train_vector: +0.00|+0.00|+0.00|+0.00|+0.00|+0.00|-1.14|+0.00, \n",
      "val_vector  : +0.00|+0.00|+0.00|+0.00|+0.00|+0.00|-1.15|+0.00\n",
      "\n",
      "epoch:14, train_loss: -1.169, val_loss: -1.180, \n",
      "train_vector: +0.00|+0.00|+0.00|+0.00|+0.00|+0.00|-1.17|+0.00, \n",
      "val_vector  : +0.00|+0.00|+0.00|+0.00|+0.00|+0.00|-1.18|+0.00\n",
      "\n",
      "Training completed in 364.97120213508606s\n",
      "\n",
      "Training type: 7\n",
      "\n",
      "Training head\n",
      "epoch:0, train_loss: -1.089, val_loss: -1.322, \n",
      "train_vector: +0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|-1.09, \n",
      "val_vector  : +0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|-1.32\n",
      "\n",
      "epoch:1, train_loss: -1.395, val_loss: -1.397, \n",
      "train_vector: +0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|-1.39, \n",
      "val_vector  : +0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|-1.40\n",
      "\n",
      "epoch:2, train_loss: -1.437, val_loss: -1.468, \n",
      "train_vector: +0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|-1.44, \n",
      "val_vector  : +0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|-1.47\n",
      "\n",
      "epoch:3, train_loss: -1.456, val_loss: -1.454, \n",
      "train_vector: +0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|-1.46, \n",
      "val_vector  : +0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|-1.45\n",
      "\n",
      "epoch:4, train_loss: -1.479, val_loss: -1.448, \n",
      "train_vector: +0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|-1.48, \n",
      "val_vector  : +0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|-1.45\n",
      "\n",
      "Training completed in 51.48229789733887s\n",
      "\n",
      "Training all\n",
      "epoch:5, train_loss: -1.500, val_loss: -1.539, \n",
      "train_vector: +0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|-1.50, \n",
      "val_vector  : +0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|-1.54\n",
      "\n",
      "epoch:6, train_loss: -1.598, val_loss: -1.564, \n",
      "train_vector: +0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|-1.60, \n",
      "val_vector  : +0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|-1.56\n",
      "\n",
      "epoch:7, train_loss: -1.665, val_loss: -1.536, \n",
      "train_vector: +0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|-1.67, \n",
      "val_vector  : +0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|-1.54\n",
      "\n",
      "epoch:8, train_loss: -1.713, val_loss: -1.675, \n",
      "train_vector: +0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|-1.71, \n",
      "val_vector  : +0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|-1.68\n",
      "\n",
      "epoch:9, train_loss: -1.758, val_loss: -1.668, \n",
      "train_vector: +0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|-1.76, \n",
      "val_vector  : +0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|-1.67\n",
      "\n",
      "epoch:10, train_loss: -1.805, val_loss: -1.779, \n",
      "train_vector: +0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|-1.80, \n",
      "val_vector  : +0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|-1.78\n",
      "\n",
      "epoch:11, train_loss: -1.847, val_loss: -1.769, \n",
      "train_vector: +0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|-1.85, \n",
      "val_vector  : +0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|-1.77\n",
      "\n",
      "epoch:12, train_loss: -1.872, val_loss: -1.829, \n",
      "train_vector: +0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|-1.87, \n",
      "val_vector  : +0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|-1.83\n",
      "\n",
      "epoch:13, train_loss: -1.905, val_loss: -1.827, \n",
      "train_vector: +0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|-1.90, \n",
      "val_vector  : +0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|-1.83\n",
      "\n",
      "epoch:14, train_loss: -1.932, val_loss: -1.881, \n",
      "train_vector: +0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|-1.93, \n",
      "val_vector  : +0.00|+0.00|+0.00|+0.00|+0.00|+0.00|+0.00|-1.88\n",
      "\n",
      "Training completed in 220.315260887146s\n"
     ]
    }
   ],
   "source": [
    "for i in range(8):\n",
    "    # load type data\n",
    "    data_type = '../Data/{}_data_ACSF_expand_type_'+str(i)+'.pickle'\n",
    "    train_dl,val_dl = get_data(data_type,batch_size)\n",
    "    \n",
    "    # load base model\n",
    "    model = GNN(reuse,block,head,dim,layer1,layer2,factor,**data_dict[data]).to('cuda:0')\n",
    "    checkpoint = torch.load('../Model/'+file_name)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    set_requires_grad(model, False)\n",
    "    model.head = cat3Head_type(dim,8,data_dict[data]['edge_in4']).to('cuda:0')\n",
    "    \n",
    "    paras = trainable_parameter(model)\n",
    "    opt = Adam(paras,lr=lr_type) \n",
    "    # train head\n",
    "    print('\\nTraining type: {}'.format(i))\n",
    "    print('\\nTraining head')\n",
    "    model,train_loss_perType,val_loss_perType = train(opt,model,5,train_dl,val_dl,paras,clip,True)\n",
    "    \n",
    "    # train all\n",
    "    set_requires_grad(model, True)\n",
    "    paras = trainable_parameter(model)\n",
    "    opt = Adam(paras,lr=lr_type)    \n",
    "    print('\\nTraining all')\n",
    "    model,train_loss_perType,val_loss_perType = train(opt,model,epochs_type,train_dl,val_dl,paras,clip,True,train_loss_perType,val_loss_perType)\n",
    "    \n",
    "    save_results(train_loss_perType,val_loss_perType,reuse,block,\\\n",
    "                 cat3Head_type,data,batch_size,dim,clip,layer1,layer2,factor,epochs,'type_'+str(i)+'_2stage')\n",
    "\n",
    "    save_model(model,opt,reuse,block,cat3Head_type,data,batch_size,dim,clip,layer1,layer2,factor,epochs,'type_'+str(i)+'_2stage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_submission(reuse,block,head,data,batch_size,dim,clip,layer1,layer2,factor,epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "head = cat3Head_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_submission(reuse,block,head,data,batch_size,dim,clip,layer1,layer2,factor,epochs,'_start')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "head = cat3Head_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_submission(reuse,block,head,data,batch_size,dim,clip,layer1,layer2,factor,epochs,'_2stage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
