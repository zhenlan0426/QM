{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from attention import *\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_util import RAdam,trainable_parameter\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2048\n",
    "dim = 512\n",
    "head_d = 8\n",
    "head = SimplyInteraction #SimplyHead\n",
    "encoder_layer,decoder_layer = 2,2\n",
    "epochs = 10\n",
    "clip = 0.5\n",
    "logLoss = True\n",
    "\n",
    "dim_feedforward = 1024\n",
    "dropout = 0.1\n",
    "lr = 1e-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Data/train_data_attention_node.pickle', 'rb') as handle:\n",
    "    train_node = pickle.load(handle)\n",
    "with open('../Data/train_data_attention_edge.pickle', 'rb') as handle:\n",
    "    train_edge = pickle.load(handle)\n",
    "with open('../Data/train_data_attention_edge_y.pickle', 'rb') as handle:\n",
    "    train_y = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = attentionDataset(train_node[:4000000],train_edge[:4000000],train_y[:4000000])\n",
    "train_dl = DataLoader(train_dl,shuffle=True,batch_size=batch_size,collate_fn=collate_fn,num_workers=4)\n",
    "val_dl = attentionDataset(train_node[4000000:],train_edge[4000000:],train_y[4000000:])\n",
    "val_dl = DataLoader(val_dl,shuffle=False,batch_size=batch_size,collate_fn=collate_fn,num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Attention(dim,encoder_layer,decoder_layer,head_d,\\\n",
    "                head,dropout=dropout,dim_feedforward=dim_feedforward).to('cuda')\n",
    "paras = trainable_parameter(model)\n",
    "opt = RAdam(paras,lr=lr,weight_decay=1e-2)\n",
    "scheduler = ReduceLROnPlateau(opt, 'min',factor=0.5,patience=5,min_lr=1e-04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out,mask,edge,y = next(iter(train_dl))\n",
    "# out,mask,edge,y = out.to('cuda:0'),mask.to('cuda:0'),edge.to('cuda:0'),y.to('cuda:0')\n",
    "\n",
    "# opt.zero_grad()\n",
    "# loss,loss_perType = model(out,mask,edge,y,logLoss)\n",
    "# loss.backward()\n",
    "\n",
    "# [(n,p.std()) for n,p in model.named_parameters()]\n",
    "\n",
    "# [(n,p.grad.mean()) for n,p in model.named_parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss: +1.656, val_loss: +2.735, \n",
      "train_vector: +2.70|+2.51|+1.42|+1.48|+1.37|+1.32|+1.44|+0.99, \n",
      "val_vector  : +3.44|+1.78|+2.67|+2.65|+2.60|+2.79|+2.68|+2.50\n",
      "\n",
      "epoch:1, train_loss: +1.978, val_loss: +4.704, \n",
      "train_vector: +2.71|+2.60|+1.81|+1.85|+1.75|+1.74|+1.81|+1.56, \n",
      "val_vector  : +4.83|+3.95|+4.70|+4.68|+4.44|+4.71|+4.57|+4.47\n",
      "\n",
      "epoch:2, train_loss: +1.752, val_loss: +4.407, \n",
      "train_vector: +2.59|+2.50|+1.55|+1.60|+1.50|+1.47|+1.56|+1.25, \n",
      "val_vector  : +4.33|+4.28|+4.42|+4.21|+4.14|+4.41|+4.15|+4.14\n",
      "\n",
      "epoch:3, train_loss: +1.653, val_loss: +5.002, \n",
      "train_vector: +2.54|+2.46|+1.44|+1.49|+1.38|+1.35|+1.45|+1.12, \n",
      "val_vector  : +6.22|+4.27|+4.78|+4.68|+4.52|+4.81|+4.79|+4.56\n",
      "\n",
      "epoch:4, train_loss: +1.668, val_loss: +4.967, \n",
      "train_vector: +2.55|+2.46|+1.45|+1.50|+1.40|+1.36|+1.47|+1.14, \n",
      "val_vector  : +4.98|+4.18|+4.98|+4.93|+4.67|+4.97|+4.94|+4.71\n",
      "\n",
      "epoch:5, train_loss: +1.665, val_loss: +5.861, \n",
      "train_vector: +2.54|+2.45|+1.45|+1.50|+1.40|+1.36|+1.47|+1.14, \n",
      "val_vector  : +5.83|+4.87|+5.87|+5.88|+5.53|+5.87|+5.86|+5.57\n",
      "\n",
      "epoch:6, train_loss: +1.650, val_loss: +3.721, \n",
      "train_vector: +2.55|+2.44|+1.44|+1.49|+1.38|+1.34|+1.45|+1.12, \n",
      "val_vector  : +3.51|+3.19|+3.76|+3.73|+3.52|+3.75|+3.73|+3.56\n",
      "\n",
      "----early stop at epoch 6----\n"
     ]
    }
   ],
   "source": [
    "model,bestOpt,bestWeight = train_type(opt,model,epochs,train_dl,val_dl,paras,clip,\\\n",
    "                                       scheduler=scheduler,logLoss=logLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
