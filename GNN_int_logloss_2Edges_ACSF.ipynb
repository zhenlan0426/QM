{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch_geometric.data import Data,DataLoader\n",
    "from functions import *\n",
    "from pytorch_util import *\n",
    "from torch.optim import Adam\n",
    "from torch.nn.utils import clip_grad_value_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Data/train_data_ACSF.pickle', 'rb') as handle:\n",
    "    train_data = pickle.load(handle)\n",
    "with open('../Data/val_data_ACSF.pickle', 'rb') as handle:\n",
    "    val_data = pickle.load(handle)\n",
    "with open('../Data/test_data_ACSF.pickle', 'rb') as handle:\n",
    "    test_data = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### parameters ###\n",
    "batch_size = 32\n",
    "dim = 64\n",
    "edge_dim = 12\n",
    "epochs = 5\n",
    "clip = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = [Data(**d) for d in train_data]\n",
    "train_dl = DataLoader(train_list,batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_list = [Data(**d) for d in val_data]\n",
    "valid_dl = DataLoader(val_list,batch_size,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = [Data(**d) for d in test_data]\n",
    "test_dl = DataLoader(test_list,batch_size,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_attr=[36, 19], edge_attr3=[58, 8], edge_attr4=[58, 1], edge_index=[2, 36], edge_index3=[2, 58], x=[17, 89], y=[58])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_int_2Edges(torch.nn.Module):\n",
    "    # use both types of edges\n",
    "    def __init__(self,dim=64,edge_dim=12,node_in=8,edge_in=19,edge_in3=8):\n",
    "        super(Net_int_2Edges, self).__init__()\n",
    "        self.lin_node = torch.nn.Linear(node_in, dim)\n",
    "        self.lin_edge_attr = torch.nn.Linear(edge_in, edge_dim)\n",
    "        \n",
    "        nn1 = Linear(edge_dim, dim * dim, bias=False)\n",
    "        nn2 = Linear(edge_in3, dim * dim * 2 * 2, bias=False)\n",
    "        \n",
    "        self.conv1 = NNConv(dim, dim, nn1, aggr='mean', root_weight=False)\n",
    "        self.gru1 = GRU(dim, dim)\n",
    "        self.lin_covert = Sequential(BatchNorm1d(dim),Linear(dim, dim*2), \\\n",
    "                                     RReLU(), Dropout(),Linear(dim*2, dim*2),RReLU())\n",
    "        \n",
    "        self.conv2 = NNConv(dim*2, dim*2, nn2, aggr='mean', root_weight=False)\n",
    "        self.gru2 = GRU(dim*2, dim*2)\n",
    "        \n",
    "        self.lin_weight = Linear(8, dim*3*2, bias=False)\n",
    "        self.lin_bias = Linear(8, 1, bias=False)\n",
    "        self.norm = BatchNorm1d(dim*3*2)\n",
    "        self.norm_x = BatchNorm1d(node_in)\n",
    "        \n",
    "    def forward(self, data,IsTrain=False):\n",
    "        out = F.rrelu(self.lin_node(self.norm_x(data.x)))\n",
    "        edge_attr = F.rrelu(self.lin_edge_attr(data.edge_attr))\n",
    "        h = out.unsqueeze(0)\n",
    "        # edge_*3 only does not repeat for undirected graph. Hence need to add (j,i) to (i,j) in edges\n",
    "        edge_index3 = torch.cat([data.edge_index3,data.edge_index3[[1,0]]],1)\n",
    "        edge_attr3 = torch.cat([data.edge_attr3,data.edge_attr3],0)\n",
    "        \n",
    "        for i in range(2):\n",
    "            # using bonding as edge\n",
    "            m = F.rrelu(self.conv1(out, data.edge_index, edge_attr))\n",
    "            out, h = self.gru1(m.unsqueeze(0), h)\n",
    "            out = out.squeeze(0)\n",
    "        \n",
    "        out = self.lin_covert(out)\n",
    "        h = out.unsqueeze(0)\n",
    "        for i in range(2):\n",
    "            # using couping as edge\n",
    "            m = F.rrelu(self.conv2(out, edge_index3, edge_attr3))\n",
    "            out, h = self.gru2(m.unsqueeze(0), h)\n",
    "            out = out.squeeze(0)     \n",
    "            \n",
    "        temp = out[data.edge_index3] # (2,N,d)\n",
    "        yhat = torch.cat([temp.mean(0),temp[0]*temp[1],(temp[0]-temp[1])**2],1)\n",
    "        yhat = self.norm(yhat)\n",
    "        weight = self.lin_weight(data.edge_attr3)\n",
    "        bias = self.lin_bias(data.edge_attr3)\n",
    "        yhat = torch.sum(yhat * weight,1,keepdim=True) + bias\n",
    "        yhat = yhat.squeeze(1)\n",
    "        \n",
    "        if IsTrain:\n",
    "            k = torch.sum(data.edge_attr3,0)\n",
    "            nonzeroIndex = torch.nonzero(k).squeeze(1)\n",
    "            abs_ = torch.abs(data.y-yhat).unsqueeze(1)\n",
    "            loss = torch.sum(torch.log(torch.sum(abs_ * data.edge_attr3[:,nonzeroIndex],0)/k[nonzeroIndex]))/nonzeroIndex.shape[0]\n",
    "            return loss\n",
    "        else:\n",
    "            return yhat    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build model and set up training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Net_int_2Edges(dim=dim,edge_dim=edge_dim,node_in=89).to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "paras = trainable_parameter(model)\n",
    "opt = Adam(paras,lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:1.1739346754294746, val_loss:0.8054832735886941\n",
      "epoch:1, train_loss:0.7571289767044889, val_loss:0.5158659981993529\n",
      "epoch:2, train_loss:0.4491829921120533, val_loss:0.24700134334305668\n",
      "epoch:3, train_loss:0.3196105955396006, val_loss:0.17007113736855167\n",
      "epoch:4, train_loss:0.24730826115510782, val_loss:0.10247237822757317\n",
      "Training completed in 171.19584012031555s\n"
     ]
    }
   ],
   "source": [
    "since = time.time()\n",
    "opt.zero_grad()\n",
    "for epoch in range(epochs):\n",
    "    # training #\n",
    "    model.train()\n",
    "    np.random.seed()\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    \n",
    "    for i,data in enumerate(train_dl):\n",
    "        data = data.to('cuda:0')\n",
    "        loss = model(data,True)\n",
    "        loss.backward()\n",
    "        clip_grad_value_(paras,clip)\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # evaluating #\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for j,data in enumerate(valid_dl):\n",
    "            data = data.to('cuda:0')\n",
    "            loss = model(data,True)\n",
    "            val_loss += loss.item()\n",
    "    print('epoch:{}, train_loss:{}, val_loss:{}'.format(epoch,train_loss/i,val_loss/j))\n",
    "    \n",
    "time_elapsed = time.time() - since\n",
    "print('Training completed in {}s'.format(time_elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:0.19482433232962132, val_loss:0.04124950004630109\n",
      "epoch:1, train_loss:0.14898996313613982, val_loss:0.005395223840306967\n",
      "epoch:2, train_loss:0.11200088394399534, val_loss:-0.045809876229454816\n",
      "epoch:3, train_loss:0.07885806503010276, val_loss:-0.016717322250334624\n",
      "epoch:4, train_loss:0.050386534285806986, val_loss:-0.06465468732401347\n",
      "Training completed in 171.54214429855347s\n"
     ]
    }
   ],
   "source": [
    "since = time.time()\n",
    "opt.zero_grad()\n",
    "for epoch in range(epochs):\n",
    "    # training #\n",
    "    model.train()\n",
    "    np.random.seed()\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    \n",
    "    for i,data in enumerate(train_dl):\n",
    "        data = data.to('cuda:0')\n",
    "        loss = model(data,True)\n",
    "        loss.backward()\n",
    "        clip_grad_value_(paras,clip)\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # evaluating #\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for j,data in enumerate(valid_dl):\n",
    "            data = data.to('cuda:0')\n",
    "            loss = model(data,True)\n",
    "            val_loss += loss.item()\n",
    "    print('epoch:{}, train_loss:{}, val_loss:{}'.format(epoch,train_loss/i,val_loss/j))\n",
    "    \n",
    "time_elapsed = time.time() - since\n",
    "print('Training completed in {}s'.format(time_elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:0.021055064112574857, val_loss:-0.11192599882204564\n",
      "epoch:1, train_loss:-0.0026387100563195942, val_loss:-0.13560246680982602\n",
      "epoch:2, train_loss:-0.02474585040691758, val_loss:-0.13499401912538925\n",
      "epoch:3, train_loss:-0.04765281962953886, val_loss:-0.18288500405625147\n",
      "epoch:4, train_loss:-0.06743211330949006, val_loss:-0.19911610616100395\n",
      "Training completed in 170.19796442985535s\n"
     ]
    }
   ],
   "source": [
    "since = time.time()\n",
    "opt.zero_grad()\n",
    "for epoch in range(epochs):\n",
    "    # training #\n",
    "    model.train()\n",
    "    np.random.seed()\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    \n",
    "    for i,data in enumerate(train_dl):\n",
    "        data = data.to('cuda:0')\n",
    "        loss = model(data,True)\n",
    "        loss.backward()\n",
    "        clip_grad_value_(paras,clip)\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # evaluating #\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for j,data in enumerate(valid_dl):\n",
    "            data = data.to('cuda:0')\n",
    "            loss = model(data,True)\n",
    "            val_loss += loss.item()\n",
    "    print('epoch:{}, train_loss:{}, val_loss:{}'.format(epoch,train_loss/i,val_loss/j))\n",
    "    \n",
    "time_elapsed = time.time() - since\n",
    "print('Training completed in {}s'.format(time_elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:-0.0847593189788208, val_loss:-0.23004544464250407\n",
      "epoch:1, train_loss:-0.10592249585175056, val_loss:-0.23748463238629267\n",
      "epoch:2, train_loss:-0.11914311985604066, val_loss:-0.20975303685722443\n",
      "epoch:3, train_loss:-0.13494598430891833, val_loss:-0.24600053661399418\n",
      "epoch:4, train_loss:-0.1513652730337972, val_loss:-0.28226680762301654\n",
      "Training completed in 170.19137907028198s\n"
     ]
    }
   ],
   "source": [
    "since = time.time()\n",
    "opt.zero_grad()\n",
    "for epoch in range(epochs):\n",
    "    # training #\n",
    "    model.train()\n",
    "    np.random.seed()\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    \n",
    "    for i,data in enumerate(train_dl):\n",
    "        data = data.to('cuda:0')\n",
    "        loss = model(data,True)\n",
    "        loss.backward()\n",
    "        clip_grad_value_(paras,clip)\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # evaluating #\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for j,data in enumerate(valid_dl):\n",
    "            data = data.to('cuda:0')\n",
    "            loss = model(data,True)\n",
    "            val_loss += loss.item()\n",
    "    print('epoch:{}, train_loss:{}, val_loss:{}'.format(epoch,train_loss/i,val_loss/j))\n",
    "    \n",
    "time_elapsed = time.time() - since\n",
    "print('Training completed in {}s'.format(time_elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:-0.16466826203210636, val_loss:-0.2865101226852236\n",
      "epoch:1, train_loss:-0.1792188692798776, val_loss:-0.31221284513544834\n",
      "epoch:2, train_loss:-0.19233726936460196, val_loss:-0.32245305239453786\n",
      "epoch:3, train_loss:-0.20338699091813528, val_loss:-0.3258422153691451\n",
      "epoch:4, train_loss:-0.2134199583069151, val_loss:-0.29250387927023774\n",
      "Training completed in 171.03588199615479s\n"
     ]
    }
   ],
   "source": [
    "since = time.time()\n",
    "opt.zero_grad()\n",
    "for epoch in range(epochs):\n",
    "    # training #\n",
    "    model.train()\n",
    "    np.random.seed()\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    \n",
    "    for i,data in enumerate(train_dl):\n",
    "        data = data.to('cuda:0')\n",
    "        loss = model(data,True)\n",
    "        loss.backward()\n",
    "        clip_grad_value_(paras,clip)\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # evaluating #\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for j,data in enumerate(valid_dl):\n",
    "            data = data.to('cuda:0')\n",
    "            loss = model(data,True)\n",
    "            val_loss += loss.item()\n",
    "    print('epoch:{}, train_loss:{}, val_loss:{}'.format(epoch,train_loss/i,val_loss/j))\n",
    "    \n",
    "time_elapsed = time.time() - since\n",
    "print('Training completed in {}s'.format(time_elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:-0.2257434239242248, val_loss:-0.35334680882147235\n",
      "epoch:1, train_loss:-0.23928674256448665, val_loss:-0.3699718626200134\n",
      "epoch:2, train_loss:-0.247189037614235, val_loss:-0.3909210362750241\n",
      "epoch:3, train_loss:-0.25850824375347725, val_loss:-0.3752531309922536\n",
      "epoch:4, train_loss:-0.2669378805924318, val_loss:-0.3674872216378522\n",
      "Training completed in 171.29786944389343s\n"
     ]
    }
   ],
   "source": [
    "since = time.time()\n",
    "opt.zero_grad()\n",
    "for epoch in range(epochs):\n",
    "    # training #\n",
    "    model.train()\n",
    "    np.random.seed()\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    \n",
    "    for i,data in enumerate(train_dl):\n",
    "        data = data.to('cuda:0')\n",
    "        loss = model(data,True)\n",
    "        loss.backward()\n",
    "        clip_grad_value_(paras,clip)\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # evaluating #\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for j,data in enumerate(valid_dl):\n",
    "            data = data.to('cuda:0')\n",
    "            loss = model(data,True)\n",
    "            val_loss += loss.item()\n",
    "    print('epoch:{}, train_loss:{}, val_loss:{}'.format(epoch,train_loss/i,val_loss/j))\n",
    "    \n",
    "time_elapsed = time.time() - since\n",
    "print('Training completed in {}s'.format(time_elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:-0.2726908994554983, val_loss:-0.4101419033976192\n",
      "epoch:1, train_loss:-0.28439659813685564, val_loss:-0.4101586128847721\n",
      "epoch:2, train_loss:-0.29093954196198923, val_loss:-0.42486121648779285\n",
      "epoch:3, train_loss:-0.30186586135467763, val_loss:-0.40633517338169944\n",
      "epoch:4, train_loss:-0.30604040321213066, val_loss:-0.43537348827235717\n",
      "Training completed in 169.79613542556763s\n"
     ]
    }
   ],
   "source": [
    "since = time.time()\n",
    "opt.zero_grad()\n",
    "for epoch in range(epochs):\n",
    "    # training #\n",
    "    model.train()\n",
    "    np.random.seed()\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    \n",
    "    for i,data in enumerate(train_dl):\n",
    "        data = data.to('cuda:0')\n",
    "        loss = model(data,True)\n",
    "        loss.backward()\n",
    "        clip_grad_value_(paras,clip)\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # evaluating #\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for j,data in enumerate(valid_dl):\n",
    "            data = data.to('cuda:0')\n",
    "            loss = model(data,True)\n",
    "            val_loss += loss.item()\n",
    "    print('epoch:{}, train_loss:{}, val_loss:{}'.format(epoch,train_loss/i,val_loss/j))\n",
    "    \n",
    "time_elapsed = time.time() - since\n",
    "print('Training completed in {}s'.format(time_elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:-0.3165331670463385, val_loss:-0.456929642197668\n",
      "epoch:1, train_loss:-0.32575479115069483, val_loss:-0.42108159066520184\n",
      "epoch:2, train_loss:-0.33182264629719077, val_loss:-0.4503420043386455\n",
      "epoch:3, train_loss:-0.3366897756077952, val_loss:-0.4654683940685712\n",
      "epoch:4, train_loss:-0.34268184704258936, val_loss:-0.47542838936942255\n",
      "Training completed in 169.73175168037415s\n"
     ]
    }
   ],
   "source": [
    "since = time.time()\n",
    "opt.zero_grad()\n",
    "for epoch in range(epochs):\n",
    "    # training #\n",
    "    model.train()\n",
    "    np.random.seed()\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    \n",
    "    for i,data in enumerate(train_dl):\n",
    "        data = data.to('cuda:0')\n",
    "        loss = model(data,True)\n",
    "        loss.backward()\n",
    "        clip_grad_value_(paras,clip)\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # evaluating #\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for j,data in enumerate(valid_dl):\n",
    "            data = data.to('cuda:0')\n",
    "            loss = model(data,True)\n",
    "            val_loss += loss.item()\n",
    "    print('epoch:{}, train_loss:{}, val_loss:{}'.format(epoch,train_loss/i,val_loss/j))\n",
    "    \n",
    "time_elapsed = time.time() - since\n",
    "print('Training completed in {}s'.format(time_elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:-0.348475465487142, val_loss:-0.4884253043649543\n",
      "epoch:1, train_loss:-0.3560849300593778, val_loss:-0.4622787304031543\n",
      "epoch:2, train_loss:-0.3612955486530521, val_loss:-0.451917429574025\n",
      "epoch:3, train_loss:-0.36585089616106153, val_loss:-0.5000598888494011\n",
      "epoch:4, train_loss:-0.37419000813063824, val_loss:-0.4910751003931221\n",
      "Training completed in 170.13969039916992s\n"
     ]
    }
   ],
   "source": [
    "since = time.time()\n",
    "opt.zero_grad()\n",
    "for epoch in range(epochs):\n",
    "    # training #\n",
    "    model.train()\n",
    "    np.random.seed()\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    \n",
    "    for i,data in enumerate(train_dl):\n",
    "        data = data.to('cuda:0')\n",
    "        loss = model(data,True)\n",
    "        loss.backward()\n",
    "        clip_grad_value_(paras,clip)\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # evaluating #\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for j,data in enumerate(valid_dl):\n",
    "            data = data.to('cuda:0')\n",
    "            loss = model(data,True)\n",
    "            val_loss += loss.item()\n",
    "    print('epoch:{}, train_loss:{}, val_loss:{}'.format(epoch,train_loss/i,val_loss/j))\n",
    "    \n",
    "time_elapsed = time.time() - since\n",
    "print('Training completed in {}s'.format(time_elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:-0.3793950006536114, val_loss:-0.5205923237989092\n",
      "epoch:1, train_loss:-0.38672326124989936, val_loss:-0.5085453941908658\n",
      "epoch:2, train_loss:-0.39007923657020915, val_loss:-0.5276373753435591\n",
      "epoch:3, train_loss:-0.3960084253534586, val_loss:-0.5188691905803151\n",
      "epoch:4, train_loss:-0.4020602917379585, val_loss:-0.5302597437149439\n",
      "Training completed in 169.79043078422546s\n"
     ]
    }
   ],
   "source": [
    "since = time.time()\n",
    "opt.zero_grad()\n",
    "for epoch in range(epochs):\n",
    "    # training #\n",
    "    model.train()\n",
    "    np.random.seed()\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    \n",
    "    for i,data in enumerate(train_dl):\n",
    "        data = data.to('cuda:0')\n",
    "        loss = model(data,True)\n",
    "        loss.backward()\n",
    "        clip_grad_value_(paras,clip)\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # evaluating #\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for j,data in enumerate(valid_dl):\n",
    "            data = data.to('cuda:0')\n",
    "            loss = model(data,True)\n",
    "            val_loss += loss.item()\n",
    "    print('epoch:{}, train_loss:{}, val_loss:{}'.format(epoch,train_loss/i,val_loss/j))\n",
    "    \n",
    "time_elapsed = time.time() - since\n",
    "print('Training completed in {}s'.format(time_elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:-0.40591379787873394, val_loss:-0.5214587506702822\n",
      "epoch:1, train_loss:-0.4125010917686304, val_loss:-0.5283720578011285\n",
      "epoch:2, train_loss:-0.41525019050175926, val_loss:-0.5590619807187308\n",
      "epoch:3, train_loss:-0.4216138071456782, val_loss:-0.5187173646229964\n",
      "epoch:4, train_loss:-0.42495096202004595, val_loss:-0.5449248650389859\n",
      "Training completed in 169.7900834083557s\n"
     ]
    }
   ],
   "source": [
    "since = time.time()\n",
    "opt.zero_grad()\n",
    "for epoch in range(epochs):\n",
    "    # training #\n",
    "    model.train()\n",
    "    np.random.seed()\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    \n",
    "    for i,data in enumerate(train_dl):\n",
    "        data = data.to('cuda:0')\n",
    "        loss = model(data,True)\n",
    "        loss.backward()\n",
    "        clip_grad_value_(paras,clip)\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # evaluating #\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for j,data in enumerate(valid_dl):\n",
    "            data = data.to('cuda:0')\n",
    "            loss = model(data,True)\n",
    "            val_loss += loss.item()\n",
    "    print('epoch:{}, train_loss:{}, val_loss:{}'.format(epoch,train_loss/i,val_loss/j))\n",
    "    \n",
    "time_elapsed = time.time() - since\n",
    "print('Training completed in {}s'.format(time_elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:-0.43039891749252507, val_loss:-0.5483956351621538\n",
      "epoch:1, train_loss:-0.4333486231388869, val_loss:-0.5703659195166367\n",
      "epoch:2, train_loss:-0.440496726754489, val_loss:-0.537911924541506\n",
      "epoch:3, train_loss:-0.4422573691628325, val_loss:-0.5538144424939767\n",
      "epoch:4, train_loss:-0.4470055357650583, val_loss:-0.5761168503608459\n",
      "Training completed in 169.45271110534668s\n"
     ]
    }
   ],
   "source": [
    "since = time.time()\n",
    "opt.zero_grad()\n",
    "for epoch in range(epochs):\n",
    "    # training #\n",
    "    model.train()\n",
    "    np.random.seed()\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    \n",
    "    for i,data in enumerate(train_dl):\n",
    "        data = data.to('cuda:0')\n",
    "        loss = model(data,True)\n",
    "        loss.backward()\n",
    "        clip_grad_value_(paras,clip)\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # evaluating #\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for j,data in enumerate(valid_dl):\n",
    "            data = data.to('cuda:0')\n",
    "            loss = model(data,True)\n",
    "            val_loss += loss.item()\n",
    "    print('epoch:{}, train_loss:{}, val_loss:{}'.format(epoch,train_loss/i,val_loss/j))\n",
    "    \n",
    "time_elapsed = time.time() - since\n",
    "print('Training completed in {}s'.format(time_elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:-0.4531842126665619, val_loss:-0.5655131068749305\n",
      "epoch:1, train_loss:-0.45369216979612864, val_loss:-0.5756788440367095\n",
      "epoch:2, train_loss:-0.4574622080159285, val_loss:-0.5844029667031052\n",
      "epoch:3, train_loss:-0.46239074298138483, val_loss:-0.5930155215100346\n",
      "epoch:4, train_loss:-0.46749998267976783, val_loss:-0.590697639199913\n",
      "Training completed in 169.91831278800964s\n"
     ]
    }
   ],
   "source": [
    "since = time.time()\n",
    "opt.zero_grad()\n",
    "for epoch in range(epochs):\n",
    "    # training #\n",
    "    model.train()\n",
    "    np.random.seed()\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    \n",
    "    for i,data in enumerate(train_dl):\n",
    "        data = data.to('cuda:0')\n",
    "        loss = model(data,True)\n",
    "        loss.backward()\n",
    "        clip_grad_value_(paras,clip)\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # evaluating #\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for j,data in enumerate(valid_dl):\n",
    "            data = data.to('cuda:0')\n",
    "            loss = model(data,True)\n",
    "            val_loss += loss.item()\n",
    "    print('epoch:{}, train_loss:{}, val_loss:{}'.format(epoch,train_loss/i,val_loss/j))\n",
    "    \n",
    "time_elapsed = time.time() - since\n",
    "print('Training completed in {}s'.format(time_elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:-0.47080848518985563, val_loss:-0.5995975306782967\n",
      "epoch:1, train_loss:-0.4741554025460118, val_loss:-0.603205823745483\n",
      "epoch:2, train_loss:-0.4786110106782386, val_loss:-0.6041232046917973\n",
      "epoch:3, train_loss:-0.4811708473306188, val_loss:-0.6133963423661697\n",
      "epoch:4, train_loss:-0.48519493008537495, val_loss:-0.6065863131457924\n",
      "Training completed in 171.77669525146484s\n"
     ]
    }
   ],
   "source": [
    "since = time.time()\n",
    "opt.zero_grad()\n",
    "for epoch in range(epochs):\n",
    "    # training #\n",
    "    model.train()\n",
    "    np.random.seed()\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    \n",
    "    for i,data in enumerate(train_dl):\n",
    "        data = data.to('cuda:0')\n",
    "        loss = model(data,True)\n",
    "        loss.backward()\n",
    "        clip_grad_value_(paras,clip)\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # evaluating #\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for j,data in enumerate(valid_dl):\n",
    "            data = data.to('cuda:0')\n",
    "            loss = model(data,True)\n",
    "            val_loss += loss.item()\n",
    "    print('epoch:{}, train_loss:{}, val_loss:{}'.format(epoch,train_loss/i,val_loss/j))\n",
    "    \n",
    "time_elapsed = time.time() - since\n",
    "print('Training completed in {}s'.format(time_elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:-0.48952987899123995, val_loss:-0.6128631965217427\n",
      "epoch:1, train_loss:-0.49240797561191785, val_loss:-0.6245898399342839\n",
      "epoch:2, train_loss:-0.49650030983437343, val_loss:-0.6064111420996169\n",
      "epoch:3, train_loss:-0.49681177621542943, val_loss:-0.6042713013469664\n",
      "epoch:4, train_loss:-0.501068246367319, val_loss:-0.6274271909879823\n",
      "Training completed in 170.0950791835785s\n"
     ]
    }
   ],
   "source": [
    "since = time.time()\n",
    "opt.zero_grad()\n",
    "for epoch in range(epochs):\n",
    "    # training #\n",
    "    model.train()\n",
    "    np.random.seed()\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    \n",
    "    for i,data in enumerate(train_dl):\n",
    "        data = data.to('cuda:0')\n",
    "        loss = model(data,True)\n",
    "        loss.backward()\n",
    "        clip_grad_value_(paras,clip)\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # evaluating #\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for j,data in enumerate(valid_dl):\n",
    "            data = data.to('cuda:0')\n",
    "            loss = model(data,True)\n",
    "            val_loss += loss.item()\n",
    "    print('epoch:{}, train_loss:{}, val_loss:{}'.format(epoch,train_loss/i,val_loss/j))\n",
    "    \n",
    "time_elapsed = time.time() - since\n",
    "print('Training completed in {}s'.format(time_elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('../Model/gnn_int_logloss_2Edges.tar')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "opt.load_state_dict(checkpoint['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': opt.state_dict(),\n",
    "            }, '../Model/gnn_int_logloss_2Edges_ACSF.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "yhat_list = []\n",
    "with torch.no_grad():\n",
    "    for data in test_dl:\n",
    "        data = data.to('cuda:0')\n",
    "        yhat_list.append(model(data,False))\n",
    "\n",
    "yhat = torch.cat(yhat_list).cpu().detach().numpy()\n",
    "submission = pd.read_csv('../Data/sample_submission.csv')\n",
    "submission['scalar_coupling_constant'] = yhat\n",
    "submission.to_csv('../Submission/gnn_int_logloss_2Edges_ACSF.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
