{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "from torch_geometric.data import Data,DataLoader\n",
    "from functions_refactor import *\n",
    "from pytorch_util import *\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model parameters\n",
    "reuse = False\n",
    "block = MEGNet_block\n",
    "head = feedforwardHead_Update\n",
    "head_mol,head_atom,head_edge = head_mol,head_atom,head_edge\n",
    "data = '../Data/{}_data_ACSF_expand_PCA_otherInfo.pickle'\n",
    "batch_size = 32\n",
    "dim = 128\n",
    "epochs = 60\n",
    "clip = 0.4\n",
    "layer1 = 3\n",
    "layer2 = 3\n",
    "factor = 2\n",
    "lr = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss: +1.456, val_loss: +0.102, \n",
      "train_vector: +4.32|+1.41|+0.09|-0.37|-0.54|+0.16|-0.54|-0.93, \n",
      "val_vector  : +4.00|+0.26|-0.32|-0.62|-0.93|-0.16|-0.95|-1.21\n",
      "\n",
      "epoch:1, train_loss: +0.561, val_loss: -0.568, \n",
      "train_vector: +1.89|+0.32|-0.37|-1.00|-1.11|-0.23|-1.01|-1.35, \n",
      "val_vector  : +0.51|+0.18|-0.52|-1.39|-1.18|-0.35|-1.08|-1.42\n",
      "\n",
      "epoch:2, train_loss: +0.228, val_loss: -0.693, \n",
      "train_vector: +0.84|+0.06|-0.52|-1.24|-1.31|-0.37|-1.19|-1.52, \n",
      "val_vector  : +0.72|-0.05|-0.68|-1.51|-1.46|-0.45|-1.19|-1.62\n",
      "\n",
      "epoch:3, train_loss: +0.101, val_loss: -0.716, \n",
      "train_vector: +0.78|-0.07|-0.62|-1.36|-1.43|-0.45|-1.28|-1.64, \n",
      "val_vector  : +0.91|-0.41|-0.73|-1.08|-1.52|-0.54|-1.32|-1.71\n",
      "\n",
      "epoch:4, train_loss: +0.002, val_loss: -0.859, \n",
      "train_vector: +0.74|-0.20|-0.69|-1.46|-1.52|-0.52|-1.35|-1.72, \n",
      "val_vector  : +0.75|-0.33|-0.83|-1.72|-1.56|-0.60|-1.53|-1.73\n",
      "\n",
      "epoch:5, train_loss: -0.074, val_loss: -0.959, \n",
      "train_vector: +0.67|-0.26|-0.75|-1.52|-1.59|-0.57|-1.41|-1.78, \n",
      "val_vector  : +0.44|-0.52|-0.85|-1.82|-1.65|-0.64|-1.55|-1.75\n",
      "\n",
      "epoch:6, train_loss: -0.142, val_loss: -0.949, \n",
      "train_vector: +0.64|-0.33|-0.80|-1.59|-1.65|-0.62|-1.47|-1.84, \n",
      "val_vector  : +0.17|-0.51|-0.91|-1.07|-1.78|-0.69|-1.58|-1.88\n",
      "\n",
      "epoch:7, train_loss: -0.202, val_loss: -0.998, \n",
      "train_vector: +0.57|-0.37|-0.85|-1.65|-1.70|-0.65|-1.51|-1.89, \n",
      "val_vector  : +0.29|-0.54|-0.91|-1.52|-1.75|-0.71|-1.62|-1.86\n",
      "\n",
      "epoch:8, train_loss: -0.258, val_loss: -1.091, \n",
      "train_vector: +0.47|-0.41|-0.88|-1.69|-1.74|-0.69|-1.54|-1.93, \n",
      "val_vector  : +0.26|-0.59|-0.97|-1.91|-1.88|-0.72|-1.59|-1.96\n",
      "\n",
      "epoch:9, train_loss: -0.317, val_loss: -1.041, \n",
      "train_vector: +0.35|-0.46|-0.91|-1.74|-1.78|-0.71|-1.57|-1.97, \n",
      "val_vector  : +0.55|-0.52|-1.01|-1.77|-1.83|-0.78|-1.63|-1.98\n",
      "\n",
      "epoch:10, train_loss: -0.361, val_loss: -1.089, \n",
      "train_vector: +0.29|-0.50|-0.95|-1.76|-1.82|-0.74|-1.61|-2.00, \n",
      "val_vector  : -0.05|-0.03|-1.05|-1.89|-1.81|-0.80|-1.71|-2.01\n",
      "\n",
      "epoch:11, train_loss: -0.401, val_loss: -1.174, \n",
      "train_vector: +0.24|-0.54|-0.98|-1.79|-1.85|-0.77|-1.63|-2.04, \n",
      "val_vector  : +0.30|-0.69|-1.04|-2.03|-1.93|-0.83|-1.71|-2.09\n",
      "\n",
      "epoch:12, train_loss: -0.447, val_loss: -1.139, \n",
      "train_vector: +0.17|-0.58|-1.00|-1.82|-1.88|-0.79|-1.66|-2.07, \n",
      "val_vector  : +0.44|-0.68|-1.07|-1.98|-1.76|-0.85|-1.75|-2.08\n",
      "\n",
      "epoch:13, train_loss: -0.482, val_loss: -1.261, \n",
      "train_vector: +0.12|-0.60|-1.02|-1.85|-1.92|-0.82|-1.70|-2.10, \n",
      "val_vector  : -0.05|-0.90|-1.10|-1.96|-1.90|-0.88|-1.81|-2.10\n",
      "\n",
      "epoch:14, train_loss: -0.513, val_loss: -1.153, \n",
      "train_vector: +0.09|-0.63|-1.04|-1.87|-1.93|-0.84|-1.71|-2.13, \n",
      "val_vector  : +0.29|-0.41|-1.11|-2.06|-1.83|-0.88|-1.78|-2.05\n",
      "\n",
      "epoch:15, train_loss: -0.543, val_loss: -1.249, \n",
      "train_vector: +0.05|-0.66|-1.07|-1.88|-1.95|-0.86|-1.74|-2.14, \n",
      "val_vector  : +0.17|-0.97|-1.11|-1.92|-2.03|-0.87|-1.71|-2.15\n",
      "\n",
      "epoch:16, train_loss: -0.572, val_loss: -1.312, \n",
      "train_vector: +0.03|-0.66|-1.09|-1.91|-1.98|-0.87|-1.75|-2.18, \n",
      "val_vector  : -0.08|-0.81|-1.15|-2.16|-2.02|-0.93|-1.78|-2.17\n",
      "\n",
      "epoch:17, train_loss: -0.602, val_loss: -1.275, \n",
      "train_vector: +0.00|-0.71|-1.10|-1.93|-2.01|-0.89|-1.78|-2.19, \n",
      "val_vector  : +0.02|-0.60|-1.11|-2.15|-2.03|-0.93|-1.86|-2.14\n",
      "\n",
      "epoch:18, train_loss: -0.621, val_loss: -1.285, \n",
      "train_vector: +0.01|-0.72|-1.12|-1.95|-2.03|-0.90|-1.79|-2.22, \n",
      "val_vector  : -0.03|-0.71|-1.19|-1.98|-2.01|-0.95|-1.84|-2.18\n",
      "\n",
      "epoch:19, train_loss: -0.647, val_loss: -1.299, \n",
      "train_vector: -0.02|-0.72|-1.14|-1.97|-2.05|-0.92|-1.81|-2.23, \n",
      "val_vector  : -0.21|-0.90|-1.21|-1.59|-2.03|-0.97|-1.89|-2.21\n",
      "\n",
      "epoch:20, train_loss: -0.670, val_loss: -1.354, \n",
      "train_vector: -0.04|-0.77|-1.15|-1.98|-2.06|-0.93|-1.82|-2.25, \n",
      "val_vector  : -0.10|-1.02|-1.21|-2.00|-2.06|-0.98|-1.92|-2.13\n",
      "\n",
      "epoch:21, train_loss: -0.687, val_loss: -1.273, \n",
      "train_vector: -0.06|-0.74|-1.16|-1.99|-2.08|-0.95|-1.84|-2.27, \n",
      "val_vector  : +0.36|-0.88|-1.18|-1.87|-2.10|-0.98|-1.91|-2.21\n",
      "\n",
      "epoch:22, train_loss: -0.716, val_loss: -1.364, \n",
      "train_vector: -0.08|-0.79|-1.18|-2.02|-2.10|-0.96|-1.85|-2.30, \n",
      "val_vector  : +0.16|-1.04|-1.24|-2.24|-2.07|-1.00|-1.84|-2.23\n",
      "\n",
      "epoch:23, train_loss: -0.743, val_loss: -1.394, \n",
      "train_vector: -0.11|-0.84|-1.19|-2.04|-2.11|-0.97|-1.87|-2.31, \n",
      "val_vector  : -0.13|-1.09|-1.24|-2.03|-2.09|-1.01|-1.91|-2.24\n",
      "\n",
      "epoch:24, train_loss: -0.755, val_loss: -1.392, \n",
      "train_vector: -0.12|-0.83|-1.20|-2.04|-2.13|-0.98|-1.88|-2.32, \n",
      "val_vector  : -0.19|-0.94|-1.25|-2.04|-2.14|-1.02|-1.94|-2.21\n",
      "\n",
      "epoch:25, train_loss: -0.778, val_loss: -1.383, \n",
      "train_vector: -0.13|-0.85|-1.21|-2.06|-2.15|-0.99|-1.89|-2.34, \n",
      "val_vector  : -0.37|-0.78|-1.26|-1.98|-2.08|-1.02|-1.93|-2.24\n",
      "\n",
      "epoch:26, train_loss: -0.799, val_loss: -1.418, \n",
      "train_vector: -0.15|-0.89|-1.22|-2.07|-2.16|-1.00|-1.91|-2.36, \n",
      "val_vector  : -0.25|-0.89|-1.27|-2.19|-2.12|-1.01|-1.89|-2.30\n",
      "\n",
      "epoch:27, train_loss: -0.815, val_loss: -1.440, \n",
      "train_vector: -0.15|-0.87|-1.23|-2.10|-2.18|-1.01|-1.92|-2.37, \n",
      "val_vector  : -0.37|-0.75|-1.29|-2.28|-2.09|-1.05|-1.97|-2.32\n",
      "\n",
      "epoch:28, train_loss: -0.826, val_loss: -1.445, \n",
      "train_vector: -0.15|-0.87|-1.24|-2.11|-2.19|-1.02|-1.93|-2.38, \n",
      "val_vector  : -0.08|-0.93|-1.30|-2.31|-2.16|-1.04|-1.99|-2.32\n",
      "\n",
      "epoch:29, train_loss: -0.845, val_loss: -1.502, \n",
      "train_vector: -0.16|-0.90|-1.25|-2.10|-2.20|-1.03|-1.94|-2.40, \n",
      "val_vector  : -0.41|-1.15|-1.31|-2.28|-2.17|-1.05|-1.91|-2.33\n",
      "\n",
      "epoch:30, train_loss: -0.867, val_loss: -1.362, \n",
      "train_vector: -0.19|-0.92|-1.27|-2.13|-2.22|-1.04|-1.95|-2.41, \n",
      "val_vector  : +0.27|-0.62|-1.28|-2.28|-2.19|-1.07|-2.03|-2.27\n",
      "\n",
      "epoch:31, train_loss: -0.879, val_loss: -1.498, \n",
      "train_vector: -0.19|-0.93|-1.27|-2.14|-2.23|-1.04|-1.96|-2.42, \n",
      "val_vector  : -0.28|-1.19|-1.30|-2.21|-2.17|-1.09|-1.98|-2.35\n",
      "\n",
      "epoch:32, train_loss: -0.896, val_loss: -1.354, \n",
      "train_vector: -0.21|-0.95|-1.28|-2.14|-2.24|-1.05|-1.97|-2.43, \n",
      "val_vector  : -0.12|-0.56|-1.32|-2.08|-2.21|-1.07|-1.79|-2.27\n",
      "\n",
      "epoch:33, train_loss: -0.910, val_loss: -1.367, \n",
      "train_vector: -0.22|-0.95|-1.29|-2.14|-2.25|-1.06|-1.98|-2.45, \n",
      "val_vector  : +0.27|-0.94|-1.30|-1.99|-2.19|-1.04|-2.00|-2.34\n",
      "\n",
      "epoch:34, train_loss: -0.922, val_loss: -1.484, \n",
      "train_vector: -0.22|-0.97|-1.30|-2.16|-2.26|-1.07|-1.98|-2.46, \n",
      "val_vector  : -0.11|-0.99|-1.33|-2.34|-2.22|-1.10|-2.04|-2.32\n",
      "\n",
      "epoch:35, train_loss: -0.934, val_loss: -1.405, \n",
      "train_vector: -0.21|-0.96|-1.31|-2.18|-2.27|-1.07|-2.00|-2.47, \n",
      "val_vector  : +0.22|-0.68|-1.32|-2.33|-2.22|-1.11|-2.02|-2.37\n",
      "\n",
      "epoch:36, train_loss: -1.113, val_loss: -1.596, \n",
      "train_vector: -0.37|-1.22|-1.38|-2.34|-2.45|-1.13|-2.12|-2.62, \n",
      "val_vector  : -0.50|-0.84|-1.42|-2.45|-2.37|-1.17|-2.12|-2.48\n",
      "\n",
      "epoch:37, train_loss: -1.143, val_loss: -1.685, \n",
      "train_vector: -0.38|-1.25|-1.40|-2.35|-2.49|-1.14|-2.14|-2.66, \n",
      "val_vector  : -0.53|-1.33|-1.43|-2.48|-2.41|-1.18|-2.19|-2.50\n",
      "\n",
      "epoch:38, train_loss: -1.168, val_loss: -1.635, \n",
      "train_vector: -0.40|-1.28|-1.41|-2.37|-2.51|-1.15|-2.15|-2.68, \n",
      "val_vector  : -0.46|-1.07|-1.44|-2.44|-2.41|-1.18|-2.14|-2.51\n",
      "\n",
      "epoch:39, train_loss: -1.181, val_loss: -1.660, \n",
      "train_vector: -0.42|-1.30|-1.41|-2.37|-2.53|-1.16|-2.16|-2.69, \n",
      "val_vector  : -0.28|-1.29|-1.44|-2.51|-2.40|-1.18|-2.19|-2.55\n",
      "\n",
      "epoch:40, train_loss: -1.192, val_loss: -1.637, \n",
      "train_vector: -0.41|-1.30|-1.42|-2.40|-2.53|-1.16|-2.16|-2.70, \n",
      "val_vector  : -0.53|-1.00|-1.43|-2.51|-2.39|-1.17|-2.13|-2.50\n",
      "\n",
      "epoch:41, train_loss: -1.205, val_loss: -1.642, \n",
      "train_vector: -0.42|-1.30|-1.43|-2.40|-2.54|-1.17|-2.17|-2.72, \n",
      "val_vector  : -0.30|-1.21|-1.44|-2.53|-2.36|-1.18|-2.21|-2.48\n",
      "\n",
      "epoch:42, train_loss: -1.219, val_loss: -1.696, \n",
      "train_vector: -0.43|-1.32|-1.43|-2.41|-2.56|-1.17|-2.18|-2.72, \n",
      "val_vector  : -0.56|-1.38|-1.45|-2.42|-2.40|-1.19|-2.19|-2.53\n",
      "\n",
      "epoch:43, train_loss: -1.226, val_loss: -1.699, \n",
      "train_vector: -0.44|-1.33|-1.44|-2.41|-2.56|-1.18|-2.18|-2.73, \n",
      "val_vector  : -0.51|-1.38|-1.45|-2.51|-2.43|-1.19|-2.15|-2.54\n",
      "\n",
      "epoch:44, train_loss: -1.234, val_loss: -1.685, \n",
      "train_vector: -0.43|-1.34|-1.44|-2.42|-2.57|-1.18|-2.19|-2.74, \n",
      "val_vector  : -0.43|-1.37|-1.45|-2.41|-2.46|-1.19|-2.20|-2.54\n",
      "\n",
      "epoch:45, train_loss: -1.246, val_loss: -1.713, \n",
      "train_vector: -0.45|-1.35|-1.44|-2.43|-2.58|-1.18|-2.19|-2.75, \n",
      "val_vector  : -0.53|-1.43|-1.47|-2.45|-2.45|-1.19|-2.20|-2.54\n",
      "\n",
      "epoch:46, train_loss: -1.256, val_loss: -1.694, \n",
      "train_vector: -0.46|-1.37|-1.45|-2.44|-2.58|-1.19|-2.20|-2.76, \n",
      "val_vector  : -0.59|-1.39|-1.46|-2.36|-2.35|-1.20|-2.23|-2.54\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:47, train_loss: -1.261, val_loss: -1.669, \n",
      "train_vector: -0.46|-1.36|-1.45|-2.43|-2.60|-1.19|-2.21|-2.76, \n",
      "val_vector  : -0.58|-1.20|-1.47|-2.24|-2.42|-1.21|-2.24|-2.56\n",
      "\n",
      "epoch:48, train_loss: -1.272, val_loss: -1.635, \n",
      "train_vector: -0.47|-1.38|-1.46|-2.45|-2.60|-1.20|-2.21|-2.77, \n",
      "val_vector  : -0.05|-1.17|-1.47|-2.53|-2.43|-1.21|-2.24|-2.55\n",
      "\n",
      "epoch:49, train_loss: -1.275, val_loss: -1.734, \n",
      "train_vector: -0.46|-1.37|-1.46|-2.45|-2.60|-1.20|-2.21|-2.77, \n",
      "val_vector  : -0.61|-1.43|-1.48|-2.51|-2.44|-1.20|-2.20|-2.56\n",
      "\n",
      "epoch:50, train_loss: -1.283, val_loss: -1.675, \n",
      "train_vector: -0.46|-1.38|-1.47|-2.46|-2.61|-1.20|-2.22|-2.78, \n",
      "val_vector  : -0.43|-1.11|-1.47|-2.52|-2.43|-1.22|-2.23|-2.56\n",
      "\n",
      "epoch:51, train_loss: -1.293, val_loss: -1.656, \n",
      "train_vector: -0.47|-1.40|-1.47|-2.45|-2.62|-1.20|-2.23|-2.79, \n",
      "val_vector  : -0.50|-1.20|-1.47|-2.25|-2.36|-1.22|-2.23|-2.57\n",
      "\n",
      "epoch:52, train_loss: -1.301, val_loss: -1.634, \n",
      "train_vector: -0.48|-1.39|-1.47|-2.47|-2.63|-1.21|-2.23|-2.80, \n",
      "val_vector  : -0.36|-1.03|-1.47|-2.45|-2.37|-1.22|-2.16|-2.57\n",
      "\n",
      "epoch:53, train_loss: -1.309, val_loss: -1.742, \n",
      "train_vector: -0.48|-1.41|-1.48|-2.47|-2.63|-1.21|-2.24|-2.80, \n",
      "val_vector  : -0.60|-1.39|-1.49|-2.53|-2.45|-1.23|-2.24|-2.57\n",
      "\n",
      "epoch:54, train_loss: -1.317, val_loss: -1.620, \n",
      "train_vector: -0.49|-1.42|-1.48|-2.48|-2.64|-1.21|-2.24|-2.81, \n",
      "val_vector  : -0.29|-0.89|-1.48|-2.54|-2.43|-1.23|-2.16|-2.51\n",
      "\n",
      "epoch:55, train_loss: -1.318, val_loss: -1.713, \n",
      "train_vector: -0.49|-1.40|-1.48|-2.47|-2.64|-1.22|-2.24|-2.81, \n",
      "val_vector  : -0.47|-1.23|-1.49|-2.55|-2.45|-1.23|-2.27|-2.58\n",
      "\n",
      "epoch:56, train_loss: -1.329, val_loss: -1.721, \n",
      "train_vector: -0.49|-1.42|-1.49|-2.49|-2.65|-1.22|-2.24|-2.82, \n",
      "val_vector  : -0.61|-1.42|-1.47|-2.30|-2.45|-1.22|-2.26|-2.59\n",
      "\n",
      "epoch:57, train_loss: -1.334, val_loss: -1.728, \n",
      "train_vector: -0.49|-1.42|-1.49|-2.49|-2.66|-1.22|-2.25|-2.82, \n",
      "val_vector  : -0.60|-1.34|-1.49|-2.48|-2.45|-1.23|-2.25|-2.56\n",
      "\n",
      "epoch:58, train_loss: -1.339, val_loss: -1.736, \n",
      "train_vector: -0.50|-1.42|-1.49|-2.49|-2.66|-1.23|-2.26|-2.83, \n",
      "val_vector  : -0.61|-1.42|-1.47|-2.41|-2.46|-1.24|-2.25|-2.58\n",
      "\n",
      "epoch:59, train_loss: -1.346, val_loss: -1.596, \n",
      "train_vector: -0.51|-1.44|-1.50|-2.48|-2.66|-1.23|-2.26|-2.84, \n",
      "val_vector  : +0.08|-0.99|-1.50|-2.50|-2.39|-1.23|-2.24|-2.56\n",
      "\n",
      "Training completed in 6447.1923797130585s\n"
     ]
    }
   ],
   "source": [
    "train_dl,val_dl = get_data(data,batch_size)\n",
    "\n",
    "model = GNN_multiHead(reuse,block,head,head_mol,head_atom,head_edge,\\\n",
    "                      dim,layer1,layer2,factor,**data_dict[data]).to('cuda:0')\n",
    "\n",
    "paras = trainable_parameter(model)\n",
    "opt = Adam(paras,lr=lr)\n",
    "scheduler = ReduceLROnPlateau(opt, 'min',factor=0.5,patience=5)\n",
    "\n",
    "model,train_loss_list,val_loss_list,bestWeight = train_type(opt,model,epochs,train_dl,val_dl,paras,clip,scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(train_loss_list,val_loss_list,reuse,block,\\\n",
    "             head,data,batch_size,dim,clip,layer1,layer2,factor,epochs)\n",
    "save_model_type(bestWeight,opt,reuse,block,head,data,batch_size,dim,clip,layer1,layer2,factor,epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_submission(reuse,block,head,data,batch_size,dim,clip,layer1,layer2,factor,epochs,postStr='base'):\n",
    "    # set up\n",
    "    model = GNN_multiHead(reuse,block,head,head_mol,head_atom,head_edge\\\n",
    "                          ,dim,layer1,layer2,factor,**data_dict[data]).to('cuda:0')\n",
    "    submission = pd.read_csv('../Data/sample_submission.csv')\n",
    "    \n",
    "    for i in range(8):\n",
    "        # load test data and type_id\n",
    "        with open(data.format('test').split('pickle')[0][:-1]+'_type_'+str(i)+'.pickle', 'rb') as handle:\n",
    "            test_data = pickle.load(handle)\n",
    "        test_list = [Data(**d) for d in test_data]\n",
    "        test_dl = DataLoader(test_list,batch_size,shuffle=False)\n",
    "        with open(data.format('test').split('pickle')[0][:-1]+'_id_type_'+str(i)+'.pickle', 'rb') as handle:\n",
    "            test_id = pickle.load(handle)\n",
    "    \n",
    "    \n",
    "        # load model\n",
    "        checkpoint = torch.load('../Model/{}.tar'.format('_'.join([str(i).split('}')[1] if '}' in str(i) else str(i) \\\n",
    "                                            for i in [reuse,block,head,data,batch_size,dim,clip,\\\n",
    "                                                  layer1,layer2,factor,epochs,'type_'+str(i)+postStr]])))\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    \n",
    "        # predict\n",
    "        model.eval()\n",
    "        yhat_list = []\n",
    "        with torch.no_grad():\n",
    "            for data_torch in test_dl:\n",
    "                data_torch = data_torch.to('cuda:0')\n",
    "                yhat_list.append(model(data_torch,False,True))\n",
    "        yhat = torch.cat(yhat_list).cpu().detach().numpy()        \n",
    "        \n",
    "        # join\n",
    "        submit_ = dict(zip(test_id,yhat))\n",
    "        submission['type_'+str(i)] = submission.id.map(submit_)\n",
    "    \n",
    "    # save types results    \n",
    "    submission.to_csv('../Submission/{}.csv'.format('_'.join([str(i).split('}')[1] if '}' in str(i) else str(i) \\\n",
    "                                        for i in [reuse,block,head,data,batch_size,dim,clip,\\\n",
    "                                              layer1,layer2,factor,epochs,'all_types'+postStr]])),\\\n",
    "                      index=False)\n",
    "    \n",
    "    # save final results for submission\n",
    "    submission['scalar_coupling_constant'] = submission.iloc[:,2:].mean(1)\n",
    "    submission = submission[['id','scalar_coupling_constant']]\n",
    "    \n",
    "    submission.to_csv('../Submission/{}.csv'.format('_'.join([str(i).split('}')[1] if '}' in str(i) else str(i) \\\n",
    "                                        for i in [reuse,block,head,data,batch_size,dim,clip,\\\n",
    "                                              layer1,layer2,factor,epochs,'final'+postStr]])),\\\n",
    "                      index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_submission(reuse,block,head,data,batch_size,dim,clip,layer1,layer2,factor,epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
