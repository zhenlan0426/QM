{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "from torch_geometric.data import Data,DataLoader\n",
    "from functions_refactor import *\n",
    "from pytorch_util import *\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixed parameters\n",
    "hyper_epoch = 50\n",
    "threshold = -1.15\n",
    "reuse = False\n",
    "block = MEGNet_block\n",
    "head_mol,head_atom,head_edge = head_mol,head_atom,head_edge\n",
    "epochs = 50\n",
    "batch_size = 32\n",
    "clip = 2\n",
    "lr = 1e-4\n",
    "epochs_type = epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(hyper_epoch):\n",
    "    # model parameters\n",
    "\n",
    "    head = np.random.choice([feedforwardHead_Update,feedforwardCombineHead_Update],p=[0.6,0.4])\n",
    "    data = np.random.choice(['../Data/{}_data_ACSF_expand_PCA_otherInfo.pickle',\\\n",
    "                             '../Data/{}_data_SOAP_expand_PCA_otherInfo.pickle',\\\n",
    "                             '../Data/{}_data_atomInfo_otherInfo.pickle'])\n",
    "    logLoss = np.random.choice([True,False])\n",
    "    weight = np.random.rand()*3 if logLoss else np.random.rand()*0.75\n",
    "    dim = int(np.random.choice([128,256,512]))\n",
    "    layer1 = int(np.random.choice([3,4,5]))\n",
    "    layer2 = int(np.random.choice([3,4,5]))\n",
    "    factor = int(np.random.choice([2,3,4]))\n",
    "    print('\\ntraining on {}\\n'.format('_'.join([str(i).split('}')[1] if '}' in str(i) else str(i) \\\n",
    "                                        for i in [head,data,dim,logLoss,weight,layer1,layer2,factor]])))\n",
    "\n",
    "    train_dl,val_dl = get_data(data,batch_size)\n",
    "    model = GNN_multiHead(reuse,block,head,head_mol,head_atom,head_edge,\\\n",
    "                          dim,layer1,layer2,factor,**data_dict[data]).to('cuda:0')\n",
    "    paras = trainable_parameter(model)\n",
    "    opt = Adam(paras,lr=lr)\n",
    "    scheduler = ReduceLROnPlateau(opt, 'min',factor=0.5,patience=5)\n",
    "    \n",
    "    model,train_loss_perType,val_loss_perType = train_type_earlyStop(opt,model,epochs_type,train_dl,val_dl,paras,clip,True,\\\n",
    "                                                                    scheduler=scheduler,logLoss=logLoss,weight=weight,threshold=threshold)\n",
    "    if model is not None:\n",
    "        save_results2(train_loss_list,val_loss_list,head,data,dim,logLoss,weight,layer1,layer2,factor)\n",
    "        save_model_type2(bestWeight,opt,head,data,dim,logLoss,weight,layer1,layer2,factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixed parameters\n",
    "hyper_epoch = 50\n",
    "threshold = -1.15\n",
    "reuse = False\n",
    "block = MEGNet_block\n",
    "head_mol,head_atom,head_edge = head_mol,head_atom,head_edge\n",
    "epochs = 1\n",
    "batch_size = 32\n",
    "clip = 2\n",
    "lr = 1e-4\n",
    "epochs_type = epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training on <class 'functions_refactor.feedforwardHead_Update'>__data_ACSF_expand_PCA_otherInfo.pickle_128_True_0.2831571741916332_3_3_3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in range(hyper_epoch):\n",
    "    # model parameters\n",
    "\n",
    "    head = np.random.choice([feedforwardHead_Update,feedforwardCombineHead_Update],p=[0.6,0.4])\n",
    "    data = '../Data/{}_data_ACSF_expand_PCA_otherInfo.pickle'\n",
    "    logLoss = np.random.choice([True,False])\n",
    "    weight = np.random.rand()*3 if logLoss else np.random.rand()*0.75\n",
    "    dim = int(np.random.choice([128,256,512]))\n",
    "    layer1 = int(np.random.choice([3,4,5]))\n",
    "    layer2 = int(np.random.choice([3,4,5]))\n",
    "    factor = int(np.random.choice([2,3,4]))\n",
    "    print('\\ntraining on {}\\n'.format('_'.join([str(i).split('}')[1] if '}' in str(i) else str(i) \\\n",
    "                                        for i in [head,data,dim,logLoss,weight,layer1,layer2,factor]])))\n",
    "\n",
    "    train_dl,val_dl = get_data(data,batch_size)\n",
    "    model = GNN_multiHead(reuse,block,head,head_mol,head_atom,head_edge,\\\n",
    "                          dim,layer1,layer2,factor,**data_dict[data]).to('cuda:0')\n",
    "    paras = trainable_parameter(model)\n",
    "    opt = Adam(paras,lr=lr)\n",
    "    scheduler = ReduceLROnPlateau(opt, 'min',factor=0.5,patience=5)\n",
    "    \n",
    "    model,train_loss_perType,val_loss_perType,bestWeight = train_type_earlyStop(opt,model,epochs_type,train_dl,val_dl,paras,clip,\\\n",
    "                                                                    scheduler=scheduler,logLoss=logLoss,weight=weight,threshold=threshold)\n",
    "    if model is not None:\n",
    "        save_results2(train_loss_perType,val_loss_perType,head,data,dim,logLoss,weight,layer1,layer2,factor)\n",
    "        save_model_type2(bestWeight,opt,head,data,dim,logLoss,weight,layer1,layer2,factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun(a,*c):\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, 4, 5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fun(1,2,3,4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loss_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-5a004d7586ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msave_results2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_loss_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlogLoss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfactor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_loss_list' is not defined"
     ]
    }
   ],
   "source": [
    "save_results2(train_loss_list,val_loss_list,head,data,dim,logLoss,weight,layer1,layer2,factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_loss_perType' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-a8bedd142de7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mval_loss_perType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'val_loss_perType' is not defined"
     ]
    }
   ],
   "source": [
    "val_loss_perType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
