{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "from torch_geometric.data import Data,DataLoader\n",
    "from functions_refactor import *\n",
    "from pytorch_util import *\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model parameters\n",
    "reuse = False\n",
    "block = MEGNet_block\n",
    "head = feedforwardHead_Update\n",
    "data = '../Data/{}_data_ACSF_expand_PCA.pickle'\n",
    "batch_size = 32\n",
    "dim = 128\n",
    "epochs = 50\n",
    "clip = 0.4\n",
    "layer1 = 3\n",
    "layer2 = 3\n",
    "factor = 2\n",
    "lr = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss: +0.353, val_loss: -0.137, \n",
      "train_vector: +4.19|+0.96|+0.12|-0.38|-0.58|+0.11|-0.62|-0.96, \n",
      "val_vector  : +3.88|+0.13|-0.32|-1.13|-1.07|-0.21|-1.05|-1.32\n",
      "\n",
      "epoch:1, train_loss: -0.340, val_loss: -0.694, \n",
      "train_vector: +2.08|+0.30|-0.33|-0.97|-1.10|-0.26|-1.06|-1.38, \n",
      "val_vector  : +0.52|-0.04|-0.53|-1.15|-1.33|-0.39|-1.09|-1.54\n",
      "\n",
      "epoch:2, train_loss: -0.655, val_loss: -0.823, \n",
      "train_vector: +0.87|+0.06|-0.50|-1.20|-1.30|-0.39|-1.21|-1.56, \n",
      "val_vector  : +0.38|-0.08|-0.59|-1.53|-1.30|-0.49|-1.30|-1.68\n",
      "\n",
      "epoch:3, train_loss: -0.777, val_loss: -0.884, \n",
      "train_vector: +0.78|-0.09|-0.62|-1.40|-1.43|-0.48|-1.31|-1.68, \n",
      "val_vector  : +0.84|-0.41|-0.73|-1.63|-1.53|-0.57|-1.44|-1.60\n",
      "\n",
      "epoch:4, train_loss: -0.849, val_loss: -0.876, \n",
      "train_vector: +0.74|-0.13|-0.70|-1.47|-1.53|-0.55|-1.40|-1.76, \n",
      "val_vector  : +0.79|-0.08|-0.80|-1.45|-1.61|-0.62|-1.41|-1.82\n",
      "\n",
      "epoch:5, train_loss: -0.908, val_loss: -0.987, \n",
      "train_vector: +0.70|-0.21|-0.77|-1.53|-1.59|-0.59|-1.45|-1.82, \n",
      "val_vector  : +0.53|-0.06|-0.84|-1.80|-1.61|-0.68|-1.58|-1.86\n",
      "\n",
      "epoch:6, train_loss: -0.964, val_loss: -1.154, \n",
      "train_vector: +0.68|-0.31|-0.82|-1.60|-1.65|-0.64|-1.50|-1.88, \n",
      "val_vector  : +0.17|-0.68|-0.93|-1.78|-1.72|-0.72|-1.65|-1.91\n",
      "\n",
      "epoch:7, train_loss: -1.015, val_loss: -1.171, \n",
      "train_vector: +0.61|-0.37|-0.86|-1.64|-1.70|-0.68|-1.55|-1.93, \n",
      "val_vector  : +0.05|-0.56|-0.95|-1.86|-1.63|-0.76|-1.67|-1.98\n",
      "\n",
      "epoch:8, train_loss: -1.064, val_loss: -1.159, \n",
      "train_vector: +0.53|-0.43|-0.90|-1.70|-1.75|-0.71|-1.59|-1.97, \n",
      "val_vector  : +0.16|-0.48|-0.95|-1.74|-1.78|-0.78|-1.73|-1.97\n",
      "\n",
      "epoch:9, train_loss: -1.108, val_loss: -1.076, \n",
      "train_vector: +0.46|-0.49|-0.94|-1.73|-1.79|-0.74|-1.63|-2.01, \n",
      "val_vector  : +0.06|+0.27|-1.03|-1.58|-1.79|-0.81|-1.68|-2.05\n",
      "\n",
      "epoch:10, train_loss: -1.136, val_loss: -1.221, \n",
      "train_vector: +0.40|-0.46|-0.97|-1.78|-1.82|-0.77|-1.64|-2.05, \n",
      "val_vector  : +0.23|-0.75|-1.06|-1.80|-1.86|-0.80|-1.75|-1.98\n",
      "\n",
      "epoch:11, train_loss: -1.174, val_loss: -1.218, \n",
      "train_vector: +0.32|-0.52|-1.00|-1.80|-1.85|-0.80|-1.67|-2.08, \n",
      "val_vector  : +0.33|-0.30|-1.09|-2.01|-1.91|-0.87|-1.82|-2.08\n",
      "\n",
      "epoch:12, train_loss: -1.203, val_loss: -1.125, \n",
      "train_vector: +0.27|-0.54|-1.02|-1.83|-1.87|-0.82|-1.70|-2.11, \n",
      "val_vector  : -0.08|+0.65|-1.09|-1.96|-1.83|-0.85|-1.74|-2.11\n",
      "\n",
      "epoch:13, train_loss: -1.233, val_loss: -1.223, \n",
      "train_vector: +0.22|-0.57|-1.05|-1.85|-1.91|-0.84|-1.73|-2.14, \n",
      "val_vector  : +0.04|-0.16|-1.10|-2.10|-1.80|-0.89|-1.74|-2.04\n",
      "\n",
      "epoch:14, train_loss: -1.262, val_loss: -1.278, \n",
      "train_vector: +0.17|-0.60|-1.07|-1.89|-1.93|-0.86|-1.75|-2.16, \n",
      "val_vector  : +0.16|-0.38|-1.11|-2.10|-1.93|-0.92|-1.80|-2.14\n",
      "\n",
      "epoch:15, train_loss: -1.291, val_loss: -1.407, \n",
      "train_vector: +0.12|-0.66|-1.09|-1.91|-1.95|-0.88|-1.77|-2.19, \n",
      "val_vector  : -0.24|-0.82|-1.14|-2.08|-2.00|-0.95|-1.85|-2.17\n",
      "\n",
      "epoch:16, train_loss: -1.314, val_loss: -1.285, \n",
      "train_vector: +0.10|-0.70|-1.11|-1.91|-1.99|-0.90|-1.79|-2.22, \n",
      "val_vector  : +0.01|-0.44|-1.15|-1.81|-1.91|-0.95|-1.85|-2.18\n",
      "\n",
      "epoch:17, train_loss: -1.333, val_loss: -1.332, \n",
      "train_vector: +0.07|-0.70|-1.13|-1.93|-2.01|-0.92|-1.81|-2.23, \n",
      "val_vector  : -0.17|-0.67|-1.17|-1.77|-1.94|-0.97|-1.84|-2.13\n",
      "\n",
      "epoch:18, train_loss: -1.353, val_loss: -1.402, \n",
      "train_vector: +0.04|-0.70|-1.15|-1.96|-2.03|-0.93|-1.83|-2.26, \n",
      "val_vector  : -0.29|-0.48|-1.20|-2.17|-2.00|-0.98|-1.93|-2.17\n",
      "\n",
      "epoch:19, train_loss: -1.368, val_loss: -1.411, \n",
      "train_vector: +0.03|-0.72|-1.16|-1.97|-2.04|-0.95|-1.85|-2.28, \n",
      "val_vector  : -0.22|-0.73|-1.22|-2.06|-1.99|-0.97|-1.94|-2.15\n",
      "\n",
      "epoch:20, train_loss: -1.388, val_loss: -1.385, \n",
      "train_vector: -0.00|-0.76|-1.18|-1.98|-2.06|-0.96|-1.87|-2.30, \n",
      "val_vector  : -0.01|-0.48|-1.22|-2.06|-2.09|-1.02|-1.93|-2.26\n",
      "\n",
      "epoch:21, train_loss: -1.406, val_loss: -1.357, \n",
      "train_vector: -0.03|-0.78|-1.19|-1.99|-2.08|-0.98|-1.88|-2.31, \n",
      "val_vector  : -0.31|+0.08|-1.25|-2.14|-2.05|-1.03|-1.93|-2.23\n",
      "\n",
      "epoch:22, train_loss: -1.424, val_loss: -1.396, \n",
      "train_vector: -0.05|-0.79|-1.21|-2.02|-2.10|-0.99|-1.90|-2.33, \n",
      "val_vector  : +0.50|-0.90|-1.26|-2.14|-2.14|-1.03|-1.91|-2.28\n",
      "\n",
      "epoch:23, train_loss: -1.442, val_loss: -1.354, \n",
      "train_vector: -0.06|-0.82|-1.22|-2.05|-2.12|-1.00|-1.91|-2.35, \n",
      "val_vector  : +0.42|-0.50|-1.27|-2.09|-2.13|-1.04|-1.92|-2.31\n",
      "\n",
      "epoch:24, train_loss: -1.454, val_loss: -1.467, \n",
      "train_vector: -0.09|-0.84|-1.23|-2.04|-2.12|-1.01|-1.93|-2.36, \n",
      "val_vector  : -0.19|-1.03|-1.29|-1.91|-2.11|-1.04|-1.86|-2.30\n",
      "\n",
      "epoch:25, train_loss: -1.463, val_loss: -1.516, \n",
      "train_vector: -0.09|-0.82|-1.25|-2.06|-2.15|-1.03|-1.94|-2.38, \n",
      "val_vector  : -0.33|-0.85|-1.31|-2.20|-2.14|-1.07|-1.91|-2.31\n",
      "\n",
      "epoch:26, train_loss: -1.479, val_loss: -1.523, \n",
      "train_vector: -0.10|-0.85|-1.26|-2.08|-2.16|-1.04|-1.95|-2.40, \n",
      "val_vector  : -0.41|-0.88|-1.30|-2.20|-2.05|-1.07|-1.97|-2.30\n",
      "\n",
      "epoch:27, train_loss: -1.496, val_loss: -1.368, \n",
      "train_vector: -0.13|-0.88|-1.27|-2.08|-2.18|-1.05|-1.97|-2.41, \n",
      "val_vector  : +0.54|-0.49|-1.28|-2.25|-2.14|-1.09|-1.95|-2.28\n",
      "\n",
      "epoch:28, train_loss: -1.511, val_loss: -1.495, \n",
      "train_vector: -0.15|-0.88|-1.28|-2.12|-2.19|-1.06|-1.98|-2.42, \n",
      "val_vector  : -0.37|-0.43|-1.34|-2.20|-2.17|-1.11|-1.96|-2.38\n",
      "\n",
      "epoch:29, train_loss: -1.514, val_loss: -1.480, \n",
      "train_vector: -0.15|-0.89|-1.29|-2.11|-2.20|-1.07|-1.98|-2.44, \n",
      "val_vector  : -0.03|-0.87|-1.34|-2.03|-2.11|-1.11|-2.00|-2.35\n",
      "\n",
      "epoch:30, train_loss: -1.527, val_loss: -1.523, \n",
      "train_vector: -0.16|-0.89|-1.30|-2.12|-2.21|-1.08|-2.00|-2.45, \n",
      "val_vector  : -0.30|-0.58|-1.32|-2.26|-2.20|-1.11|-2.06|-2.35\n",
      "\n",
      "epoch:31, train_loss: -1.541, val_loss: -1.501, \n",
      "train_vector: -0.18|-0.92|-1.31|-2.13|-2.23|-1.08|-2.01|-2.46, \n",
      "val_vector  : -0.14|-0.68|-1.34|-2.22|-2.08|-1.11|-2.05|-2.38\n",
      "\n",
      "epoch:32, train_loss: -1.552, val_loss: -1.386, \n",
      "train_vector: -0.18|-0.91|-1.33|-2.17|-2.24|-1.09|-2.02|-2.48, \n",
      "val_vector  : +0.48|-0.36|-1.34|-2.30|-2.01|-1.10|-2.08|-2.38\n",
      "\n",
      "epoch:33, train_loss: -1.562, val_loss: -1.621, \n",
      "train_vector: -0.20|-0.91|-1.34|-2.16|-2.25|-1.10|-2.03|-2.49, \n",
      "val_vector  : -0.45|-1.03|-1.37|-2.31|-2.22|-1.15|-2.04|-2.41\n",
      "\n",
      "epoch:34, train_loss: -1.575, val_loss: -1.565, \n",
      "train_vector: -0.21|-0.95|-1.34|-2.17|-2.26|-1.11|-2.04|-2.50, \n",
      "val_vector  : -0.40|-0.74|-1.38|-2.34|-2.17|-1.11|-2.09|-2.29\n",
      "\n",
      "epoch:35, train_loss: -1.579, val_loss: -1.604, \n",
      "train_vector: -0.20|-0.94|-1.35|-2.18|-2.27|-1.12|-2.05|-2.51, \n",
      "val_vector  : -0.49|-0.95|-1.35|-2.24|-2.12|-1.15|-2.12|-2.39\n",
      "\n",
      "epoch:36, train_loss: -1.591, val_loss: -1.473, \n",
      "train_vector: -0.23|-0.96|-1.36|-2.18|-2.29|-1.13|-2.06|-2.53, \n",
      "val_vector  : -0.05|-0.36|-1.39|-2.29|-2.07|-1.15|-2.07|-2.40\n",
      "\n",
      "epoch:37, train_loss: -1.601, val_loss: -1.594, \n",
      "train_vector: -0.24|-0.98|-1.37|-2.20|-2.29|-1.14|-2.07|-2.53, \n",
      "val_vector  : -0.26|-0.98|-1.41|-2.25|-2.27|-1.17|-2.03|-2.38\n",
      "\n",
      "epoch:38, train_loss: -1.606, val_loss: -1.600, \n",
      "train_vector: -0.23|-0.97|-1.38|-2.21|-2.30|-1.14|-2.07|-2.55, \n",
      "val_vector  : -0.50|-0.67|-1.42|-2.34|-2.13|-1.17|-2.14|-2.42\n",
      "\n",
      "epoch:39, train_loss: -1.625, val_loss: -1.318, \n",
      "train_vector: -0.26|-1.02|-1.39|-2.22|-2.32|-1.15|-2.09|-2.56, \n",
      "val_vector  : +0.68|-0.04|-1.39|-2.18|-2.24|-1.15|-1.87|-2.34\n",
      "\n",
      "epoch:40, train_loss: -1.762, val_loss: -1.738, \n",
      "train_vector: -0.40|-1.22|-1.46|-2.39|-2.50|-1.21|-2.21|-2.72, \n",
      "val_vector  : -0.50|-1.17|-1.49|-2.39|-2.38|-1.23|-2.18|-2.55\n",
      "\n",
      "epoch:41, train_loss: -1.800, val_loss: -1.733, \n",
      "train_vector: -0.44|-1.30|-1.48|-2.41|-2.54|-1.22|-2.23|-2.76, \n",
      "val_vector  : -0.24|-1.19|-1.49|-2.51|-2.43|-1.24|-2.24|-2.53\n",
      "\n",
      "epoch:42, train_loss: -1.813, val_loss: -1.721, \n",
      "train_vector: -0.45|-1.32|-1.49|-2.42|-2.57|-1.23|-2.25|-2.78, \n",
      "val_vector  : -0.25|-1.06|-1.49|-2.49|-2.41|-1.23|-2.27|-2.57\n",
      "\n",
      "epoch:43, train_loss: -1.820, val_loss: -1.779, \n",
      "train_vector: -0.45|-1.32|-1.50|-2.43|-2.58|-1.23|-2.25|-2.80, \n",
      "val_vector  : -0.44|-1.38|-1.51|-2.40|-2.45|-1.25|-2.24|-2.55\n",
      "\n",
      "epoch:44, train_loss: -1.833, val_loss: -1.793, \n",
      "train_vector: -0.46|-1.36|-1.50|-2.43|-2.59|-1.24|-2.26|-2.81, \n",
      "val_vector  : -0.43|-1.38|-1.50|-2.46|-2.46|-1.25|-2.27|-2.57\n",
      "\n",
      "epoch:45, train_loss: -1.844, val_loss: -1.832, \n",
      "train_vector: -0.48|-1.36|-1.51|-2.46|-2.60|-1.25|-2.27|-2.82, \n",
      "val_vector  : -0.55|-1.52|-1.52|-2.53|-2.44|-1.26|-2.24|-2.60\n",
      "\n",
      "epoch:46, train_loss: -1.849, val_loss: -1.655, \n",
      "train_vector: -0.48|-1.38|-1.52|-2.46|-2.61|-1.25|-2.28|-2.83, \n",
      "val_vector  : -0.63|-0.25|-1.50|-2.43|-2.38|-1.26|-2.25|-2.55\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:47, train_loss: -1.856, val_loss: -1.769, \n",
      "train_vector: -0.49|-1.38|-1.52|-2.46|-2.62|-1.25|-2.29|-2.83, \n",
      "val_vector  : -0.37|-1.26|-1.52|-2.51|-2.43|-1.26|-2.22|-2.58\n",
      "\n",
      "epoch:48, train_loss: -1.859, val_loss: -1.792, \n",
      "train_vector: -0.49|-1.37|-1.52|-2.47|-2.63|-1.26|-2.29|-2.84, \n",
      "val_vector  : -0.59|-1.34|-1.52|-2.33|-2.41|-1.26|-2.29|-2.60\n",
      "\n",
      "epoch:49, train_loss: -1.865, val_loss: -1.825, \n",
      "train_vector: -0.50|-1.38|-1.53|-2.48|-2.63|-1.26|-2.30|-2.84, \n",
      "val_vector  : -0.49|-1.41|-1.53|-2.54|-2.48|-1.28|-2.29|-2.59\n",
      "\n",
      "Training completed in 4058.0178639888763s\n"
     ]
    }
   ],
   "source": [
    "train_dl,val_dl = get_data(data,batch_size)\n",
    "\n",
    "model = GNN_multiHead_interleave(reuse,block,head,head_mol,head_atom,head_edge,\\\n",
    "                                 dim,layer1,layer2,factor,**data_dict[data],interleave=True).to('cuda:0')\n",
    "\n",
    "paras = trainable_parameter(model)\n",
    "opt = Adam(paras,lr=lr)\n",
    "scheduler = ReduceLROnPlateau(opt, 'min',factor=0.5,patience=5)\n",
    "\n",
    "model,train_loss_list,val_loss_list,bestWeight = train_type(opt,model,epochs,train_dl,val_dl,paras,clip,scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(train_loss_list,val_loss_list,reuse,block,\\\n",
    "             head,data,batch_size,dim,clip,layer1,layer2,factor,epochs,postStr='_interleave')\n",
    "save_model_type(bestWeight,opt,reuse,block,head,data,batch_size,dim,clip,layer1,layer2,factor,epochs,postStr='_interleave')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_submission(reuse,block,head,data,batch_size,dim,clip,layer1,layer2,factor,epochs,postStr='base'):\n",
    "    # set up\n",
    "    model = GNN_edgeUpdate(reuse,block,head,dim,layer1,layer2,factor,**data_dict[data]).to('cuda:0')\n",
    "    submission = pd.read_csv('../Data/sample_submission.csv')\n",
    "    \n",
    "    for i in range(8):\n",
    "        # load test data and type_id\n",
    "        with open(data.format('test').split('pickle')[0][:-1]+'_type_'+str(i)+'.pickle', 'rb') as handle:\n",
    "            test_data = pickle.load(handle)\n",
    "        test_list = [Data(**d) for d in test_data]\n",
    "        test_dl = DataLoader(test_list,batch_size,shuffle=False)\n",
    "        with open(data.format('test').split('pickle')[0][:-1]+'_id_type_'+str(i)+'.pickle', 'rb') as handle:\n",
    "            test_id = pickle.load(handle)\n",
    "    \n",
    "    \n",
    "        # load model\n",
    "        checkpoint = torch.load('../Model/{}.tar'.format('_'.join([str(i).split('}')[1] if '}' in str(i) else str(i) \\\n",
    "                                            for i in [reuse,block,head,data,batch_size,dim,clip,\\\n",
    "                                                  layer1,layer2,factor,epochs,'type_'+str(i)+postStr]])))\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    \n",
    "        # predict\n",
    "        model.eval()\n",
    "        yhat_list = []\n",
    "        with torch.no_grad():\n",
    "            for data_torch in test_dl:\n",
    "                data_torch = data_torch.to('cuda:0')\n",
    "                yhat_list.append(model(data_torch,False,True))\n",
    "        yhat = torch.cat(yhat_list).cpu().detach().numpy()        \n",
    "        \n",
    "        # join\n",
    "        submit_ = dict(zip(test_id,yhat))\n",
    "        submission['type_'+str(i)] = submission.id.map(submit_)\n",
    "    \n",
    "    # save types results    \n",
    "    submission.to_csv('../Submission/{}.csv'.format('_'.join([str(i).split('}')[1] if '}' in str(i) else str(i) \\\n",
    "                                        for i in [reuse,block,head,data,batch_size,dim,clip,\\\n",
    "                                              layer1,layer2,factor,epochs,'all_types'+postStr]])),\\\n",
    "                      index=False)\n",
    "    \n",
    "    # save final results for submission\n",
    "    submission['scalar_coupling_constant'] = submission.iloc[:,2:].mean(1)\n",
    "    submission = submission[['id','scalar_coupling_constant']]\n",
    "    \n",
    "    submission.to_csv('../Submission/{}.csv'.format('_'.join([str(i).split('}')[1] if '}' in str(i) else str(i) \\\n",
    "                                        for i in [reuse,block,head,data,batch_size,dim,clip,\\\n",
    "                                              layer1,layer2,factor,epochs,'final'+postStr]])),\\\n",
    "                      index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_submission(reuse,block,head,data,batch_size,dim,clip,layer1,layer2,factor,epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
