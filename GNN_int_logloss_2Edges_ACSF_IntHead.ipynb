{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch_geometric.data import Data,DataLoader\n",
    "from functions import *\n",
    "from pytorch_util import *\n",
    "from torch.optim import Adam\n",
    "from torch.nn.utils import clip_grad_value_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Data/train_data_ACSF.pickle', 'rb') as handle:\n",
    "    train_data = pickle.load(handle)\n",
    "with open('../Data/val_data_ACSF.pickle', 'rb') as handle:\n",
    "    val_data = pickle.load(handle)\n",
    "with open('../Data/test_data_ACSF.pickle', 'rb') as handle:\n",
    "    test_data = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### parameters ###\n",
    "batch_size = 32\n",
    "dim = 64\n",
    "edge_dim = 12\n",
    "epochs = 5\n",
    "clip = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = [Data(**d) for d in train_data]\n",
    "train_dl = DataLoader(train_list,batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_list = [Data(**d) for d in val_data]\n",
    "valid_dl = DataLoader(val_list,batch_size,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = [Data(**d) for d in test_data]\n",
    "test_dl = DataLoader(test_list,batch_size,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_int_2Edges_intHead(torch.nn.Module):\n",
    "    # use both types of edges\n",
    "    def __init__(self,dim=64,edge_dim=12,node_in=8,edge_in=19,edge_in3=8):\n",
    "        super(Net_int_2Edges_intHead, self).__init__()\n",
    "        self.lin_node = torch.nn.Linear(node_in, dim)\n",
    "        self.lin_edge_attr = torch.nn.Linear(edge_in, edge_dim)\n",
    "        \n",
    "        nn1 = Linear(edge_dim, dim * dim, bias=False)\n",
    "        nn2 = Linear(edge_in3, dim * dim * 2 * 2, bias=False)\n",
    "        \n",
    "        self.conv1 = NNConv(dim, dim, nn1, aggr='mean', root_weight=False)\n",
    "        self.gru1 = GRU(dim, dim)\n",
    "        self.lin_covert = Sequential(BatchNorm1d(dim),Linear(dim, dim*2), \\\n",
    "                                     RReLU(), Dropout(),Linear(dim*2, dim*2),RReLU())\n",
    "        \n",
    "        self.conv2 = NNConv(dim*2, dim*2, nn2, aggr='mean', root_weight=False)\n",
    "        self.gru2 = GRU(dim*2, dim*2)\n",
    "        \n",
    "        self.head = InteractionNet2(edge_in3,[dim*3*2,dim*2,1],[F.relu,None])\n",
    "        \n",
    "        self.norm = BatchNorm1d(dim*3*2)\n",
    "        self.norm_x = BatchNorm1d(node_in)\n",
    "        \n",
    "    def forward(self, data,IsTrain=False):\n",
    "        out = F.rrelu(self.lin_node(self.norm_x(data.x)))\n",
    "        edge_attr = F.rrelu(self.lin_edge_attr(data.edge_attr))\n",
    "        h = out.unsqueeze(0)\n",
    "        # edge_*3 only does not repeat for undirected graph. Hence need to add (j,i) to (i,j) in edges\n",
    "        edge_index3 = torch.cat([data.edge_index3,data.edge_index3[[1,0]]],1)\n",
    "        edge_attr3 = torch.cat([data.edge_attr3,data.edge_attr3],0)\n",
    "        \n",
    "        for i in range(2):\n",
    "            # using bonding as edge\n",
    "            m = F.rrelu(self.conv1(out, data.edge_index, edge_attr))\n",
    "            out, h = self.gru1(m.unsqueeze(0), h)\n",
    "            out = out.squeeze(0)\n",
    "        \n",
    "        out = self.lin_covert(out)\n",
    "        h = out.unsqueeze(0)\n",
    "        for i in range(2):\n",
    "            # using couping as edge\n",
    "            m = F.rrelu(self.conv2(out, edge_index3, edge_attr3))\n",
    "            out, h = self.gru2(m.unsqueeze(0), h)\n",
    "            out = out.squeeze(0)     \n",
    "            \n",
    "        temp = out[data.edge_index3] # (2,N,d)\n",
    "        yhat = torch.cat([temp.mean(0),temp[0]*temp[1],(temp[0]-temp[1])**2],1)\n",
    "        yhat = self.norm(yhat)\n",
    "        yhat = self.head(data.edge_attr3,yhat)\n",
    "        yhat = yhat.squeeze(1)\n",
    "        \n",
    "        if IsTrain:\n",
    "            k = torch.sum(data.edge_attr3,0)\n",
    "            nonzeroIndex = torch.nonzero(k).squeeze(1)\n",
    "            abs_ = torch.abs(data.y-yhat).unsqueeze(1)\n",
    "            loss = torch.sum(torch.log(torch.sum(abs_ * data.edge_attr3[:,nonzeroIndex],0)/k[nonzeroIndex]))/nonzeroIndex.shape[0]\n",
    "            return loss\n",
    "        else:\n",
    "            return yhat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_int_2Edges_pool_intHead(torch.nn.Module):\n",
    "    # use set2set for global pooling and cat results with local features\n",
    "    def __init__(self,dim=64,edge_dim=12,node_in=8,edge_in=19,edge_in3=8):\n",
    "        super(Net_int_2Edges_pool_intHead, self).__init__()\n",
    "        self.lin_node = torch.nn.Linear(node_in, dim)\n",
    "        self.lin_edge_attr = torch.nn.Linear(edge_in, edge_dim)\n",
    "        \n",
    "        nn1 = Linear(edge_dim, dim * dim, bias=False)\n",
    "        nn2 = Linear(edge_in3, dim * dim * 2 * 2, bias=False)\n",
    "        \n",
    "        self.conv1 = NNConv(dim, dim, nn1, aggr='mean', root_weight=False)\n",
    "        self.gru1 = GRU(dim, dim)\n",
    "        self.lin_covert = Sequential(BatchNorm1d(dim),Linear(dim, dim*2), \\\n",
    "                                     RReLU(), Dropout(),Linear(dim*2, dim*2),RReLU())\n",
    "        \n",
    "        self.conv2 = NNConv(dim*2, dim*2, nn2, aggr='mean', root_weight=False)\n",
    "        self.gru2 = GRU(dim*2, dim*2)\n",
    "        \n",
    "        self.head = InteractionNet2(edge_in3,[dim*5*2,dim*2,1],[F.relu,None])\n",
    "        \n",
    "        self.norm = BatchNorm1d(dim*5*2)\n",
    "        self.norm_x = BatchNorm1d(node_in)\n",
    "        self.set2set = Set2Set(dim*2,processing_steps=3)\n",
    "        \n",
    "    def forward(self, data,IsTrain=False):\n",
    "        out = F.rrelu(self.lin_node(self.norm_x(data.x)))\n",
    "        edge_attr = F.rrelu(self.lin_edge_attr(data.edge_attr))\n",
    "        h = out.unsqueeze(0)\n",
    "        # edge_*3 only does not repeat for undirected graph. Hence need to add (j,i) to (i,j) in edges\n",
    "        edge_index3 = torch.cat([data.edge_index3,data.edge_index3[[1,0]]],1)\n",
    "        edge_attr3 = torch.cat([data.edge_attr3,data.edge_attr3],0)\n",
    "        \n",
    "        for i in range(2):\n",
    "            # using bonding as edge\n",
    "            m = F.rrelu(self.conv1(out, data.edge_index, edge_attr))\n",
    "            out, h = self.gru1(m.unsqueeze(0), h)\n",
    "            out = out.squeeze(0)\n",
    "        \n",
    "        out = self.lin_covert(out)\n",
    "        h = out.unsqueeze(0)\n",
    "        for i in range(2):\n",
    "            # using couping as edge\n",
    "            m = F.rrelu(self.conv2(out, edge_index3, edge_attr3))\n",
    "            out, h = self.gru2(m.unsqueeze(0), h)\n",
    "            out = out.squeeze(0)  \n",
    "            \n",
    "        coupling_batch_index = data.batch[data.edge_index3[0]]\n",
    "        pool = self.set2set(out, data.batch) # (m,d)\n",
    "        pool = pool[coupling_batch_index] # (n_target,d)\n",
    "        temp = out[data.edge_index3] # (2,n_target,d)\n",
    "        yhat = torch.cat([temp.mean(0),temp[0]*temp[1],(temp[0]-temp[1])**2,pool],1)  \n",
    "        \n",
    "        yhat = self.norm(yhat)\n",
    "        yhat = self.head(data.edge_attr3,yhat)\n",
    "        yhat = yhat.squeeze(1)\n",
    "        \n",
    "        if IsTrain:\n",
    "            k = torch.sum(data.edge_attr3,0)\n",
    "            nonzeroIndex = torch.nonzero(k).squeeze(1)\n",
    "            abs_ = torch.abs(data.y-yhat).unsqueeze(1)\n",
    "            loss = torch.sum(torch.log(torch.sum(abs_ * data.edge_attr3[:,nonzeroIndex],0)/k[nonzeroIndex]))/nonzeroIndex.shape[0]\n",
    "            return loss\n",
    "        else:\n",
    "            return yhat  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_int_2Edges_pool_intHead2(torch.nn.Module):\n",
    "    # use set2set for global pooling and cat results with local features\n",
    "    def __init__(self,dim=64,edge_dim=12,node_in=8,edge_in=19,edge_in3=8):\n",
    "        super(Net_int_2Edges_pool_intHead2, self).__init__()\n",
    "        self.lin_node = torch.nn.Linear(node_in, dim)\n",
    "        self.lin_edge_attr = torch.nn.Linear(edge_in, edge_dim)\n",
    "        \n",
    "        nn1 = Linear(edge_dim, dim * dim, bias=False)\n",
    "        nn2 = Linear(edge_in3, dim * dim * 2 * 2, bias=False)\n",
    "        \n",
    "        self.conv1 = NNConv(dim, dim, nn1, aggr='mean', root_weight=False)\n",
    "        self.gru1 = GRU(dim, dim)\n",
    "        self.lin_covert = Sequential(BatchNorm1d(dim),Linear(dim, dim*2), \\\n",
    "                                     RReLU(), Dropout(),Linear(dim*2, dim*2),RReLU())\n",
    "        \n",
    "        self.conv2 = NNConv(dim*2, dim*2, nn2, aggr='mean', root_weight=False)\n",
    "        self.gru2 = GRU(dim*2, dim*2)\n",
    "        \n",
    "        self.head = InteractionNet2(edge_in3+dim*4,[dim*3*2,dim,1],[F.relu,None])\n",
    "        \n",
    "        self.norm = BatchNorm1d(dim*3*2)\n",
    "        self.norm_x = BatchNorm1d(node_in)\n",
    "        self.set2set = Set2Set(dim*2,processing_steps=3)\n",
    "        \n",
    "    def forward(self, data,IsTrain=False):\n",
    "        out = F.rrelu(self.lin_node(self.norm_x(data.x)))\n",
    "        edge_attr = F.rrelu(self.lin_edge_attr(data.edge_attr))\n",
    "        h = out.unsqueeze(0)\n",
    "        # edge_*3 only does not repeat for undirected graph. Hence need to add (j,i) to (i,j) in edges\n",
    "        edge_index3 = torch.cat([data.edge_index3,data.edge_index3[[1,0]]],1)\n",
    "        edge_attr3 = torch.cat([data.edge_attr3,data.edge_attr3],0)\n",
    "        \n",
    "        for i in range(2):\n",
    "            # using bonding as edge\n",
    "            m = F.rrelu(self.conv1(out, data.edge_index, edge_attr))\n",
    "            out, h = self.gru1(m.unsqueeze(0), h)\n",
    "            out = out.squeeze(0)\n",
    "        \n",
    "        out = self.lin_covert(out)\n",
    "        h = out.unsqueeze(0)\n",
    "        for i in range(2):\n",
    "            # using couping as edge\n",
    "            m = F.rrelu(self.conv2(out, edge_index3, edge_attr3))\n",
    "            out, h = self.gru2(m.unsqueeze(0), h)\n",
    "            out = out.squeeze(0)  \n",
    "            \n",
    "        coupling_batch_index = data.batch[data.edge_index3[0]]\n",
    "        pool = self.set2set(out, data.batch) # (m,d)\n",
    "        pool = pool[coupling_batch_index] # (n_target,d)\n",
    "        temp = out[data.edge_index3] # (2,n_target,d)\n",
    "        yhat = torch.cat([temp.mean(0),temp[0]*temp[1],(temp[0]-temp[1])**2],1)  \n",
    "        \n",
    "        yhat = self.norm(yhat)\n",
    "        yhat = self.head(torch.cat([data.edge_attr3,pool],1),yhat)\n",
    "        yhat = yhat.squeeze(1)\n",
    "        \n",
    "        if IsTrain:\n",
    "            k = torch.sum(data.edge_attr3,0)\n",
    "            nonzeroIndex = torch.nonzero(k).squeeze(1)\n",
    "            abs_ = torch.abs(data.y-yhat).unsqueeze(1)\n",
    "            loss = torch.sum(torch.log(torch.sum(abs_ * data.edge_attr3[:,nonzeroIndex],0)/k[nonzeroIndex]))/nonzeroIndex.shape[0]\n",
    "            return loss\n",
    "        else:\n",
    "            return yhat  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build model and set up training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#model = Net_int_2Edges_intHead(dim=dim,edge_dim=edge_dim,node_in=89).to('cuda:0')\n",
    "#model = Net_int_2Edges_pool_intHead(dim=dim,edge_dim=edge_dim,node_in=89).to('cuda:0')\n",
    "model = Net_int_2Edges_pool_intHead2(dim=dim,edge_dim=edge_dim,node_in=89).to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "paras = trainable_parameter(model)\n",
    "opt = Adam(paras,lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:0.7873947438198408, val_loss:0.3341339266516714\n",
      "epoch:1, train_loss:0.36166528322119446, val_loss:0.24919676350859496\n",
      "epoch:2, train_loss:0.22757536750312368, val_loss:0.10041901867231752\n",
      "epoch:3, train_loss:0.1381506137720215, val_loss:-0.02990294844469326\n",
      "epoch:4, train_loss:0.0665987360708085, val_loss:0.04686835084237859\n",
      "Training completed in 575.0818157196045s\n"
     ]
    }
   ],
   "source": [
    "# Net_int_2Edges_pool_intHead2\n",
    "since = time.time()\n",
    "opt.zero_grad()\n",
    "for epoch in range(epochs):\n",
    "    # training #\n",
    "    model.train()\n",
    "    np.random.seed()\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    \n",
    "    for i,data in enumerate(train_dl):\n",
    "        data = data.to('cuda:0')\n",
    "        loss = model(data,True)\n",
    "        loss.backward()\n",
    "        clip_grad_value_(paras,clip)\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # evaluating #\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for j,data in enumerate(valid_dl):\n",
    "            data = data.to('cuda:0')\n",
    "            loss = model(data,True)\n",
    "            val_loss += loss.item()\n",
    "    print('epoch:{}, train_loss:{}, val_loss:{}'.format(epoch,train_loss/i,val_loss/j))\n",
    "    \n",
    "time_elapsed = time.time() - since\n",
    "print('Training completed in {}s'.format(time_elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:0.00524437175761307, val_loss:-0.11224827195048077\n",
      "epoch:1, train_loss:-0.04776853368888857, val_loss:-0.13469644623179722\n",
      "epoch:2, train_loss:-0.09216798324637016, val_loss:-0.19477214771681106\n",
      "epoch:3, train_loss:-0.13292237297279627, val_loss:-0.24870299455574435\n",
      "epoch:4, train_loss:-0.16989954037035662, val_loss:-0.29617804620001054\n",
      "Training completed in 645.3577108383179s\n"
     ]
    }
   ],
   "source": [
    "# Net_int_2Edges_pool_intHead2\n",
    "since = time.time()\n",
    "opt.zero_grad()\n",
    "for epoch in range(epochs):\n",
    "    # training #\n",
    "    model.train()\n",
    "    np.random.seed()\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    \n",
    "    for i,data in enumerate(train_dl):\n",
    "        data = data.to('cuda:0')\n",
    "        loss = model(data,True)\n",
    "        loss.backward()\n",
    "        clip_grad_value_(paras,clip)\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # evaluating #\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for j,data in enumerate(valid_dl):\n",
    "            data = data.to('cuda:0')\n",
    "            loss = model(data,True)\n",
    "            val_loss += loss.item()\n",
    "    print('epoch:{}, train_loss:{}, val_loss:{}'.format(epoch,train_loss/i,val_loss/j))\n",
    "    \n",
    "time_elapsed = time.time() - since\n",
    "print('Training completed in {}s'.format(time_elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:-0.20147026187489445, val_loss:-0.3301054004293222\n",
      "epoch:1, train_loss:-0.231122358219641, val_loss:-0.35216580302669453\n",
      "epoch:2, train_loss:-0.25693018601250855, val_loss:-0.3782724665525632\n",
      "epoch:3, train_loss:-0.2834316911282308, val_loss:-0.4049747976928185\n",
      "epoch:4, train_loss:-0.3059644651010285, val_loss:-0.43008813596306705\n",
      "Training completed in 661.7355451583862s\n"
     ]
    }
   ],
   "source": [
    "# Net_int_2Edges_pool_intHead2\n",
    "since = time.time()\n",
    "opt.zero_grad()\n",
    "for epoch in range(epochs):\n",
    "    # training #\n",
    "    model.train()\n",
    "    np.random.seed()\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    \n",
    "    for i,data in enumerate(train_dl):\n",
    "        data = data.to('cuda:0')\n",
    "        loss = model(data,True)\n",
    "        loss.backward()\n",
    "        clip_grad_value_(paras,clip)\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # evaluating #\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for j,data in enumerate(valid_dl):\n",
    "            data = data.to('cuda:0')\n",
    "            loss = model(data,True)\n",
    "            val_loss += loss.item()\n",
    "    print('epoch:{}, train_loss:{}, val_loss:{}'.format(epoch,train_loss/i,val_loss/j))\n",
    "    \n",
    "time_elapsed = time.time() - since\n",
    "print('Training completed in {}s'.format(time_elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:-0.32840665769995375, val_loss:-0.4471948258897178\n",
      "epoch:1, train_loss:-0.34614883554366066, val_loss:-0.47605571195355845\n",
      "epoch:2, train_loss:-0.3652804598355326, val_loss:-0.48447955495271927\n",
      "epoch:3, train_loss:-0.3845258105697837, val_loss:-0.4832447755158457\n",
      "epoch:4, train_loss:-0.4010357999629935, val_loss:-0.5053740528404204\n",
      "Training completed in 749.0423629283905s\n"
     ]
    }
   ],
   "source": [
    "# Net_int_2Edges_pool_intHead2\n",
    "since = time.time()\n",
    "opt.zero_grad()\n",
    "for epoch in range(epochs):\n",
    "    # training #\n",
    "    model.train()\n",
    "    np.random.seed()\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    \n",
    "    for i,data in enumerate(train_dl):\n",
    "        data = data.to('cuda:0')\n",
    "        loss = model(data,True)\n",
    "        loss.backward()\n",
    "        clip_grad_value_(paras,clip)\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # evaluating #\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for j,data in enumerate(valid_dl):\n",
    "            data = data.to('cuda:0')\n",
    "            loss = model(data,True)\n",
    "            val_loss += loss.item()\n",
    "    print('epoch:{}, train_loss:{}, val_loss:{}'.format(epoch,train_loss/i,val_loss/j))\n",
    "    \n",
    "time_elapsed = time.time() - since\n",
    "print('Training completed in {}s'.format(time_elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:-0.4195739028998363, val_loss:-0.5370073982665682\n",
      "epoch:1, train_loss:-0.43429612570366033, val_loss:-0.5289927729301982\n",
      "epoch:2, train_loss:-0.445725753521832, val_loss:-0.5260609407455493\n",
      "epoch:3, train_loss:-0.46146462580413106, val_loss:-0.5786263877127924\n",
      "epoch:4, train_loss:-0.475618605144666, val_loss:-0.5662320554893241\n",
      "Training completed in 928.5973472595215s\n"
     ]
    }
   ],
   "source": [
    "# Net_int_2Edges_pool_intHead2\n",
    "since = time.time()\n",
    "opt.zero_grad()\n",
    "for epoch in range(epochs):\n",
    "    # training #\n",
    "    model.train()\n",
    "    np.random.seed()\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    \n",
    "    for i,data in enumerate(train_dl):\n",
    "        data = data.to('cuda:0')\n",
    "        loss = model(data,True)\n",
    "        loss.backward()\n",
    "        clip_grad_value_(paras,clip)\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # evaluating #\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for j,data in enumerate(valid_dl):\n",
    "            data = data.to('cuda:0')\n",
    "            loss = model(data,True)\n",
    "            val_loss += loss.item()\n",
    "    print('epoch:{}, train_loss:{}, val_loss:{}'.format(epoch,train_loss/i,val_loss/j))\n",
    "    \n",
    "time_elapsed = time.time() - since\n",
    "print('Training completed in {}s'.format(time_elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:-0.48830208976109607, val_loss:-0.5802539597846504\n",
      "epoch:1, train_loss:-0.49995962164148, val_loss:-0.6050142347175851\n",
      "epoch:2, train_loss:-0.5147427366471585, val_loss:-0.5544515141309836\n",
      "epoch:3, train_loss:-0.528825285816825, val_loss:-0.5788627008342335\n",
      "epoch:4, train_loss:-0.5388606865492159, val_loss:-0.6163132952956053\n",
      "Training completed in 932.0772387981415s\n"
     ]
    }
   ],
   "source": [
    "# Net_int_2Edges_pool_intHead2\n",
    "since = time.time()\n",
    "opt.zero_grad()\n",
    "for epoch in range(epochs):\n",
    "    # training #\n",
    "    model.train()\n",
    "    np.random.seed()\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    \n",
    "    for i,data in enumerate(train_dl):\n",
    "        data = data.to('cuda:0')\n",
    "        loss = model(data,True)\n",
    "        loss.backward()\n",
    "        clip_grad_value_(paras,clip)\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # evaluating #\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for j,data in enumerate(valid_dl):\n",
    "            data = data.to('cuda:0')\n",
    "            loss = model(data,True)\n",
    "            val_loss += loss.item()\n",
    "    print('epoch:{}, train_loss:{}, val_loss:{}'.format(epoch,train_loss/i,val_loss/j))\n",
    "    \n",
    "time_elapsed = time.time() - since\n",
    "print('Training completed in {}s'.format(time_elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "for para in opt.param_groups:\n",
    "    para['lr'] = 5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:-0.594168065520362, val_loss:-0.6928425587267957\n",
      "epoch:1, train_loss:-0.6068908522049477, val_loss:-0.6865779711013167\n",
      "epoch:2, train_loss:-0.6141801948519019, val_loss:-0.7026917973899434\n",
      "epoch:3, train_loss:-0.6220309867208059, val_loss:-0.7057264423650554\n",
      "epoch:4, train_loss:-0.6282204711442676, val_loss:-0.7012094151642587\n",
      "Training completed in 927.6188719272614s\n"
     ]
    }
   ],
   "source": [
    "# Net_int_2Edges_pool_intHead2\n",
    "since = time.time()\n",
    "opt.zero_grad()\n",
    "for epoch in range(epochs):\n",
    "    # training #\n",
    "    model.train()\n",
    "    np.random.seed()\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    \n",
    "    for i,data in enumerate(train_dl):\n",
    "        data = data.to('cuda:0')\n",
    "        loss = model(data,True)\n",
    "        loss.backward()\n",
    "        clip_grad_value_(paras,clip)\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # evaluating #\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for j,data in enumerate(valid_dl):\n",
    "            data = data.to('cuda:0')\n",
    "            loss = model(data,True)\n",
    "            val_loss += loss.item()\n",
    "    print('epoch:{}, train_loss:{}, val_loss:{}'.format(epoch,train_loss/i,val_loss/j))\n",
    "    \n",
    "time_elapsed = time.time() - since\n",
    "print('Training completed in {}s'.format(time_elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "for para in opt.param_groups:\n",
    "    para['lr'] = 2e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:-0.6633511964431025, val_loss:-0.7569363331183409\n",
      "epoch:1, train_loss:-0.6710359787335939, val_loss:-0.7478445477337918\n",
      "epoch:2, train_loss:-0.6752695218171494, val_loss:-0.7589000694007955\n",
      "epoch:3, train_loss:-0.6774823888148355, val_loss:-0.7486525864427925\n",
      "epoch:4, train_loss:-0.6821317726011193, val_loss:-0.7608554126360477\n",
      "Training completed in 932.4170694351196s\n"
     ]
    }
   ],
   "source": [
    "# Net_int_2Edges_pool_intHead2\n",
    "since = time.time()\n",
    "opt.zero_grad()\n",
    "for epoch in range(epochs):\n",
    "    # training #\n",
    "    model.train()\n",
    "    np.random.seed()\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    \n",
    "    for i,data in enumerate(train_dl):\n",
    "        data = data.to('cuda:0')\n",
    "        loss = model(data,True)\n",
    "        loss.backward()\n",
    "        clip_grad_value_(paras,clip)\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # evaluating #\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for j,data in enumerate(valid_dl):\n",
    "            data = data.to('cuda:0')\n",
    "            loss = model(data,True)\n",
    "            val_loss += loss.item()\n",
    "    print('epoch:{}, train_loss:{}, val_loss:{}'.format(epoch,train_loss/i,val_loss/j))\n",
    "    \n",
    "time_elapsed = time.time() - since\n",
    "print('Training completed in {}s'.format(time_elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:-0.6843306843308918, val_loss:-0.7611134335016593\n",
      "epoch:1, train_loss:-0.6876784494929408, val_loss:-0.7651663442325388\n",
      "epoch:2, train_loss:-0.6915706446114118, val_loss:-0.7709255159920098\n",
      "epoch:3, train_loss:-0.6920657717287677, val_loss:-0.7760558013732617\n",
      "epoch:4, train_loss:-0.6943480713513543, val_loss:-0.7782296613495574\n",
      "Training completed in 931.6694602966309s\n"
     ]
    }
   ],
   "source": [
    "# Net_int_2Edges_pool_intHead2\n",
    "since = time.time()\n",
    "opt.zero_grad()\n",
    "for epoch in range(epochs):\n",
    "    # training #\n",
    "    model.train()\n",
    "    np.random.seed()\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    \n",
    "    for i,data in enumerate(train_dl):\n",
    "        data = data.to('cuda:0')\n",
    "        loss = model(data,True)\n",
    "        loss.backward()\n",
    "        clip_grad_value_(paras,clip)\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # evaluating #\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for j,data in enumerate(valid_dl):\n",
    "            data = data.to('cuda:0')\n",
    "            loss = model(data,True)\n",
    "            val_loss += loss.item()\n",
    "    print('epoch:{}, train_loss:{}, val_loss:{}'.format(epoch,train_loss/i,val_loss/j))\n",
    "    \n",
    "time_elapsed = time.time() - since\n",
    "print('Training completed in {}s'.format(time_elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:1.0586407478944755, val_loss:0.5972323164853275\n",
      "epoch:1, train_loss:0.5822940412781039, val_loss:0.3499437818924586\n",
      "epoch:2, train_loss:0.4129772612669177, val_loss:0.2494932159733696\n",
      "epoch:3, train_loss:0.31060964641406974, val_loss:0.14766907464298937\n",
      "epoch:4, train_loss:0.23812104661526967, val_loss:0.09794970082007667\n",
      "Training completed in 1035.262710094452s\n"
     ]
    }
   ],
   "source": [
    "# Net_int_2Edges_pool_intHead\n",
    "since = time.time()\n",
    "opt.zero_grad()\n",
    "for epoch in range(epochs):\n",
    "    # training #\n",
    "    model.train()\n",
    "    np.random.seed()\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    \n",
    "    for i,data in enumerate(train_dl):\n",
    "        data = data.to('cuda:0')\n",
    "        loss = model(data,True)\n",
    "        loss.backward()\n",
    "        clip_grad_value_(paras,clip)\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # evaluating #\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for j,data in enumerate(valid_dl):\n",
    "            data = data.to('cuda:0')\n",
    "            loss = model(data,True)\n",
    "            val_loss += loss.item()\n",
    "    print('epoch:{}, train_loss:{}, val_loss:{}'.format(epoch,train_loss/i,val_loss/j))\n",
    "    \n",
    "time_elapsed = time.time() - since\n",
    "print('Training completed in {}s'.format(time_elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:0.9432164053421997, val_loss:0.4776822461022271\n",
      "epoch:1, train_loss:0.4486014823364132, val_loss:0.2770513335927429\n",
      "epoch:2, train_loss:0.30067624731196296, val_loss:0.15217620228281897\n",
      "epoch:3, train_loss:0.21372147340789116, val_loss:0.06608518575214678\n",
      "epoch:4, train_loss:0.14415263022697702, val_loss:0.00784918664691922\n",
      "Training completed in 644.1707198619843s\n"
     ]
    }
   ],
   "source": [
    "# Net_int_2Edges_intHead\n",
    "since = time.time()\n",
    "opt.zero_grad()\n",
    "for epoch in range(epochs):\n",
    "    # training #\n",
    "    model.train()\n",
    "    np.random.seed()\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    \n",
    "    for i,data in enumerate(train_dl):\n",
    "        data = data.to('cuda:0')\n",
    "        loss = model(data,True)\n",
    "        loss.backward()\n",
    "        clip_grad_value_(paras,clip)\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # evaluating #\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for j,data in enumerate(valid_dl):\n",
    "            data = data.to('cuda:0')\n",
    "            loss = model(data,True)\n",
    "            val_loss += loss.item()\n",
    "    print('epoch:{}, train_loss:{}, val_loss:{}'.format(epoch,train_loss/i,val_loss/j))\n",
    "    \n",
    "time_elapsed = time.time() - since\n",
    "print('Training completed in {}s'.format(time_elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = torch.load('../Model/gnn_int_logloss_2Edges.tar')\n",
    "# model.load_state_dict(checkpoint['model_state_dict'])\n",
    "# opt.load_state_dict(checkpoint['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': opt.state_dict(),\n",
    "            }, '../Model/Net_int_2Edges_pool_intHead2.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "yhat_list = []\n",
    "with torch.no_grad():\n",
    "    for data in test_dl:\n",
    "        data = data.to('cuda:0')\n",
    "        yhat_list.append(model(data,False))\n",
    "\n",
    "yhat = torch.cat(yhat_list).cpu().detach().numpy()\n",
    "submission = pd.read_csv('../Data/sample_submission.csv')\n",
    "submission['scalar_coupling_constant'] = yhat\n",
    "submission.to_csv('../Submission/Net_int_2Edges_pool_intHead2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
