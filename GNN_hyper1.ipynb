{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "from torch_geometric.data import Data,DataLoader\n",
    "from functions_refactor import *\n",
    "from pytorch_util import *\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_epoch=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(hyper_epoch):\n",
    "    # model parameters\n",
    "    reuse = np.random.choice([True,False])\n",
    "    block = np.random.choice([NNConv_block,schnet_block])\n",
    "    head = np.random.choice([cat3Head_type,swapHead_type,cat3HeadPool_type,set2setHead_type,SimpleHead_type])\n",
    "    data = np.random.choice(['../Data/{}_data_ACSF_expand_PCA.pickle',\\\n",
    "                             '../Data/{}_data_SOAP_expand_PCA.pickle',\\\n",
    "                             '../Data/{}_data_atomInfo.pickle'])\n",
    "    batch_size = 32\n",
    "    dim = int(np.random.choice([128,256]))\n",
    "    epochs = 50\n",
    "    clip = 2\n",
    "    layer1 = int(np.random.choice([2,3]))\n",
    "    layer2 = int(np.random.choice([2,3]))\n",
    "    factor = int(np.random.choice([2,3,4]))\n",
    "    lr = 1e-4\n",
    "    epochs_type = epochs\n",
    "\n",
    "    print('\\ntraining on {}\\n'.format('_'.join([str(i).split('}')[1] if '}' in str(i) else str(i) \\\n",
    "                                        for i in [reuse,block,head,data,batch_size,dim,clip,\\\n",
    "                                              layer1,layer2,factor,epochs]])))\n",
    "\n",
    "    for i in range(8):\n",
    "        # load type data\n",
    "        data_type = data.split('.pickle')[0]+ '_type_'+str(i)+'.pickle'\n",
    "        train_dl,val_dl = get_data(data_type,batch_size)\n",
    "\n",
    "        # init model\n",
    "        model = GNN(reuse,block,head,dim,layer1,layer2,factor,**data_dict[data]).to('cuda:0')\n",
    "        paras = trainable_parameter(model)\n",
    "        opt = Adam(paras,lr=lr)\n",
    "        scheduler = ReduceLROnPlateau(opt, 'min',factor=0.5,patience=5)\n",
    "\n",
    "        print('\\nTraining type: {}'.format(i))\n",
    "        model,train_loss_perType,val_loss_perType = train(opt,model,epochs_type,train_dl,val_dl,paras,clip,True,scheduler=scheduler)\n",
    "\n",
    "        save_results(train_loss_perType,val_loss_perType,reuse,block,\\\n",
    "                     head,data,batch_size,dim,clip,layer1,layer2,factor,epochs,'type_'+str(i)+'_start')\n",
    "\n",
    "        save_model(model,opt,reuse,block,head,data,batch_size,dim,clip,layer1,layer2,factor,epochs,'type_'+str(i)+'_start')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
