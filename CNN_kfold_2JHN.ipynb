{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from functions_refactor import RAdam\n",
    "from functions_cnn import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "type_ = '2JHN'\n",
    "num_workers = 4\n",
    "batch_size = 512\n",
    "clip = 2\n",
    "n_epochs = 50\n",
    "model_struct = CNN\n",
    "root_dir =\"../Data/full-images-2jhn/Image_2JHN/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/will/Desktop/kaggle/QM/Code/functions_cnn.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  train_ids['file_name'] = train_ids.molecule_name.str.cat(train_ids.id.astype(str),sep='_')\n",
      "/home/will/Desktop/kaggle/QM/Code/functions_cnn.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  test_ids['file_name'] = test_ids.molecule_name.str.cat(test_ids.id.astype(str),sep='_')\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('../Data/train.csv')\n",
    "test_df = pd.read_csv('../Data/test.csv')\n",
    "train_ids,test_ids = process_data(train_df,test_df,type_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs =2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "start fold: 0\n",
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Epoch: 1 \tTraining Loss: 2.879799 \tValidation Loss: 2.860868\n",
      "Epoch: 2 \tTraining Loss: 2.849440 \tValidation Loss: 2.826412\n",
      "Training completed in 39.659775257110596s\n"
     ]
    }
   ],
   "source": [
    "group_kfold = GroupKFold(n_splits=5)\n",
    "for n_fold, (train_idx, valid_idx) in enumerate(group_kfold.split(train_ids,groups=train_ids['molecule_name'])):\n",
    "    print('\\nstart fold: {}'.format(n_fold))\n",
    "    \n",
    "    # set-up data\n",
    "    train_dl = train_ids.iloc[train_idx]\n",
    "    valid_dl = train_ids.iloc[valid_idx]\n",
    "    train_dl = CustomImageDataset(train_dl, root_dir, transform=None, IsTrain=True)\n",
    "    valid_dl = CustomImageDataset(valid_dl, root_dir, transform=None, IsTrain=True)\n",
    "    test_dl = CustomImageDataset(test_ids, root_dir, transform=None, IsTrain=False)\n",
    "    train_dl = torch.utils.data.DataLoader(train_dl,batch_size=batch_size,shuffle=True,num_workers=num_workers)\n",
    "    valid_dl = torch.utils.data.DataLoader(valid_dl,batch_size=batch_size,shuffle=False,num_workers=num_workers)\n",
    "    test_dl = torch.utils.data.DataLoader(test_dl,batch_size=batch_size,shuffle=False,num_workers=num_workers)\n",
    "    \n",
    "    # train model\n",
    "    model = model_struct().to('cuda')\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    optimizer = RAdam(model.parameters(),lr=0.0001,weight_decay=1e-2)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'min',factor=0.5,patience=5)\n",
    "    model = train_cnn(model,optimizer,train_dl,valid_dl,n_epochs,clip,scheduler)\n",
    "    \n",
    "    # predict oof\n",
    "    model.eval()\n",
    "    yhat_list = []\n",
    "    with torch.no_grad():\n",
    "        for x_torch,_ in valid_dl:\n",
    "            x_torch = x_torch.to('cuda:0')\n",
    "            yhat_list.append(model(x_torch).squeeze(1))\n",
    "    yhat = torch.cat(yhat_list).cpu().detach().numpy()        \n",
    "    \n",
    "    assert yhat.shape[0]==train_ids.iloc[valid_idx].shape[0],'yhat and test_id should have same shape'\n",
    "    submit_ = dict(zip(train_ids.iloc[valid_idx]['id'].values,yhat))\n",
    "    train_df['fold'+str(n_fold)+'_'+type_] = train_df.id.map(submit_)\n",
    "    \n",
    "    # predict test\n",
    "    model.eval()\n",
    "    yhat_list = []\n",
    "    with torch.no_grad():\n",
    "        for data_torch in test_dl:\n",
    "            data_torch = data_torch.to('cuda:0')\n",
    "            yhat_list.append(model(data_torch).squeeze(1))\n",
    "    yhat = torch.cat(yhat_list).cpu().detach().numpy()        \n",
    "\n",
    "    # join\n",
    "    assert yhat.shape[0]==test_ids.shape[0],'yhat and test_id should have same shape'\n",
    "    submit_ = dict(zip(test_ids['id'].values,yhat))\n",
    "    test_df['fold'+str(n_fold)+'_'+type_] = test_df.id.map(submit_)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
