{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch_geometric.data import Data,DataLoader\n",
    "from functions import *\n",
    "from pytorch_util import *\n",
    "from torch.optim import Adam\n",
    "from torch.nn.utils import clip_grad_value_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Data/train_data3.pickle', 'rb') as handle:\n",
    "    train_data = pickle.load(handle)\n",
    "with open('../Data/val_data3.pickle', 'rb') as handle:\n",
    "    val_data = pickle.load(handle)\n",
    "with open('../Data/test_data3.pickle', 'rb') as handle:\n",
    "    test_data = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### parameters ###\n",
    "batch_size = 32\n",
    "dim = 64\n",
    "edge_dim = 12\n",
    "epochs = 5\n",
    "clip = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = [Data(**transform_xyz(d)) for d in train_data]\n",
    "train_dl = DataLoader(train_list,batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_list = [Data(**d) for d in val_data]\n",
    "valid_dl = DataLoader(val_list,batch_size,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = [Data(**d) for d in test_data]\n",
    "test_dl = DataLoader(test_list,batch_size,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_int(torch.nn.Module):\n",
    "    # differ from Net in that edge_attr3 is used to determine Weight\n",
    "    def __init__(self,dim=64,edge_dim=12):\n",
    "        super(Net_int, self).__init__()\n",
    "        self.lin_node = torch.nn.Linear(8, dim)\n",
    "        self.lin_edge_attr = torch.nn.Linear(19, edge_dim)\n",
    "        \n",
    "        nn = Sequential(Linear(12, 128), ReLU(), Linear(128, dim * dim))\n",
    "        self.conv = NNConv(dim, dim, nn, aggr='mean', root_weight=False)\n",
    "        self.gru = GRU(dim, dim)\n",
    "        self.lin_weight = Linear(8, dim*3, bias=False)\n",
    "        self.lin_bias = Linear(8, 1, bias=False)\n",
    "        self.norm = BatchNorm1d(dim*3)\n",
    "        \n",
    "    def forward(self, data,IsTrain=False):\n",
    "        out = F.relu(self.lin_node(data.x))\n",
    "        edge_attr = F.relu(self.lin_edge_attr(data.edge_attr))\n",
    "        h = out.unsqueeze(0)\n",
    "\n",
    "        for i in range(3):\n",
    "            m = F.relu(self.conv(out, data.edge_index, edge_attr))\n",
    "            out, h = self.gru(m.unsqueeze(0), h)\n",
    "            out = out.squeeze(0)\n",
    "        \n",
    "        temp = out[data.edge_index3] # (2,N,d)\n",
    "        yhat = torch.cat([temp.mean(0),temp[0]*temp[1],(temp[0]-temp[1])**2],1)\n",
    "        yhat = self.norm(yhat)\n",
    "        weight = self.lin_weight(data.edge_attr3)\n",
    "        bias = self.lin_bias(data.edge_attr3)\n",
    "        yhat = torch.sum(yhat * weight,1,keepdim=True) + bias\n",
    "        yhat = yhat.squeeze(1)\n",
    "        \n",
    "        if IsTrain:\n",
    "            k = torch.sum(data.edge_attr3,0)\n",
    "            nonzeroIndex = torch.nonzero(k).squeeze(1)\n",
    "            abs_ = torch.abs(data.y-yhat).unsqueeze(1)\n",
    "            loss = torch.sum(torch.log(torch.sum(abs_ * data.edge_attr3[:,nonzeroIndex],0)/k[nonzeroIndex]))/nonzeroIndex.shape[0]\n",
    "            return loss\n",
    "        else:\n",
    "            return yhat    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build model and set up training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net_int(dim=dim,edge_dim=edge_dim).to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "paras = trainable_parameter(model)\n",
    "opt = Adam(paras,lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:1.31292921487305, val_loss:1.0950018126740415\n",
      "epoch:1, train_loss:1.0645866456727322, val_loss:0.9791319724331554\n",
      "epoch:2, train_loss:0.9445941792430538, val_loss:0.8604759289922878\n",
      "epoch:3, train_loss:0.7860951898410868, val_loss:0.6345988603101836\n",
      "epoch:4, train_loss:0.6399021933598773, val_loss:0.6021169496652408\n",
      "Training completed in 160.5507984161377s\n"
     ]
    }
   ],
   "source": [
    "since = time.time()\n",
    "opt.zero_grad()\n",
    "for epoch in range(epochs):\n",
    "    # training #\n",
    "    model.train()\n",
    "    np.random.seed()\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    \n",
    "    for i,data in enumerate(train_dl):\n",
    "        data = data.to('cuda:0')\n",
    "        loss = model(data,True)\n",
    "        loss.backward()\n",
    "        clip_grad_value_(paras,clip)\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # evaluating #\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for j,data in enumerate(valid_dl):\n",
    "            data = data.to('cuda:0')\n",
    "            loss = model(data,True)\n",
    "            val_loss += loss.item()\n",
    "    print('epoch:{}, train_loss:{}, val_loss:{}'.format(epoch,train_loss/i,val_loss/j))\n",
    "    \n",
    "    # Rotation transform\n",
    "    train_list = [Data(**transform_xyz(d)) for d in train_data]\n",
    "    train_dl = DataLoader(train_list,batch_size,shuffle=True)\n",
    "    \n",
    "time_elapsed = time.time() - since\n",
    "print('Training completed in {}s'.format(time_elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:0.5974241261565091, val_loss:0.5467007857484695\n",
      "epoch:1, train_loss:0.5663623529642643, val_loss:0.5349229339860443\n",
      "epoch:2, train_loss:0.536406577260297, val_loss:0.4970583523440565\n",
      "epoch:3, train_loss:0.5169361425852416, val_loss:0.4863691093384201\n",
      "epoch:4, train_loss:0.4997656222179048, val_loss:0.4951587853650761\n",
      "Training completed in 157.28429293632507s\n"
     ]
    }
   ],
   "source": [
    "since = time.time()\n",
    "opt.zero_grad()\n",
    "for epoch in range(epochs):\n",
    "    # training #\n",
    "    model.train()\n",
    "    np.random.seed()\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    \n",
    "    for i,data in enumerate(train_dl):\n",
    "        data = data.to('cuda:0')\n",
    "        loss = model(data,True)\n",
    "        loss.backward()\n",
    "        clip_grad_value_(paras,clip)\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # evaluating #\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for j,data in enumerate(valid_dl):\n",
    "            data = data.to('cuda:0')\n",
    "            loss = model(data,True)\n",
    "            val_loss += loss.item()\n",
    "    print('epoch:{}, train_loss:{}, val_loss:{}'.format(epoch,train_loss/i,val_loss/j))\n",
    "    \n",
    "    # Rotation transform\n",
    "    train_list = [Data(**transform_xyz(d)) for d in train_data]\n",
    "    train_dl = DataLoader(train_list,batch_size,shuffle=True)\n",
    "    \n",
    "time_elapsed = time.time() - since\n",
    "print('Training completed in {}s'.format(time_elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:0.48688141853775563, val_loss:0.49846169906548965\n",
      "epoch:1, train_loss:0.4696073501852478, val_loss:0.43649199050970566\n",
      "epoch:2, train_loss:0.45278630615861437, val_loss:0.449871155887078\n",
      "epoch:3, train_loss:0.44190578099985783, val_loss:0.45378813586938077\n",
      "epoch:4, train_loss:0.4257568464493937, val_loss:0.4150658223746169\n",
      "Training completed in 160.6892945766449s\n"
     ]
    }
   ],
   "source": [
    "since = time.time()\n",
    "opt.zero_grad()\n",
    "for epoch in range(epochs):\n",
    "    # training #\n",
    "    model.train()\n",
    "    np.random.seed()\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    \n",
    "    for i,data in enumerate(train_dl):\n",
    "        data = data.to('cuda:0')\n",
    "        loss = model(data,True)\n",
    "        loss.backward()\n",
    "        clip_grad_value_(paras,clip)\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # evaluating #\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for j,data in enumerate(valid_dl):\n",
    "            data = data.to('cuda:0')\n",
    "            loss = model(data,True)\n",
    "            val_loss += loss.item()\n",
    "    print('epoch:{}, train_loss:{}, val_loss:{}'.format(epoch,train_loss/i,val_loss/j))\n",
    "    \n",
    "    # Rotation transform\n",
    "    train_list = [Data(**transform_xyz(d)) for d in train_data]\n",
    "    train_dl = DataLoader(train_list,batch_size,shuffle=True)\n",
    "    \n",
    "time_elapsed = time.time() - since\n",
    "print('Training completed in {}s'.format(time_elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': opt.state_dict(),\n",
    "            }, '../Model/gnn_int.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "yhat_list = []\n",
    "with torch.no_grad():\n",
    "    for data in test_dl:\n",
    "        data = data.to('cuda:0')\n",
    "        yhat_list.append(model(data,False))\n",
    "\n",
    "yhat = torch.cat(yhat_list).cpu().detach().numpy()\n",
    "submission = pd.read_csv('../Data/sample_submission.csv')\n",
    "submission['scalar_coupling_constant'] = yhat\n",
    "submission.to_csv('../Submission/sub_gnn_int.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
