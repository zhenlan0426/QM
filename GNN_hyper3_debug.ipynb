{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import torch\n",
    "from torch_geometric.data import Data,DataLoader\n",
    "from functions_refactor import *\n",
    "from pytorch_util import *\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixed parameters\n",
    "hyper_epoch = 25\n",
    "threshold = -1.3\n",
    "epochs = 50\n",
    "batch_size = 32\n",
    "clip = 2\n",
    "lr = 1e-4\n",
    "epochs_type = epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training on <class 'functions_refactor.feedforwardHead_Update'>__data_ACSF_expand_PCA_otherInfo.pickle_512_False_0.6288604599490546_3_3_2_True_False_False\n",
      "\n",
      "epoch:0, train_loss: +2.122, val_loss: -0.506, \n",
      "train_vector: +1.11|+0.64|+0.09|-0.39|-0.41|+0.11|-0.43|-0.80, \n",
      "val_vector  : +0.32|+0.19|-0.30|-0.98|-0.88|-0.27|-0.94|-1.18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#for _ in range(hyper_epoch):\n",
    "    # model parameters\n",
    "\n",
    "#     head = np.random.choice([feedforwardHead_Update,feedforwardCombineHead_Update],p=[0.6,0.4])\n",
    "#     data = np.random.choice(['../Data/{}_data_ACSF_expand_PCA_otherInfo.pickle',\\\n",
    "#                              '../Data/{}_data_SOAP_expand_PCA_otherInfo.pickle',\\\n",
    "#                              '../Data/{}_data_atomInfo_otherInfo.pickle',\\\n",
    "#                              '../Data/{}_data_ACSF_SOAP_atomInfo_otherInfo.pickle'\n",
    "#                             ])\n",
    "#     logLoss = np.random.choice([True,False])\n",
    "#     weight = np.random.rand()*3 if logLoss else np.random.rand()*0.8\n",
    "#     dim = int(np.random.choice([256,512]))#\n",
    "#     interleave = np.random.choice([True,False])\n",
    "#     BatchNorm = np.random.choice([True,False],p=[0.6,0.4])\n",
    "#     if interleave:\n",
    "#         if dim == 768:\n",
    "#             layer1 = int(np.random.choice([3,4]))\n",
    "#             layer2 = layer1\n",
    "#         else:\n",
    "#             layer1 = int(np.random.choice([3,4,5]))\n",
    "#             layer2 = layer1            \n",
    "#     else:\n",
    "#         if dim == 768:        \n",
    "#             layer1 = int(np.random.choice([3,4]))\n",
    "#             layer2 = int(np.random.choice([3,4]))\n",
    "#         else:\n",
    "#             layer1 = int(np.random.choice([3,4,5]))\n",
    "#             layer2 = int(np.random.choice([3,4,5]))\n",
    "            \n",
    "#     if dim == 768:\n",
    "#         factor = int(np.random.choice([2,3]))\n",
    "#     else:\n",
    "#         factor = int(np.random.choice([2,3,4]))\n",
    "        \n",
    "#     useMax = np.random.choice([True,False])\n",
    "head = feedforwardHead_Update\n",
    "data = '../Data/{}_data_ACSF_expand_PCA_otherInfo.pickle'\n",
    "dim = 512\n",
    "logLoss = False\n",
    "weight = 0.6288604599490546\n",
    "layer1,layer2,factor = 3,3,2\n",
    "BatchNorm = True\n",
    "useMax = False\n",
    "interleave = False\n",
    "print('\\ntraining on {}\\n'.format('_'.join([str(i).split('}')[1] if '}' in str(i) else str(i) \\\n",
    "                                    for i in [head,data,dim,logLoss,weight,layer1,layer2,factor,\\\n",
    "                                              BatchNorm,useMax,interleave]])))\n",
    "\n",
    "train_dl,val_dl = get_data(data,batch_size)\n",
    "model = GNN_MataLayer(head,head_mol2,head_atom,head_edge,\\\n",
    "                      dim,layer1,layer2,factor,**data_dict[data],\\\n",
    "                      BatchNorm=BatchNorm,useMax=useMax,interleave=interleave).to('cuda:0')\n",
    "paras = trainable_parameter(model)\n",
    "opt = Adam(paras,lr=lr)\n",
    "scheduler = ReduceLROnPlateau(opt, 'min',factor=0.5,patience=5)\n",
    "\n",
    "model,train_loss_perType,val_loss_perType,bestWeight = train_type_earlyStop(opt,model,epochs_type,train_dl,val_dl,paras,clip,\\\n",
    "                                                                scheduler=scheduler,logLoss=logLoss,weight=weight,threshold=threshold)\n",
    "#     if model is not None:\n",
    "#         save_results2(train_loss_perType,val_loss_perType,head,data,dim,logLoss,weight,layer1,layer2,factor,\\\n",
    "#                         BatchNorm,useMax,interleave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_type_earlyStop(opt,model,epochs,train_dl,val_dl,paras,clip,typeTrain=False,\\\n",
    "                         train_loss_list=None,val_loss_list=None,scheduler=None,logLoss=True,weight=None,threshold=0):\n",
    "    # add early stop and weight for hyper Search\n",
    "    # add early stop if nan for hyper3\n",
    "    since = time.time()\n",
    "    \n",
    "    lossBest = [1e6] * 8\n",
    "    bestWeight = [None] * 8\n",
    "    if train_loss_list is None:\n",
    "        train_loss_list,val_loss_list = [],[]\n",
    "        epoch0 = 0\n",
    "    else:\n",
    "        epoch0 = len(train_loss_list)\n",
    "        \n",
    "    opt.zero_grad()\n",
    "    for epoch in range(epochs):\n",
    "        # training #\n",
    "        model.train()\n",
    "        np.random.seed()\n",
    "        train_loss = 0\n",
    "        train_loss_perType = np.zeros(8)\n",
    "        val_loss = 0\n",
    "        val_loss_perType = np.zeros(8)\n",
    "        \n",
    "        for i,data in enumerate(train_dl):\n",
    "            data = data.to('cuda:0')\n",
    "            loss,loss_perType = model(data,True,typeTrain,logLoss,weight)\n",
    "            # check nan\n",
    "            if np.isnan(loss.item()):\n",
    "                print('-----stop due to nan-----')\n",
    "                #model.load_state_dict(WeightB4)\n",
    "                return data,model,None,None            \n",
    "            loss.backward()\n",
    "            clip_grad_value_(paras,clip)\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "            #WeightB4 = copy.deepcopy(model.state_dict())\n",
    "            train_loss += loss.item()\n",
    "            train_loss_perType += loss_perType.cpu().detach().numpy()\n",
    "\n",
    "                    \n",
    "        # evaluating #\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for j,data in enumerate(val_dl):\n",
    "                data = data.to('cuda:0')\n",
    "                loss,loss_perType = model(data,True,typeTrain,True,None)\n",
    "                val_loss += loss.item()\n",
    "                val_loss_perType += loss_perType.cpu().detach().numpy()\n",
    "        \n",
    "        # early stop\n",
    "        val_loss = val_loss/j\n",
    "        if (epoch==20) and (val_loss>threshold):\n",
    "            print('-----stop due to poor performance-----')\n",
    "            return None,None,None,None\n",
    "        \n",
    "\n",
    "        # save model\n",
    "        val_loss_perType = val_loss_perType/j\n",
    "        for index_ in range(8):\n",
    "            if val_loss_perType[index_]<lossBest[index_]:\n",
    "                lossBest[index_] = val_loss_perType[index_]\n",
    "                bestWeight[index_] = copy.deepcopy(model.state_dict())\n",
    "            \n",
    "        print('epoch:{}, train_loss: {:+.3f}, val_loss: {:+.3f}, \\ntrain_vector: {}, \\nval_vector  : {}\\n'.format(epoch+epoch0,train_loss/i,val_loss,\\\n",
    "                                                            '|'.join(['%+.2f'%i for i in train_loss_perType/i]),\\\n",
    "                                                            '|'.join(['%+.2f'%i for i in val_loss_perType])))\n",
    "        train_loss_list.append(train_loss_perType/i)\n",
    "        val_loss_list.append(val_loss_perType)\n",
    "        if scheduler is not None:\n",
    "            scheduler.step(val_loss)\n",
    "            \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training completed in {}s'.format(time_elapsed))\n",
    "    return model,train_loss_list,val_loss_list,bestWeight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training on <class 'functions_refactor.feedforwardHead_Update'>__data_ACSF_expand_PCA_otherInfo.pickle_512_False_0.6288604599490546_4_3_4_False_False_False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "    head = feedforwardHead_Update\n",
    "    data = '../Data/{}_data_ACSF_expand_PCA_otherInfo.pickle'\n",
    "    dim = 512\n",
    "    logLoss = False\n",
    "    weight = 0.6288604599490546\n",
    "    layer1,layer2,factor = 4,3,4\n",
    "    BatchNorm = False\n",
    "    useMax = False\n",
    "    interleave = False\n",
    "    print('\\ntraining on {}\\n'.format('_'.join([str(i).split('}')[1] if '}' in str(i) else str(i) \\\n",
    "                                        for i in [head,data,dim,logLoss,weight,layer1,layer2,factor,\\\n",
    "                                                  BatchNorm,useMax,interleave]])))\n",
    "\n",
    "    train_dl,val_dl = get_data(data,batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward  = []\n",
    "def hook_forward(m, i, o):\n",
    "    if isinstance(o,tuple):\n",
    "        forward.append([m]+[(item.max(),item.min(),torch.isnan(item).sum()) for item in o])\n",
    "    else:\n",
    "        forward.append([m]+[o.max(),o.min(),torch.isnan(o).sum()])\n",
    "\n",
    "backward  = []\n",
    "def hook_backward(m, i, o):\n",
    "    if isinstance(o,tuple):\n",
    "        backward.append([m]+[(item.max(),item.min(),torch.isnan(item).sum()) for item in o])\n",
    "    else:\n",
    "        backward.append([m]+[o.max(),o.min(),torch.isnan(o).sum()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Sequential,Linear,ReLU,BatchNorm1d\n",
    "class head_mol3(torch.nn.Module):\n",
    "    def __init__(self,dim,mol_shape):\n",
    "        factor = 2\n",
    "        super(head_mol3, self).__init__()\n",
    "        self.linear = Sequential(BatchNorm1d(dim),Linear(dim, dim*factor),ReLU(), \\\n",
    "                                 BatchNorm1d(dim*factor),Linear(dim*factor, mol_shape))\n",
    "        \n",
    "    def forward(self,u):\n",
    "        out = self.linear(u).squeeze(1)\n",
    "        return out\n",
    "    \n",
    "class head_atom3(torch.nn.Module):\n",
    "    def __init__(self,dim,atom_shape):\n",
    "        factor = 2\n",
    "        super(head_atom3, self).__init__()\n",
    "        self.linear = Sequential(BatchNorm1d(dim),Linear(dim, dim*factor),ReLU(), \\\n",
    "                                 BatchNorm1d(dim*factor),Linear(dim*factor, atom_shape))\n",
    "        \n",
    "    def forward(self,out):\n",
    "        out = self.linear(out).squeeze(1)\n",
    "        return out\n",
    "\n",
    "class head_edge3(torch.nn.Module):\n",
    "    def __init__(self,dim,edge_shape):\n",
    "        factor = 2\n",
    "        super(head_edge3, self).__init__()\n",
    "        self.linear = Sequential(BatchNorm1d(dim),Linear(dim, dim*factor),ReLU(), \\\n",
    "                                 BatchNorm1d(dim*factor),Linear(dim*factor, edge_shape))\n",
    "        \n",
    "    def forward(self,out):\n",
    "        out = self.linear(out).squeeze(1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss: +2.245, val_loss: -0.494, \n",
      "train_vector: +1.30|+0.78|+0.11|-0.26|-0.39|+0.12|-0.35|-0.78, \n",
      "val_vector  : +0.52|+0.04|-0.38|-0.95|-0.91|-0.24|-0.88|-1.17\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 15.75 GiB total capacity; 14.54 GiB already allocated; 8.06 MiB free; 61.67 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-29a0cdfba4a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#         layer.register_forward_hook(hook_forward)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#         layer.register_backward_hook(hook_backward)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_type_earlyStop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_dl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparas\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m,\u001b[0m                                                                \u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlogLoss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogLoss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.kaggle/competitions/pmp/src/functions_refactor.py\u001b[0m in \u001b[0;36mtrain_type_earlyStop\u001b[0;34m(opt, model, epochs, train_dl, val_dl, paras, clip, typeTrain, train_loss_list, val_loss_list, scheduler, logLoss, weight, threshold)\u001b[0m\n\u001b[1;32m   1436\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1437\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1438\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_perType\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtypeTrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlogLoss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1439\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m             \u001b[0mclip_grad_value_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparas\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.kaggle/competitions/pmp/src/functions_refactor.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, data, IsTrain, typeTrain, logLoss, weight)\u001b[0m\n\u001b[1;32m   1111\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mconv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1113\u001b[0;31m                 \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0medge_attr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1114\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mconv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m                 \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0medge_attr3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0medge_index3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0medge_attr3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.kaggle/competitions/pmp/src/functions_refactor.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_attr, u, batch)\u001b[0m\n\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1053\u001b[0;31m         \u001b[0mx_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1054\u001b[0m         \u001b[0mx_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m         \u001b[0medge_attr_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_attr_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch_geometric/nn/meta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_attr, u, batch)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_model\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             edge_attr = self.edge_model(x[row], x[col], edge_attr, u,\n\u001b[0;32m--> 104\u001b[0;31m                                         batch[row])\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_model\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.kaggle/competitions/pmp/src/functions_refactor.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, dest, edge_attr, u, batch)\u001b[0m\n\u001b[1;32m    979\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 15.75 GiB total capacity; 14.54 GiB already allocated; 8.06 MiB free; 61.67 MiB cached)"
     ]
    }
   ],
   "source": [
    "    model = GNN_MataLayer(head,head_mol3,head_atom3,head_edge3,\\\n",
    "                          dim,layer1,layer2,factor,**data_dict[data],\\\n",
    "                          BatchNorm=BatchNorm,useMax=useMax,interleave=interleave).to('cuda:0')\n",
    "    paras = trainable_parameter(model)\n",
    "    opt = Adam(paras,lr=lr)\n",
    "    scheduler = ReduceLROnPlateau(opt, 'min',factor=0.5,patience=5)\n",
    "#     for name, layer in model._modules.items():\n",
    "#         layer.register_forward_hook(hook_forward)\n",
    "#         layer.register_backward_hook(hook_backward)\n",
    "    data,model,_,_ = train_type_earlyStop(opt,model,epochs_type,train_dl,val_dl,paras,clip,\\\n",
    "                                                                    scheduler=scheduler,logLoss=logLoss,weight=weight,threshold=threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_data(data):\n",
    "    print(data.max(),data.min(),torch.isnan(data).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_list = ['batch','edge_attr','edge_attr3','edge_attr4','edge_index','edge_index3','x','y','y_atom','y_coupling','y_mol']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch\n",
      "tensor(31, device='cuda:0') tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "edge_attr\n",
      "tensor(1.6122, device='cuda:0') tensor(0., device='cuda:0') tensor(0, device='cuda:0')\n",
      "edge_attr3\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0') tensor(0, device='cuda:0')\n",
      "edge_attr4\n",
      "tensor(3.7523, device='cuda:0') tensor(0., device='cuda:0') tensor(0, device='cuda:0')\n",
      "edge_index\n",
      "tensor(575, device='cuda:0') tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "edge_index3\n",
      "tensor(575, device='cuda:0') tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "x\n",
      "tensor(12.9760, device='cuda:0') tensor(-20.6225, device='cuda:0') tensor(0, device='cuda:0')\n",
      "y\n",
      "tensor(199.0140, device='cuda:0') tensor(-18.0921, device='cuda:0') tensor(0, device='cuda:0')\n",
      "y_atom\n",
      "tensor(13.4248, device='cuda:0') tensor(-11.1703, device='cuda:0') tensor(0, device='cuda:0')\n",
      "y_coupling\n",
      "tensor(6.5124, device='cuda:0') tensor(-5.2078, device='cuda:0') tensor(0, device='cuda:0')\n",
      "y_mol\n",
      "tensor(2.6854, device='cuda:0') tensor(-3.3313, device='cuda:0') tensor(0, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for attr in attr_list:\n",
    "    print(attr)\n",
    "    inspect_data(getattr(data,attr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batch(batch=[545], edge_attr=[1118, 44], edge_attr3=[1486, 8], edge_attr4=[1486, 26], edge_index=[2, 1118], edge_index3=[2, 1486], x=[545, 32], y=[1486], y_atom=[545, 10], y_coupling=[1486, 4], y_mol=[32, 4])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Sequential(\n",
       "    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Linear(in_features=32, out_features=2048, bias=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "    (3): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): Linear(in_features=2048, out_features=512, bias=True)\n",
       "    (5): LeakyReLU(negative_slope=0.01)\n",
       "  ),\n",
       "  tensor(6.1014, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0543, device='cuda:0', grad_fn=<MinBackward1>),\n",
       "  tensor(0, device='cuda:0')],\n",
       " [Sequential(\n",
       "    (0): BatchNorm1d(34, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Linear(in_features=34, out_features=2048, bias=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "    (3): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): Linear(in_features=2048, out_features=512, bias=True)\n",
       "    (5): LeakyReLU(negative_slope=0.01)\n",
       "  ),\n",
       "  tensor(6.2015, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0999, device='cuda:0', grad_fn=<MinBackward1>),\n",
       "  tensor(0, device='cuda:0')],\n",
       " [Sequential(\n",
       "    (0): BatchNorm1d(44, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Linear(in_features=44, out_features=2048, bias=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "    (3): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): Linear(in_features=2048, out_features=512, bias=True)\n",
       "    (5): LeakyReLU(negative_slope=0.01)\n",
       "  ),\n",
       "  tensor(4.7220, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0718, device='cuda:0', grad_fn=<MinBackward1>),\n",
       "  tensor(0, device='cuda:0')],\n",
       " [Sequential(\n",
       "    (0): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "    (3): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): Linear(in_features=4096, out_features=512, bias=True)\n",
       "    (5): LeakyReLU(negative_slope=0.01)\n",
       "  ),\n",
       "  tensor(2.4822, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0255, device='cuda:0', grad_fn=<MinBackward1>),\n",
       "  tensor(0, device='cuda:0')],\n",
       " [feedforwardHead_Update(\n",
       "    (linear): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=1024, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=1024, out_features=1, bias=True)\n",
       "    )\n",
       "  ),\n",
       "  tensor(0.7688, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0509, device='cuda:0', grad_fn=<MinBackward1>),\n",
       "  tensor(0, device='cuda:0')],\n",
       " [head_mol3(\n",
       "    (linear): Sequential(\n",
       "      (0): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "      (2): ReLU()\n",
       "      (3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (4): Linear(in_features=1024, out_features=4, bias=True)\n",
       "    )\n",
       "  ),\n",
       "  tensor(1.4986, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-1.3384, device='cuda:0', grad_fn=<MinBackward1>),\n",
       "  tensor(0, device='cuda:0')],\n",
       " [head_atom3(\n",
       "    (linear): Sequential(\n",
       "      (0): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "      (2): ReLU()\n",
       "      (3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (4): Linear(in_features=1024, out_features=10, bias=True)\n",
       "    )\n",
       "  ),\n",
       "  tensor(nan, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(nan, device='cuda:0', grad_fn=<MinBackward1>),\n",
       "  tensor(5760, device='cuda:0')],\n",
       " [head_edge3(\n",
       "    (linear): Sequential(\n",
       "      (0): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "      (2): ReLU()\n",
       "      (3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (4): Linear(in_features=1024, out_features=4, bias=True)\n",
       "    )\n",
       "  ),\n",
       "  tensor(0.8706, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-4.6812, device='cuda:0', grad_fn=<MinBackward1>),\n",
       "  tensor(0, device='cuda:0')]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[torch.isnan(w).sum() for w in model.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lin_node.0.weight',\n",
       "  tensor(0.9584, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(0.0001, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('lin_node.0.bias',\n",
       "  tensor(0., device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(0., device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('lin_node.1.weight',\n",
       "  tensor(0.1768, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.1768, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('lin_node.1.bias',\n",
       "  tensor(0.1767, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.1768, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('lin_node.3.weight',\n",
       "  tensor(0.9991, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(0.0009, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('lin_node.3.bias',\n",
       "  tensor(0., device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(0., device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('lin_node.4.weight',\n",
       "  tensor(0.0221, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0221, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('lin_node.4.bias',\n",
       "  tensor(0.0220, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0220, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('edge1.0.weight',\n",
       "  tensor(0.9869, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(0.0092, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('edge1.0.bias',\n",
       "  tensor(0., device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(0., device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('edge1.1.weight',\n",
       "  tensor(0.1508, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.1508, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('edge1.1.bias',\n",
       "  tensor(0.1507, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.1507, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('edge1.3.weight',\n",
       "  tensor(1.0000, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(0.0002, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('edge1.3.bias',\n",
       "  tensor(0., device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(0., device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('edge1.4.weight',\n",
       "  tensor(0.0221, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0221, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('edge1.4.bias',\n",
       "  tensor(0.0221, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0221, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('edge2.0.weight',\n",
       "  tensor(0.9889, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(0.0247, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('edge2.0.bias',\n",
       "  tensor(0., device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(0., device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('edge2.1.weight',\n",
       "  tensor(0.1715, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.1715, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('edge2.1.bias',\n",
       "  tensor(0.1712, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.1715, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('edge2.3.weight',\n",
       "  tensor(0.9996, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(0.0003, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('edge2.3.bias',\n",
       "  tensor(0., device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(0., device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('edge2.4.weight',\n",
       "  tensor(0.0221, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0221, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('edge2.4.bias',\n",
       "  tensor(0.0217, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0221, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('u_mlp.0.weight',\n",
       "  tensor(0.9989, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(0.0001, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('u_mlp.0.bias',\n",
       "  tensor(0., device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(0., device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('u_mlp.1.weight',\n",
       "  tensor(0.0312, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0312, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('u_mlp.1.bias',\n",
       "  tensor(0.0312, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0312, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('u_mlp.3.weight',\n",
       "  tensor(0.9998, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(9.1434e-05, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('u_mlp.3.bias',\n",
       "  tensor(0., device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(0., device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('u_mlp.4.weight',\n",
       "  tensor(0.0156, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0156, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('u_mlp.4.bias',\n",
       "  tensor(0.0156, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0155, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.0.v_update.0.weight',\n",
       "  tensor(0.0442, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0442, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.0.v_update.0.bias',\n",
       "  tensor(0.0441, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0441, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.0.v_update.2.weight',\n",
       "  tensor(0.0221, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0221, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.0.v_update.2.bias',\n",
       "  tensor(0.0218, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0220, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.0.e_update.0.weight',\n",
       "  tensor(0.0442, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0442, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.0.e_update.0.bias',\n",
       "  tensor(0.0442, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0442, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.0.e_update.2.weight',\n",
       "  tensor(0.0221, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0221, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.0.e_update.2.bias',\n",
       "  tensor(0.0220, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0221, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.0.u_update.0.weight',\n",
       "  tensor(0.0442, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0442, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.0.u_update.0.bias',\n",
       "  tensor(0.0442, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0442, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.0.u_update.2.weight',\n",
       "  tensor(0.0221, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0221, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.0.u_update.2.bias',\n",
       "  tensor(0.0220, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0220, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.0.conv.edge_model._mlp.0.weight',\n",
       "  tensor(0.0255, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0255, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.0.conv.edge_model._mlp.0.bias',\n",
       "  tensor(0.0255, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0255, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.0.conv.edge_model._mlp.2.weight',\n",
       "  tensor(0.0128, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0128, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.0.conv.edge_model._mlp.2.bias',\n",
       "  tensor(0.0127, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0126, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.0.conv.node_model._mlp.0.weight',\n",
       "  tensor(0.0255, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0255, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.0.conv.node_model._mlp.0.bias',\n",
       "  tensor(0.0255, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0255, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.0.conv.node_model._mlp.2.weight',\n",
       "  tensor(0.0128, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0128, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.0.conv.node_model._mlp.2.bias',\n",
       "  tensor(0.0127, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0127, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.0.conv.global_model._mlp.0.weight',\n",
       "  tensor(0.0255, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0255, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.0.conv.global_model._mlp.0.bias',\n",
       "  tensor(0.0255, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0255, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.0.conv.global_model._mlp.2.weight',\n",
       "  tensor(0.0128, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0128, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.0.conv.global_model._mlp.2.bias',\n",
       "  tensor(0.0128, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0127, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.1.v_update.0.weight',\n",
       "  tensor(0.0442, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0442, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.1.v_update.0.bias',\n",
       "  tensor(0.0442, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0441, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.1.v_update.2.weight',\n",
       "  tensor(0.0221, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0221, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.1.v_update.2.bias',\n",
       "  tensor(0.0218, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0218, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.1.e_update.0.weight',\n",
       "  tensor(0.0442, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0442, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.1.e_update.0.bias',\n",
       "  tensor(0.0442, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0442, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.1.e_update.2.weight',\n",
       "  tensor(0.0221, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0221, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.1.e_update.2.bias',\n",
       "  tensor(0.0221, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0219, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.1.u_update.0.weight',\n",
       "  tensor(0.0442, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0442, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.1.u_update.0.bias',\n",
       "  tensor(0.0441, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0441, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.1.u_update.2.weight',\n",
       "  tensor(0.0221, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0221, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.1.u_update.2.bias',\n",
       "  tensor(0.0221, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0220, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.1.conv.edge_model._mlp.0.weight',\n",
       "  tensor(0.0255, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0255, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.1.conv.edge_model._mlp.0.bias',\n",
       "  tensor(0.0255, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0255, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.1.conv.edge_model._mlp.2.weight',\n",
       "  tensor(0.0128, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0128, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.1.conv.edge_model._mlp.2.bias',\n",
       "  tensor(0.0127, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0127, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.1.conv.node_model._mlp.0.weight',\n",
       "  tensor(0.0255, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0255, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.1.conv.node_model._mlp.0.bias',\n",
       "  tensor(0.0255, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0255, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.1.conv.node_model._mlp.2.weight',\n",
       "  tensor(0.0128, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0128, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.1.conv.node_model._mlp.2.bias',\n",
       "  tensor(0.0127, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0126, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.1.conv.global_model._mlp.0.weight',\n",
       "  tensor(0.0255, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0255, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.1.conv.global_model._mlp.0.bias',\n",
       "  tensor(0.0255, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0255, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.1.conv.global_model._mlp.2.weight',\n",
       "  tensor(0.0128, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0128, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.1.conv.global_model._mlp.2.bias',\n",
       "  tensor(0.0126, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0127, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.2.v_update.0.weight',\n",
       "  tensor(0.0442, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0442, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.2.v_update.0.bias',\n",
       "  tensor(0.0441, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0442, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.2.v_update.2.weight',\n",
       "  tensor(0.0221, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0221, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.2.v_update.2.bias',\n",
       "  tensor(0.0221, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0220, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.2.e_update.0.weight',\n",
       "  tensor(0.0442, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0442, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.2.e_update.0.bias',\n",
       "  tensor(0.0442, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0441, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.2.e_update.2.weight',\n",
       "  tensor(0.0221, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0221, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.2.e_update.2.bias',\n",
       "  tensor(0.0220, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0221, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.2.u_update.0.weight',\n",
       "  tensor(0.0442, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0442, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.2.u_update.0.bias',\n",
       "  tensor(0.0442, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0442, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.2.u_update.2.weight',\n",
       "  tensor(0.0221, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0221, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.2.u_update.2.bias',\n",
       "  tensor(0.0219, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0221, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.2.conv.edge_model._mlp.0.weight',\n",
       "  tensor(0.0255, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0255, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.2.conv.edge_model._mlp.0.bias',\n",
       "  tensor(0.0255, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0255, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.2.conv.edge_model._mlp.2.weight',\n",
       "  tensor(0.0128, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0128, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.2.conv.edge_model._mlp.2.bias',\n",
       "  tensor(0.0124, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0127, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.2.conv.node_model._mlp.0.weight',\n",
       "  tensor(0.0255, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0255, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.2.conv.node_model._mlp.0.bias',\n",
       "  tensor(0.0255, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0255, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.2.conv.node_model._mlp.2.weight',\n",
       "  tensor(0.0128, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0128, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.2.conv.node_model._mlp.2.bias',\n",
       "  tensor(0.0127, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0128, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.2.conv.global_model._mlp.0.weight',\n",
       "  tensor(0.0255, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0255, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.2.conv.global_model._mlp.0.bias',\n",
       "  tensor(0.0255, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0255, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.2.conv.global_model._mlp.2.weight',\n",
       "  tensor(0.0128, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0128, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.2.conv.global_model._mlp.2.bias',\n",
       "  tensor(0.0127, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0128, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.3.v_update.0.weight',\n",
       "  tensor(0.0442, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0442, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.3.v_update.0.bias',\n",
       "  tensor(0.0441, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0442, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.3.v_update.2.weight',\n",
       "  tensor(0.0221, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0221, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.3.v_update.2.bias',\n",
       "  tensor(0.0220, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0219, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.3.e_update.0.weight',\n",
       "  tensor(0.0442, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0442, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.3.e_update.0.bias',\n",
       "  tensor(0.0442, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0442, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.3.e_update.2.weight',\n",
       "  tensor(0.0221, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0221, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.3.e_update.2.bias',\n",
       "  tensor(0.0219, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0220, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.3.u_update.0.weight',\n",
       "  tensor(0.0442, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0442, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.3.u_update.0.bias',\n",
       "  tensor(0.0441, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0442, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.3.u_update.2.weight',\n",
       "  tensor(0.0221, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0221, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.3.u_update.2.bias',\n",
       "  tensor(0.0220, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0220, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.3.conv.edge_model._mlp.0.weight',\n",
       "  tensor(0.0255, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0255, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.3.conv.edge_model._mlp.0.bias',\n",
       "  tensor(0.0255, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0255, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.3.conv.edge_model._mlp.2.weight',\n",
       "  tensor(0.0128, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0128, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.3.conv.edge_model._mlp.2.bias',\n",
       "  tensor(0.0127, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0127, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.3.conv.node_model._mlp.0.weight',\n",
       "  tensor(0.0255, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0255, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.3.conv.node_model._mlp.0.bias',\n",
       "  tensor(0.0255, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0255, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.3.conv.node_model._mlp.2.weight',\n",
       "  tensor(0.0128, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0128, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.3.conv.node_model._mlp.2.bias',\n",
       "  tensor(0.0128, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0127, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.3.conv.global_model._mlp.0.weight',\n",
       "  tensor(0.0255, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0255, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.3.conv.global_model._mlp.0.bias',\n",
       "  tensor(0.0255, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0255, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.3.conv.global_model._mlp.2.weight',\n",
       "  tensor(0.0128, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0128, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv1.3.conv.global_model._mlp.2.bias',\n",
       "  tensor(0.0127, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0127, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv2.0.v_update.0.weight',\n",
       "  tensor(0.0442, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0442, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv2.0.v_update.0.bias',\n",
       "  tensor(0.0441, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0442, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv2.0.v_update.2.weight',\n",
       "  tensor(0.0221, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0221, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv2.0.v_update.2.bias',\n",
       "  tensor(0.0220, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0219, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv2.0.e_update.0.weight',\n",
       "  tensor(0.0442, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0442, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv2.0.e_update.0.bias',\n",
       "  tensor(0.0440, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0442, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv2.0.e_update.2.weight',\n",
       "  tensor(0.0221, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0221, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv2.0.e_update.2.bias',\n",
       "  tensor(0.0221, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0218, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv2.0.u_update.0.weight',\n",
       "  tensor(0.0442, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0442, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv2.0.u_update.0.bias',\n",
       "  tensor(0.0442, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0442, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv2.0.u_update.2.weight',\n",
       "  tensor(0.0221, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0221, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv2.0.u_update.2.bias',\n",
       "  tensor(0.0220, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0221, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv2.0.conv.edge_model._mlp.0.weight',\n",
       "  tensor(0.0255, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0255, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv2.0.conv.edge_model._mlp.0.bias',\n",
       "  tensor(0.0255, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0255, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv2.0.conv.edge_model._mlp.2.weight',\n",
       "  tensor(0.0128, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0128, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv2.0.conv.edge_model._mlp.2.bias',\n",
       "  tensor(0.0127, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0127, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv2.0.conv.node_model._mlp.0.weight',\n",
       "  tensor(0.0255, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0255, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv2.0.conv.node_model._mlp.0.bias',\n",
       "  tensor(0.0255, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0255, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv2.0.conv.node_model._mlp.2.weight',\n",
       "  tensor(0.0128, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0128, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv2.0.conv.node_model._mlp.2.bias',\n",
       "  tensor(0.0127, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0127, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv2.0.conv.global_model._mlp.0.weight',\n",
       "  tensor(0.0255, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0255, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv2.0.conv.global_model._mlp.0.bias',\n",
       "  tensor(0.0255, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0255, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv2.0.conv.global_model._mlp.2.weight',\n",
       "  tensor(0.0128, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0128, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv2.0.conv.global_model._mlp.2.bias',\n",
       "  tensor(0.0128, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0126, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv2.1.v_update.0.weight',\n",
       "  tensor(0.0442, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0442, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv2.1.v_update.0.bias',\n",
       "  tensor(0.0442, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0442, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv2.1.v_update.2.weight',\n",
       "  tensor(0.0221, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0221, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv2.1.v_update.2.bias',\n",
       "  tensor(0.0220, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0221, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv2.1.e_update.0.weight',\n",
       "  tensor(0.0442, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0442, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv2.1.e_update.0.bias',\n",
       "  tensor(0.0442, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0441, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv2.1.e_update.2.weight',\n",
       "  tensor(0.0221, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0221, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv2.1.e_update.2.bias',\n",
       "  tensor(0.0220, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0220, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv2.1.u_update.0.weight',\n",
       "  tensor(0.0442, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0442, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv2.1.u_update.0.bias',\n",
       "  tensor(0.0441, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0442, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv2.1.u_update.2.weight',\n",
       "  tensor(0.0221, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0221, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv2.1.u_update.2.bias',\n",
       "  tensor(0.0221, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0221, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv2.1.conv.edge_model._mlp.0.weight',\n",
       "  tensor(0.0255, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0255, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv2.1.conv.edge_model._mlp.0.bias',\n",
       "  tensor(0.0255, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0255, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv2.1.conv.edge_model._mlp.2.weight',\n",
       "  tensor(0.0128, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0128, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv2.1.conv.edge_model._mlp.2.bias',\n",
       "  tensor(0.0127, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0127, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv2.1.conv.node_model._mlp.0.weight',\n",
       "  tensor(0.0255, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0255, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv2.1.conv.node_model._mlp.0.bias',\n",
       "  tensor(0.0255, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0255, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv2.1.conv.node_model._mlp.2.weight',\n",
       "  tensor(0.0128, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0128, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv2.1.conv.node_model._mlp.2.bias',\n",
       "  tensor(0.0127, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0126, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv2.1.conv.global_model._mlp.0.weight',\n",
       "  tensor(0.0255, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0255, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv2.1.conv.global_model._mlp.0.bias',\n",
       "  tensor(0.0255, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0255, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv2.1.conv.global_model._mlp.2.weight',\n",
       "  tensor(0.0128, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0128, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv2.1.conv.global_model._mlp.2.bias',\n",
       "  tensor(0.0126, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0127, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv2.2.v_update.0.weight',\n",
       "  tensor(0.0442, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0442, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv2.2.v_update.0.bias',\n",
       "  tensor(0.0442, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0441, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv2.2.v_update.2.weight',\n",
       "  tensor(0.0221, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0221, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv2.2.v_update.2.bias',\n",
       "  tensor(0.0221, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0220, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv2.2.e_update.0.weight',\n",
       "  tensor(0.0442, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0442, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv2.2.e_update.0.bias',\n",
       "  tensor(0.0441, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0442, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv2.2.e_update.2.weight',\n",
       "  tensor(0.0221, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0221, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv2.2.e_update.2.bias',\n",
       "  tensor(0.0219, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0218, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv2.2.u_update.0.weight',\n",
       "  tensor(0.0442, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0442, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv2.2.u_update.0.bias',\n",
       "  tensor(0.0441, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0442, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv2.2.u_update.2.weight',\n",
       "  tensor(0.0221, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0221, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv2.2.u_update.2.bias',\n",
       "  tensor(0.0218, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0220, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv2.2.conv.edge_model._mlp.0.weight',\n",
       "  tensor(0.0255, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0255, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv2.2.conv.edge_model._mlp.0.bias',\n",
       "  tensor(0.0255, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0255, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv2.2.conv.edge_model._mlp.2.weight',\n",
       "  tensor(0.0128, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0128, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv2.2.conv.edge_model._mlp.2.bias',\n",
       "  tensor(0.0127, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0127, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv2.2.conv.node_model._mlp.0.weight',\n",
       "  tensor(0.0255, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0255, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv2.2.conv.node_model._mlp.0.bias',\n",
       "  tensor(0.0255, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0255, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv2.2.conv.node_model._mlp.2.weight',\n",
       "  tensor(0.0128, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0128, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv2.2.conv.node_model._mlp.2.bias',\n",
       "  tensor(0.0127, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0125, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv2.2.conv.global_model._mlp.0.weight',\n",
       "  tensor(0.0255, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0255, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv2.2.conv.global_model._mlp.0.bias',\n",
       "  tensor(0.0255, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0255, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv2.2.conv.global_model._mlp.2.weight',\n",
       "  tensor(0.0128, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0128, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('conv2.2.conv.global_model._mlp.2.bias',\n",
       "  tensor(0.0127, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0127, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('head.linear.0.weight',\n",
       "  tensor(0.0442, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0442, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('head.linear.0.bias',\n",
       "  tensor(0.0440, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0442, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('head.linear.2.weight',\n",
       "  tensor(0.0312, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0312, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('head.linear.2.bias',\n",
       "  tensor(0.0217, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(0.0217, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('head_mol.linear.0.weight',\n",
       "  tensor(0.9987, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(0.0036, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('head_mol.linear.0.bias',\n",
       "  tensor(0., device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(0., device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('head_mol.linear.1.weight',\n",
       "  tensor(0.0442, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0442, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('head_mol.linear.1.bias',\n",
       "  tensor(0.0442, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0442, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('head_mol.linear.3.weight',\n",
       "  tensor(0.9983, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(0.0001, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('head_mol.linear.3.bias',\n",
       "  tensor(0., device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(0., device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('head_mol.linear.4.weight',\n",
       "  tensor(0.0312, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0312, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('head_mol.linear.4.bias',\n",
       "  tensor(0.0052, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0308, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('head_atom.linear.0.weight',\n",
       "  tensor(0.9982, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(0.0026, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('head_atom.linear.0.bias',\n",
       "  tensor(0., device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(0., device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('head_atom.linear.1.weight',\n",
       "  tensor(0.0442, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0442, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('head_atom.linear.1.bias',\n",
       "  tensor(0.0441, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0441, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('head_atom.linear.3.weight',\n",
       "  tensor(0.9990, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(1.7464e-05, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('head_atom.linear.3.bias',\n",
       "  tensor(0., device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(0., device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('head_atom.linear.4.weight',\n",
       "  tensor(0.0312, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0312, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('head_atom.linear.4.bias',\n",
       "  tensor(0.0250, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0223, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('head_edge.linear.0.weight',\n",
       "  tensor(0.9994, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(0.0055, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('head_edge.linear.0.bias',\n",
       "  tensor(0., device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(0., device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('head_edge.linear.1.weight',\n",
       "  tensor(0.0442, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0442, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('head_edge.linear.1.bias',\n",
       "  tensor(0.0440, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0437, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('head_edge.linear.3.weight',\n",
       "  tensor(0.9995, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(0.0005, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('head_edge.linear.3.bias',\n",
       "  tensor(0., device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(0., device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('head_edge.linear.4.weight',\n",
       "  tensor(0.0312, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0312, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('head_edge.linear.4.bias',\n",
       "  tensor(0.0193, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       "  tensor(-0.0206, device='cuda:0', grad_fn=<MinBackward1>))]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(n,w.max(),w.min()) for n,w in model.named_parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(data,True,False,logLoss=logLoss,weight=weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(nan, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " tensor([4.5542, 3.8246, 1.0540, 2.3506, 1.2550, 1.3202, 1.6085, 0.1599],\n",
       "        device='cuda:0', grad_fn=<IndexPutBackward>))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "self = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "IsTrain=True\n",
    "typeTrain=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "        out = self.lin_node(data.x)\n",
    "        # edge_*3 only does not repeat for undirected graph. Hence need to add (j,i) to (i,j) in edges\n",
    "        edge_index3 = torch.cat([data.edge_index3,data.edge_index3[[1,0]]],1)\n",
    "        n = data.edge_attr3.shape[0]\n",
    "        temp_ = self.edge2(torch.cat([data.edge_attr3,data.edge_attr4],1))\n",
    "        edge_attr3 = torch.cat([temp_,temp_],0)\n",
    "        edge_attr = self.edge1(data.edge_attr)\n",
    "        \n",
    "        if self.useMax:\n",
    "            u = torch.cat([scatter_max(out, data.batch, dim=0)[0],scatter_max(edge_attr, data.batch[data.edge_index[0]], dim=0)[0]], dim=1)\n",
    "        else:\n",
    "            u = torch.cat([scatter_mean(out, data.batch, dim=0),scatter_mean(edge_attr, data.batch[data.edge_index[0]], dim=0)], dim=1)\n",
    "        u = self.u_mlp(u)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "            for conv in self.conv1:\n",
    "                out,edge_attr,u = conv(out, data.edge_index, edge_attr, u, data.batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0, device='cuda:0')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.isnan(out).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([576, 512]),\n",
       " torch.Size([2, 3430]),\n",
       " torch.Size([3430, 512]),\n",
       " torch.Size([32, 512]),\n",
       " torch.Size([576]))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape,edge_index3.shape,edge_attr3.shape,u.shape,data.batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new, edge_attr_new, u_new = self.conv2[0](out,edge_index3,edge_attr3, u, data.batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0, device='cuda:0')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.isnan(out).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, edge_index, edge_attr, u, batch = out,edge_index3,edge_attr3, u, data.batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "self = self.conv2[0].conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "row, col = edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "        if self.edge_model is not None:\n",
    "            edge_attr = self.edge_model(x[row], x[col], edge_attr, u,\n",
    "                                        batch if batch is None else batch[row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new = self(x, edge_index, edge_attr, u, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NodeModel(\n",
       "  (_mlp): Sequential(\n",
       "    (0): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Linear(in_features=6144, out_features=512, bias=True)\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self.node_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "self = self.node_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NodeModel(\n",
       "  (_mlp): Sequential(\n",
       "    (0): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Linear(in_features=6144, out_features=512, bias=True)\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self.useMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "out,_ = scatter_max(edge_attr, edge_index[0], dim=0, dim_size=x.size(0))\n",
    "#out = scatter_mean(edge_attr, edge_index[0], dim=0, dim_size=x.size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6951, device='cuda:0', grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_attr.abs().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3430, 512])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_attr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.4028e+38, device='cuda:0', grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.abs().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(575, device='cuda:0')"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index[0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_scatter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.3.1'"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_scatter.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_max??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  9,   9,   9,  ..., 563, 564, 565], device='cuda:0')"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.4028e+38, device='cuda:0', grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.abs().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = torch.cat([x, out, u[batch]], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0, device='cuda:0')"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.isnan(out).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(24576, device='cuda:0')"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.isnan(self._mlp(out)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.isnan(self).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "  (1): LeakyReLU(negative_slope=0.01)\n",
       "  (2): Linear(in_features=6144, out_features=512, bias=True)\n",
       "  (3): LeakyReLU(negative_slope=0.01)\n",
       ")"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self._mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6951, device='cuda:0', grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_attr.abs().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "out2 = self._mlp[0](out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0, device='cuda:0')"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.isnan(out2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(inf, device='cuda:0', grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out2.abs().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "out3 = self._mlp[1](out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0, device='cuda:0')"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.isnan(out3).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(inf, device='cuda:0', grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out3.abs().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = \n",
    "out,edge_attr3,u = conv(out,edge_index3,edge_attr3, u, data.batch) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(24576, device='cuda:0')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.isnan(out).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MetaLayer_block"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        if self.interleave:\n",
    "            for conv1,conv2 in zip(self.conv1,self.conv2):\n",
    "                out,edge_attr,u = conv1(out, data.edge_index, edge_attr, u, data.batch)\n",
    "                out,edge_attr3,u = conv2(out,edge_index3,edge_attr3, u, data.batch)\n",
    "        else:\n",
    "            for conv in self.conv1:\n",
    "                out,edge_attr,u = conv(out, data.edge_index, edge_attr, u, data.batch)\n",
    "            for conv in self.conv2:\n",
    "                out,edge_attr3,u = conv(out,edge_index3,edge_attr3, u, data.batch) \n",
    "        \n",
    "        edge_attr3 = edge_attr3[:n]\n",
    "        if typeTrain:\n",
    "            if IsTrain:\n",
    "                y = data.y[data.type_attr]\n",
    "            edge_attr3 = edge_attr3[data.type_attr]\n",
    "            edge_index3 = data.edge_index3[:,data.type_attr]\n",
    "            edge_attr3_old = data.edge_attr3[data.type_attr]\n",
    "        else:\n",
    "            if IsTrain:\n",
    "                y = data.y\n",
    "            edge_index3 = data.edge_index3\n",
    "            edge_attr3_old = data.edge_attr3\n",
    "            \n",
    "        yhat = self.head(out,edge_index3,edge_attr3,edge_attr3_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0, device='cuda:0')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.isnan(yhat).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_atom = self.head_atom(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5760, device='cuda:0')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.isnan(y_atom).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('weight', tensor(3.7253e-09, device='cuda:0', grad_fn=<MinBackward1>)),\n",
       " ('bias', tensor(2.6058e-06, device='cuda:0', grad_fn=<MinBackward1>))]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(n,w.abs().min()) for n,w in self._mlp[0].named_parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(24576, device='cuda:0')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.isnan(out).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([512,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 512,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        512,   0,   0,   0,   0,   0,   0,   0,   0,   0, 512,   0,   0,   0,\n",
       "          0, 512,   0,   0, 512,   0,   0,   0,   0,   0,   0, 512,   0,   0,\n",
       "          0,   0, 512,   0,   0,   0,   0,   0,   0,   0,   0,   0, 512,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0, 512,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        512,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0, 512,   0, 512,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0, 512,   0,   0,   0,   0, 512,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 512,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        512,   0,   0,   0,   0,   0, 512,   0, 512,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 512,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 512,\n",
       "        512, 512, 512,   0,   0,   0,   0,   0, 512,   0,   0,   0,   0,   0,\n",
       "          0, 512,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 512,   0,\n",
       "          0, 512,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0, 512,   0,   0, 512,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0, 512,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0, 512,   0,   0,   0, 512,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0, 512,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0, 512, 512,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 512,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 512,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0, 512,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        512,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 512,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 512,   0, 512,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0, 512,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 512,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0, 512,   0,   0,   0,   0,   0,   0, 512,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 512,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0], device='cuda:0')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.isnan(out).sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'pickle' from '/usr/local/lib/python3.6/pickle.py'>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
