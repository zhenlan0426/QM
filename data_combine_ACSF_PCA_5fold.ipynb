{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'data_ACSF_expand_PCA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../Data/train.csv')\n",
    "test = pd.read_csv('../Data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### node information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Data/structures_dict_ACSF_PCA.pickle', 'rb') as handle:\n",
    "    structures_dict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bond information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Data/bonds_edge_index.pickle', 'rb') as handle:\n",
    "    bonds_edge_index = pickle.load(handle)\n",
    "with open('../Data/bonds_edge_attr_expand.pickle', 'rb') as handle:\n",
    "    bonds_edge_attr = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### coupling information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Data/coupling_edge_index.pickle', 'rb') as handle:\n",
    "    coupling_edge_index = pickle.load(handle)\n",
    "with open('../Data/coupling_edge_attr.pickle', 'rb') as handle:\n",
    "    coupling_edge_attr = pickle.load(handle)\n",
    "with open('../Data/coupling_edge_dist_expand.pickle', 'rb') as handle:\n",
    "    coupling_edge_dist = pickle.load(handle)\n",
    "with open('../Data/coupling_y.pickle', 'rb') as handle:\n",
    "    coupling_y = pickle.load(handle)\n",
    "with open('../Data/coupling_id.pickle', 'rb') as handle:\n",
    "    coupling_id = pickle.load(handle)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mol = np.unique(train.molecule_name)\n",
    "test_mol = np.unique(test.molecule_name)\n",
    "\n",
    "train_mol = np.random.permutation(train_mol)\n",
    "\n",
    "mol_f0,mol_f1,mol_f2,mol_f3,mol_f4 = train_mol[:17000],train_mol[17000:17000*2],train_mol[17000*2:17000*3],\\\n",
    "                                     train_mol[17000*3:17000*4],train_mol[17000*4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(mols,IsTrain):\n",
    "    type_list = [[] for _ in range(8)]\n",
    "    tot_list = []\n",
    "\n",
    "    test_id_type_list = [[] for _ in range(8)]\n",
    "    test_id_list = []\n",
    "        \n",
    "    for m in mols:\n",
    "        if IsTrain:\n",
    "            dict_ = {'x':structures_dict[m],'edge_index':bonds_edge_index[m],\\\n",
    "                               'edge_attr':bonds_edge_attr[m],'y':coupling_y[m],\\\n",
    "                               'edge_index3':coupling_edge_index[m],'edge_attr3':coupling_edge_attr[m],\\\n",
    "                               'edge_attr4':coupling_edge_dist[m]}\n",
    "            tot_list.append(copy.deepcopy(dict_))\n",
    "            test_id_list.append(coupling_id[m])\n",
    "            \n",
    "            temp = dict_['edge_attr3'].argmax(1)\n",
    "            for i in np.nonzero(dict_['edge_attr3'].sum(0))[0]:\n",
    "                dict_['type_attr'] = (temp==i).astype(np.uint8)\n",
    "                type_list[i].append(copy.deepcopy(dict_))\n",
    "                test_id_type_list[i].append(coupling_id[m][temp==i])\n",
    "        else:\n",
    "            dict_ = {'x':structures_dict[m],'edge_index':bonds_edge_index[m],\\\n",
    "                       'edge_attr':bonds_edge_attr[m],\\\n",
    "                       'edge_index3':coupling_edge_index[m],'edge_attr3':coupling_edge_attr[m],\\\n",
    "                       'edge_attr4':coupling_edge_dist[m]}\n",
    "            tot_list.append(copy.deepcopy(dict_))\n",
    "            test_id_list.append(coupling_id[m])\n",
    "            \n",
    "            temp = dict_['edge_attr3'].argmax(1)\n",
    "            for i in np.nonzero(dict_['edge_attr3'].sum(0))[0]:\n",
    "                dict_['type_attr'] = (temp==i).astype(np.uint8)\n",
    "                type_list[i].append(copy.deepcopy(dict_))\n",
    "                test_id_type_list[i].append(coupling_id[m][temp==i])\n",
    "    \n",
    "    return tot_list,type_list,np.concatenate(test_id_list),[np.concatenate(type_i) for type_i in test_id_type_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_list_f0,type_list_f0,tot_id_f0,type_id_f0 = create_data(mol_f0,True)\n",
    "tot_list_f1,type_list_f1,tot_id_f1,type_id_f1 = create_data(mol_f1,True)\n",
    "tot_list_f2,type_list_f2,tot_id_f2,type_id_f2 = create_data(mol_f2,True)\n",
    "tot_list_f3,type_list_f3,tot_id_f3,type_id_f3 = create_data(mol_f3,True)\n",
    "tot_list_f4,type_list_f4,tot_id_f4,type_id_f4 = create_data(mol_f4,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert numpy array to torch array\n",
    "import torch\n",
    "tot_list_f0 = [{k:torch.tensor(i[k]) for k in i.keys()} for i in tot_list_f0]\n",
    "tot_list_f1 = [{k:torch.tensor(i[k]) for k in i.keys()} for i in tot_list_f1]\n",
    "tot_list_f2 = [{k:torch.tensor(i[k]) for k in i.keys()} for i in tot_list_f2]\n",
    "tot_list_f3 = [{k:torch.tensor(i[k]) for k in i.keys()} for i in tot_list_f3]\n",
    "tot_list_f4 = [{k:torch.tensor(i[k]) for k in i.keys()} for i in tot_list_f4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy2torch(type_list):\n",
    "    out = []\n",
    "    for type_ in type_list:\n",
    "        out.append([{k:torch.tensor(i[k]) for k in i.keys()} for i in type_])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_list_f0 = numpy2torch(type_list_f0)\n",
    "type_list_f1 = numpy2torch(type_list_f1)\n",
    "type_list_f2 = numpy2torch(type_list_f2)\n",
    "type_list_f3 = numpy2torch(type_list_f3)\n",
    "type_list_f4 = numpy2torch(type_list_f4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Data/train_'+prefix+'_f0.pickle', 'wb') as handle:\n",
    "    pickle.dump(tot_list_f0, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('../Data/train_'+prefix+'_f1.pickle', 'wb') as handle:\n",
    "    pickle.dump(tot_list_f1, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('../Data/train_'+prefix+'_f2.pickle', 'wb') as handle:\n",
    "    pickle.dump(tot_list_f2, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('../Data/train_'+prefix+'_f3.pickle', 'wb') as handle:\n",
    "    pickle.dump(tot_list_f3, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('../Data/train_'+prefix+'_f4.pickle', 'wb') as handle:\n",
    "    pickle.dump(tot_list_f4, handle, protocol=pickle.HIGHEST_PROTOCOL)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_type(prefix,type_list,postfix=''):\n",
    "    for i,type_ in enumerate(type_list):\n",
    "        with open(prefix+'_type_'+str(i)+postfix+'.pickle', 'wb') as handle:\n",
    "            pickle.dump(type_, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_type('../Data/train_'+prefix+'_f0',type_list_f0)\n",
    "save_type('../Data/train_'+prefix+'_f1',type_list_f1)\n",
    "save_type('../Data/train_'+prefix+'_f2',type_list_f2)\n",
    "save_type('../Data/train_'+prefix+'_f3',type_list_f3)\n",
    "save_type('../Data/train_'+prefix+'_f4',type_list_f4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Data/train_'+prefix+'_f0_id.pickle', 'wb') as handle:\n",
    "    pickle.dump(tot_id_f0, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('../Data/train_'+prefix+'_f1_id.pickle', 'wb') as handle:\n",
    "    pickle.dump(tot_id_f1, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('../Data/train_'+prefix+'_f2_id.pickle', 'wb') as handle:\n",
    "    pickle.dump(tot_id_f2, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('../Data/train_'+prefix+'_f3_id.pickle', 'wb') as handle:\n",
    "    pickle.dump(tot_id_f3, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('../Data/train_'+prefix+'_f4_id.pickle', 'wb') as handle:\n",
    "    pickle.dump(tot_id_f4, handle, protocol=pickle.HIGHEST_PROTOCOL)    \n",
    "\n",
    "save_type('../Data/train_'+prefix+'_f0',type_id_f0,'_id')\n",
    "save_type('../Data/train_'+prefix+'_f1',type_id_f1,'_id')\n",
    "save_type('../Data/train_'+prefix+'_f2',type_id_f2,'_id')\n",
    "save_type('../Data/train_'+prefix+'_f3',type_id_f3,'_id')\n",
    "save_type('../Data/train_'+prefix+'_f4',type_id_f4,'_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
