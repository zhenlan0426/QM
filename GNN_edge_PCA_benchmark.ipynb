{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "from torch_geometric.data import Data,DataLoader\n",
    "from functions_refactor import *\n",
    "from pytorch_util import *\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model parameters\n",
    "reuse = False\n",
    "block = MEGNet_block\n",
    "head = feedforwardHead_Update\n",
    "data = '../Data/{}_data_ACSF_expand_PCA.pickle'\n",
    "batch_size = 32\n",
    "dim = 128\n",
    "epochs = 10\n",
    "clip = 0.4\n",
    "layer1 = 3\n",
    "layer2 = 3\n",
    "factor = 2\n",
    "lr = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data2(Data):\n",
    "    def apply_ignore_index(self, func, *keys):\n",
    "        r\"\"\"Applies the function :obj:`func` to all tensor attributes\n",
    "        :obj:`*keys`. If :obj:`*keys` is not given, :obj:`func` is applied to\n",
    "        all present attributes.\n",
    "        \"\"\"\n",
    "        for key, item in self(*keys):\n",
    "            if torch.is_tensor(item):\n",
    "                if 'index' not in key:\n",
    "                    self[key] = func(item)\n",
    "        return self\n",
    "    \n",
    "    def to(self, device, *keys):\n",
    "        r\"\"\"Performs tensor dtype and/or device conversion to all attributes\n",
    "        :obj:`*keys`.\n",
    "        If :obj:`*keys` is not given, the conversion is applied to all present\n",
    "        attributes.\"\"\"\n",
    "        #print(str(device))\n",
    "        if 'cuda' in str(device):\n",
    "            return self.apply(lambda x: x.to(device), *keys)\n",
    "        else:\n",
    "            return self.apply_ignore_index(lambda x: x.to(device), *keys)\n",
    "\n",
    "def get_data2(data,batch_size):\n",
    "    with open(data.format('train'), 'rb') as handle:\n",
    "        train_data = pickle.load(handle)\n",
    "    with open(data.format('val'), 'rb') as handle:\n",
    "        val_data = pickle.load(handle)\n",
    "    \n",
    "    train_list = [Data2(**d) for d in train_data]\n",
    "    train_dl = DataLoader2(train_list,batch_size,shuffle=True)\n",
    "    val_list = [Data2(**d) for d in val_data]\n",
    "    val_dl = DataLoader2(val_list,batch_size,shuffle=False)\n",
    "    \n",
    "    return train_dl,val_dl\n",
    "\n",
    "class Batch2(Data2):\n",
    "    r\"\"\"A plain old python object modeling a batch of graphs as one big\n",
    "    (dicconnected) graph. With :class:`torch_geometric.data.Data` being the\n",
    "    base class, all its methods can also be used here.\n",
    "    In addition, single graphs can be reconstructed via the assignment vector\n",
    "    :obj:`batch`, which maps each node to its respective graph identifier.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, batch=None, **kwargs):\n",
    "        super(Batch2, self).__init__(**kwargs)\n",
    "        self.batch = batch\n",
    "\n",
    "    @staticmethod\n",
    "    def from_data_list(data_list, follow_batch=[]):\n",
    "        r\"\"\"Constructs a batch object from a python list holding\n",
    "        :class:`torch_geometric.data.Data` objects.\n",
    "        The assignment vector :obj:`batch` is created on the fly.\n",
    "        Additionally, creates assignment batch vectors for each key in\n",
    "        :obj:`follow_batch`.\"\"\"\n",
    "\n",
    "        keys = [set(data.keys) for data in data_list]\n",
    "        keys = list(set.union(*keys))\n",
    "        assert 'batch' not in keys\n",
    "\n",
    "        batch = Batch2()\n",
    "\n",
    "        for key in keys:\n",
    "            batch[key] = []\n",
    "\n",
    "        for key in follow_batch:\n",
    "            batch['{}_batch'.format(key)] = []\n",
    "\n",
    "        batch.batch = []\n",
    "\n",
    "        cumsum = 0\n",
    "        for i, data in enumerate(data_list):\n",
    "            for key in data.keys:\n",
    "                item = data[key]\n",
    "                item = item + cumsum if data.__cumsum__(key, item) else item\n",
    "                batch[key].append(item)\n",
    "\n",
    "            for key in follow_batch:\n",
    "                size = data[key].size(data.__cat_dim__(key, data[key]))\n",
    "                item = torch.full((size, ), i, dtype=torch.long)\n",
    "                batch['{}_batch'.format(key)].append(item)\n",
    "\n",
    "            num_nodes = data.num_nodes\n",
    "            if num_nodes is not None:\n",
    "                item = torch.full((num_nodes, ), i, dtype=torch.long)\n",
    "                batch.batch.append(item)\n",
    "                cumsum += num_nodes\n",
    "\n",
    "        if num_nodes is None:  # pragma: no cover\n",
    "            batch.batch = None\n",
    "\n",
    "        for key in batch.keys:\n",
    "            item = batch[key][0]\n",
    "            if torch.is_tensor(item):\n",
    "                batch[key] = torch.cat(\n",
    "                    batch[key], dim=data_list[0].__cat_dim__(key, item))\n",
    "            elif isinstance(item, int) or isinstance(item, float):\n",
    "                batch[key] = torch.tensor(batch[key])\n",
    "            else:\n",
    "                raise ValueError('Unsupported attribute type.')\n",
    "\n",
    "        # Copy custom data functions to batch.\n",
    "        # if data_list.__class__ != Data:\n",
    "        #     org_funcs = set(Data.__dict__.keys())\n",
    "        #     funcs = set(data_list[0].__class__.__dict__.keys())\n",
    "        #     batch.__custom_funcs__ = funcs.difference(org_funcs)\n",
    "        #     for func in funcs.difference(org_funcs):\n",
    "        #         setattr(batch, func, getattr(data_list[0], func))\n",
    "\n",
    "        return batch.contiguous()\n",
    "\n",
    "    @property\n",
    "    def num_graphs(self):\n",
    "        \"\"\"Returns the number of graphs in the batch.\"\"\"\n",
    "        return self.batch[-1].item() + 1\n",
    "    \n",
    "    \n",
    "class DataLoader2(torch.utils.data.DataLoader):\n",
    "    r\"\"\"Data loader which merges data objects from a\n",
    "    :class:`torch_geometric.data.dataset` to a mini-batch.\n",
    "\n",
    "    Args:\n",
    "        dataset (Dataset): The dataset from which to load the data.\n",
    "        batch_size (int, optional): How may samples per batch to load.\n",
    "            (default: :obj:`1`)\n",
    "        shuffle (bool, optional): If set to :obj:`True`, the data will be\n",
    "            reshuffled at every epoch (default: :obj:`False`)\n",
    "        follow_batch (list or tuple, optional): Creates assignment batch\n",
    "            vectors for each key in the list. (default: :obj:`[]`)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 dataset,\n",
    "                 batch_size=1,\n",
    "                 shuffle=False,\n",
    "                 follow_batch=[],\n",
    "                 **kwargs):\n",
    "        super(DataLoader2,self).__init__(\n",
    "            dataset,\n",
    "            batch_size,\n",
    "            shuffle,\n",
    "            collate_fn=lambda data_list: Batch2.from_data_list(\n",
    "                data_list, follow_batch),\n",
    "            **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl,val_dl = get_data(data,batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss: +0.351, val_loss: -0.104, \n",
      "train_vector: +4.16|+0.90|+0.13|-0.42|-0.58|+0.12|-0.61|-0.91, \n",
      "val_vector  : +3.79|+0.22|-0.28|-1.13|-1.07|-0.18|-0.96|-1.22\n",
      "\n",
      "epoch:1, train_loss: -0.366, val_loss: -0.524, \n",
      "train_vector: +1.74|+0.36|-0.34|-0.99|-1.11|-0.24|-1.04|-1.31, \n",
      "val_vector  : +1.22|+0.15|-0.53|-1.20|-1.22|-0.37|-0.90|-1.34\n",
      "\n",
      "epoch:2, train_loss: -0.647, val_loss: -0.682, \n",
      "train_vector: +0.85|+0.10|-0.51|-1.24|-1.31|-0.38|-1.20|-1.49, \n",
      "val_vector  : +0.44|+0.62|-0.64|-1.11|-1.33|-0.47|-1.37|-1.59\n",
      "\n",
      "epoch:3, train_loss: -0.759, val_loss: -0.899, \n",
      "train_vector: +0.79|-0.05|-0.62|-1.38|-1.43|-0.47|-1.30|-1.60, \n",
      "val_vector  : +0.47|-0.23|-0.75|-1.52|-1.50|-0.56|-1.41|-1.69\n",
      "\n",
      "epoch:4, train_loss: -0.838, val_loss: -0.910, \n",
      "train_vector: +0.75|-0.16|-0.69|-1.47|-1.52|-0.53|-1.38|-1.70, \n",
      "val_vector  : +0.72|-0.15|-0.80|-1.51|-1.64|-0.62|-1.51|-1.75\n",
      "\n",
      "epoch:5, train_loss: -0.897, val_loss: -0.989, \n",
      "train_vector: +0.73|-0.21|-0.76|-1.55|-1.59|-0.59|-1.44|-1.76, \n",
      "val_vector  : +0.23|-0.08|-0.88|-1.60|-1.62|-0.67|-1.52|-1.77\n",
      "\n",
      "epoch:6, train_loss: -0.944, val_loss: -1.012, \n",
      "train_vector: +0.69|-0.24|-0.81|-1.60|-1.65|-0.63|-1.48|-1.82, \n",
      "val_vector  : +0.33|-0.15|-0.87|-1.60|-1.61|-0.72|-1.61|-1.87\n",
      "\n",
      "epoch:7, train_loss: -0.999, val_loss: -1.120, \n",
      "train_vector: +0.64|-0.34|-0.86|-1.65|-1.70|-0.67|-1.53|-1.88, \n",
      "val_vector  : +0.08|-0.27|-0.96|-1.87|-1.74|-0.73|-1.62|-1.84\n",
      "\n",
      "epoch:8, train_loss: -1.043, val_loss: -1.107, \n",
      "train_vector: +0.55|-0.38|-0.89|-1.70|-1.75|-0.71|-1.56|-1.92, \n",
      "val_vector  : +0.57|-0.41|-1.00|-1.75|-1.85|-0.78|-1.71|-1.92\n",
      "\n",
      "epoch:9, train_loss: -1.086, val_loss: -1.088, \n",
      "train_vector: +0.48|-0.43|-0.93|-1.73|-1.79|-0.74|-1.59|-1.96, \n",
      "val_vector  : +0.81|-0.37|-1.03|-1.83|-1.80|-0.82|-1.65|-2.00\n",
      "\n",
      "Training completed in 828.373863697052s\n"
     ]
    }
   ],
   "source": [
    "# no apex\n",
    "model = GNN_edgeUpdate(reuse,block,head,dim,layer1,layer2,factor,**data_dict[data]).to('cuda:0')\n",
    "paras = trainable_parameter(model)\n",
    "opt = Adam(paras,lr=lr)\n",
    "model,train_loss_list,val_loss_list,bestWeight = train_type(opt,model,epochs,train_dl,val_dl,paras,clip,\\\n",
    "                                                            UseAmp=False,AMP_clip=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "epoch:0, train_loss: +0.431, val_loss: -0.095, \n",
      "train_vector: +4.35|+1.30|+0.15|-0.41|-0.57|+0.14|-0.59|-0.91, \n",
      "val_vector  : +4.15|+0.14|-0.32|-1.24|-1.01|-0.20|-1.07|-1.20\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "epoch:1, train_loss: -0.180, val_loss: -0.631, \n",
      "train_vector: +3.23|+0.37|-0.34|-0.95|-1.11|-0.26|-1.06|-1.33, \n",
      "val_vector  : +0.68|+0.15|-0.50|-1.03|-1.27|-0.37|-1.22|-1.49\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "epoch:2, train_loss: -0.641, val_loss: -0.742, \n",
      "train_vector: +0.92|+0.14|-0.51|-1.26|-1.31|-0.40|-1.21|-1.50, \n",
      "val_vector  : +0.78|+0.44|-0.66|-1.57|-1.42|-0.51|-1.36|-1.63\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "epoch:3, train_loss: -0.756, val_loss: -0.931, \n",
      "train_vector: +0.82|-0.02|-0.62|-1.39|-1.43|-0.49|-1.31|-1.62, \n",
      "val_vector  : +0.28|-0.46|-0.72|-1.37|-1.44|-0.59|-1.42|-1.72\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "epoch:4, train_loss: -0.843, val_loss: -1.019, \n",
      "train_vector: +0.76|-0.15|-0.70|-1.48|-1.52|-0.56|-1.38|-1.71, \n",
      "val_vector  : +0.22|-0.46|-0.79|-1.59|-1.66|-0.64|-1.51|-1.72\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "epoch:5, train_loss: -0.917, val_loss: -1.037, \n",
      "train_vector: +0.71|-0.26|-0.76|-1.58|-1.60|-0.61|-1.45|-1.79, \n",
      "val_vector  : +0.60|-0.61|-0.85|-1.64|-1.72|-0.70|-1.52|-1.85\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "epoch:6, train_loss: -0.958, val_loss: -1.101, \n",
      "train_vector: +0.68|-0.27|-0.81|-1.60|-1.66|-0.66|-1.50|-1.84, \n",
      "val_vector  : +0.58|-0.62|-0.94|-1.91|-1.69|-0.73|-1.59|-1.90\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n",
      "epoch:7, train_loss: -1.015, val_loss: -1.173, \n",
      "train_vector: +0.60|-0.34|-0.86|-1.68|-1.71|-0.69|-1.54|-1.90, \n",
      "val_vector  : +0.22|-0.60|-0.91|-1.95|-1.76|-0.76|-1.70|-1.93\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n",
      "epoch:8, train_loss: -1.060, val_loss: -1.082, \n",
      "train_vector: +0.51|-0.40|-0.90|-1.70|-1.75|-0.73|-1.58|-1.94, \n",
      "val_vector  : +0.20|-0.00|-0.99|-1.78|-1.74|-0.81|-1.57|-1.96\n",
      "\n",
      "epoch:9, train_loss: -1.101, val_loss: -1.171, \n",
      "train_vector: +0.41|-0.43|-0.93|-1.75|-1.78|-0.76|-1.61|-1.97, \n",
      "val_vector  : +0.05|-0.38|-1.02|-1.71|-1.79|-0.83|-1.69|-1.99\n",
      "\n",
      "Training completed in 1345.8120119571686s\n"
     ]
    }
   ],
   "source": [
    "# apex-O1\n",
    "model = GNN_edgeUpdate(reuse,block,head,dim,layer1,layer2,factor,**data_dict[data]).to('cuda:0')\n",
    "paras = trainable_parameter(model)\n",
    "opt = Adam(paras,lr=lr)\n",
    "model, opt = amp.initialize(model, opt, opt_level=\"O1\")\n",
    "model,train_loss_list,val_loss_list,bestWeight = train_type(opt,model,epochs,train_dl,val_dl,paras,clip,\\\n",
    "                                                            UseAmp=True,AMP_clip=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl,val_dl = get_data2(data,batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN_edgeUpdate(torch.nn.Module):\n",
    "\n",
    "    def __init__(self,reuse,block,head,dim,layer1,layer2,factor,\\\n",
    "                 node_in,edge_in,edge_in4,edge_in3=8,aggr='mean'):\n",
    "        # block,head are nn.Module\n",
    "        # node_in,edge_in are dim for bonding and edge_in4,edge_in3 for coupling\n",
    "        super(GNN_edgeUpdate, self).__init__()\n",
    "        self.lin_node = Sequential(BatchNorm1d(node_in),Linear(node_in, dim*factor),LeakyReLU(), \\\n",
    "                                   BatchNorm1d(dim*factor),Linear(dim*factor, dim),LeakyReLU())\n",
    "\n",
    "        self.edge1 = Sequential(BatchNorm1d(edge_in),Linear(edge_in, dim*factor),LeakyReLU(), \\\n",
    "                                   BatchNorm1d(dim*factor),Linear(dim*factor, dim),LeakyReLU())\n",
    "\n",
    "        self.edge2 = Sequential(BatchNorm1d(edge_in4+edge_in3),Linear(edge_in4+edge_in3, dim*factor),LeakyReLU(), \\\n",
    "                                   BatchNorm1d(dim*factor),Linear(dim*factor, dim),LeakyReLU())        \n",
    "        if reuse:\n",
    "            self.conv1 = block(dim=dim,aggr=aggr)\n",
    "            self.conv2 = block(dim=dim,aggr=aggr)\n",
    "        else:\n",
    "            self.conv1 = nn.ModuleList([block(dim=dim,aggr=aggr) for _ in range(layer1)])\n",
    "            self.conv2 = nn.ModuleList([block(dim=dim,aggr=aggr) for _ in range(layer2)])            \n",
    "        \n",
    "        self.head = head(dim)\n",
    "        \n",
    "    def forward(self, data,IsTrain=False,typeTrain=False,logLoss=True):\n",
    "        out = self.lin_node(data.x)\n",
    "        # edge_*3 only does not repeat for undirected graph. Hence need to add (j,i) to (i,j) in edges\n",
    "        edge_index3 = torch.cat([data.edge_index3,data.edge_index3[[1,0]]],1)\n",
    "        n = data.edge_attr3.shape[0]\n",
    "        temp_ = self.edge2(torch.cat([data.edge_attr3,data.edge_attr4],1))\n",
    "        edge_attr3 = torch.cat([temp_,temp_],0)\n",
    "        \n",
    "        edge_attr = self.edge1(data.edge_attr)\n",
    "        for conv in self.conv1:\n",
    "            out,edge_attr = conv(out,data.edge_index,edge_attr)\n",
    "        \n",
    "        for conv in self.conv2:\n",
    "            out,edge_attr3 = conv(out,edge_index3,edge_attr3)    \n",
    "        \n",
    "        edge_attr3 = edge_attr3[:n]\n",
    "        if typeTrain:\n",
    "            if IsTrain:\n",
    "                y = data.y[data.type_attr]\n",
    "            edge_attr3 = edge_attr3[data.type_attr]\n",
    "            edge_index3 = data.edge_index3[:,data.type_attr]\n",
    "            edge_attr3_old = data.edge_attr3[data.type_attr]\n",
    "        else:\n",
    "            if IsTrain:\n",
    "                y = data.y\n",
    "            edge_index3 = data.edge_index3\n",
    "            edge_attr3_old = data.edge_attr3\n",
    "            \n",
    "        yhat = self.head(out,edge_index3,edge_attr3)\n",
    "        \n",
    "        if IsTrain:\n",
    "            k = torch.sum(edge_attr3_old,0)\n",
    "            nonzeroIndex = torch.nonzero(k).squeeze(1)\n",
    "            abs_ = torch.abs(y-yhat).unsqueeze(1)\n",
    "            loss_perType = torch.zeros(8,device='cuda:0').to(torch.float16)\n",
    "            if logLoss:\n",
    "                loss_perType[nonzeroIndex] = torch.log(torch.sum(abs_ * edge_attr3_old[:,nonzeroIndex],0)/k[nonzeroIndex])\n",
    "                loss = torch.sum(loss_perType)/nonzeroIndex.shape[0]\n",
    "                return loss,loss_perType\n",
    "            else:\n",
    "                loss_perType[nonzeroIndex] = torch.sum(abs_ * edge_attr3_old[:,nonzeroIndex],0)/k[nonzeroIndex]\n",
    "                loss = torch.sum(loss_perType)/nonzeroIndex.shape[0]\n",
    "                loss_perType[nonzeroIndex] = torch.log(loss_perType[nonzeroIndex])\n",
    "                return loss,loss_perType\n",
    "        else:\n",
    "            return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "epoch:0, train_loss: +0.386, val_loss: -0.024, \n",
      "train_vector: +4.22|+1.07|+0.12|-0.38|-0.55|+0.13|-0.60|-0.94, \n",
      "val_vector  : +3.91|+0.12|-0.32|-0.48|-1.07|-0.11|-1.06|-1.17\n",
      "\n",
      "epoch:1, train_loss: -0.295, val_loss: -0.689, \n",
      "train_vector: +2.22|+0.33|-0.33|-0.89|-1.08|-0.23|-1.04|-1.34, \n",
      "val_vector  : +0.71|-0.03|-0.52|-1.33|-1.25|-0.36|-1.24|-1.48\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "epoch:2, train_loss: -0.628, val_loss: -0.724, \n",
      "train_vector: +0.85|+0.11|-0.50|-1.14|-1.28|-0.37|-1.19|-1.52, \n",
      "val_vector  : +0.91|-0.23|-0.60|-1.04|-1.32|-0.48|-1.40|-1.64\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "epoch:3, train_loss: -0.747, val_loss: -0.915, \n",
      "train_vector: +0.79|-0.05|-0.61|-1.30|-1.41|-0.46|-1.29|-1.64, \n",
      "val_vector  : +0.34|-0.38|-0.73|-1.61|-1.48|-0.53|-1.25|-1.71\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n",
      "epoch:4, train_loss: -0.830, val_loss: -0.909, \n",
      "train_vector: +0.74|-0.12|-0.69|-1.43|-1.51|-0.52|-1.38|-1.72, \n",
      "val_vector  : +0.36|-0.27|-0.74|-1.30|-1.48|-0.60|-1.45|-1.80\n",
      "\n",
      "epoch:5, train_loss: -0.889, val_loss: -1.045, \n",
      "train_vector: +0.73|-0.21|-0.75|-1.50|-1.58|-0.57|-1.43|-1.80, \n",
      "val_vector  : +0.45|-0.45|-0.88|-1.84|-1.58|-0.65|-1.56|-1.83\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "epoch:6, train_loss: -0.939, val_loss: -1.029, \n",
      "train_vector: +0.69|-0.24|-0.80|-1.57|-1.64|-0.62|-1.48|-1.85, \n",
      "val_vector  : +0.39|-0.62|-0.89|-1.38|-1.63|-0.67|-1.57|-1.86\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "epoch:7, train_loss: -1.000, val_loss: -0.992, \n",
      "train_vector: +0.63|-0.35|-0.85|-1.63|-1.70|-0.66|-1.53|-1.90, \n",
      "val_vector  : +0.45|+0.23|-0.95|-1.66|-1.76|-0.72|-1.59|-1.94\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "epoch:8, train_loss: -1.035, val_loss: -0.995, \n",
      "train_vector: +0.61|-0.38|-0.89|-1.67|-1.74|-0.70|-1.57|-1.95, \n",
      "val_vector  : +0.85|+0.07|-0.94|-1.76|-1.75|-0.76|-1.70|-1.97\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "epoch:9, train_loss: -1.075, val_loss: -1.143, \n",
      "train_vector: +0.54|-0.41|-0.92|-1.72|-1.78|-0.72|-1.60|-1.98, \n",
      "val_vector  : +0.04|-0.12|-1.03|-1.71|-1.81|-0.80|-1.73|-1.98\n",
      "\n",
      "Training completed in 1193.417114496231s\n"
     ]
    }
   ],
   "source": [
    "# apex-O2\n",
    "model = GNN_edgeUpdate(reuse,block,head,dim,layer1,layer2,factor,**data_dict[data]).to('cuda:0')\n",
    "paras = trainable_parameter(model)\n",
    "opt = Adam(paras,lr=lr)\n",
    "model, opt = amp.initialize(model, opt, opt_level=\"O2\")\n",
    "model,train_loss_list,val_loss_list,bestWeight = train_type(opt,model,epochs,train_dl,val_dl,paras,clip,\\\n",
    "                                                            UseAmp=True,AMP_clip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
